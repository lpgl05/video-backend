"""
GPUä»»åŠ¡è°ƒåº¦å™¨ - ä¼˜åŒ–GPUå’ŒCPUèµ„æºåˆ†é…ï¼Œæå‡å¹¶å‘å¤„ç†èƒ½åŠ›
ä¸“ä¸ºRTX 3090ä¼˜åŒ–ï¼Œå®ç°GPUä½¿ç”¨ç‡æœ€å¤§åŒ–
"""

import asyncio
import time
import psutil
import subprocess
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

logger = logging.getLogger(__name__)

class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    VIDEO_ENCODE = "video_encode"      # è§†é¢‘ç¼–ç 
    VIDEO_DECODE = "video_decode"      # è§†é¢‘è§£ç 
    VIDEO_FILTER = "video_filter"      # è§†é¢‘æ»¤é•œ
    VIDEO_CONCAT = "video_concat"      # è§†é¢‘æ‹¼æ¥
    AUDIO_PROCESS = "audio_process"    # éŸ³é¢‘å¤„ç†
    IMAGE_PROCESS = "image_process"    # å›¾åƒå¤„ç†

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4

@dataclass
class GPUTask:
    """GPUä»»åŠ¡æ•°æ®ç±»"""
    task_id: str
    task_type: TaskType
    priority: TaskPriority
    command: List[str]
    input_files: List[str]
    output_file: str
    estimated_duration: float = 0.0
    gpu_memory_required: int = 1024  # MB
    created_at: float = 0.0
    started_at: float = 0.0
    completed_at: float = 0.0
    status: str = "pending"  # pending, running, completed, failed

class GPUResourceMonitor:
    """GPUèµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.gpu_available = self._check_gpu_availability()
        self.gpu_memory_total = self._get_gpu_memory_total()
        self.gpu_utilization_history = []
        self.cpu_utilization_history = []
    
    def _check_gpu_availability(self) -> bool:
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        try:
            result = subprocess.run(['nvidia-smi'], capture_output=True, timeout=5)
            return result.returncode == 0
        except:
            return False
    
    def _get_gpu_memory_total(self) -> int:
        """è·å–GPUæ€»å†…å­˜ï¼ˆMBï¼‰"""
        try:
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=memory.total', 
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0:
                return int(result.stdout.strip())
            return 24576  # RTX 3090é»˜è®¤å€¼
        except:
            return 24576
    
    def get_gpu_status(self) -> Dict:
        """è·å–GPUçŠ¶æ€"""
        try:
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0:
                values = result.stdout.strip().split(', ')
                return {
                    'utilization': int(values[0]),
                    'memory_used': int(values[1]),
                    'memory_total': int(values[2]),
                    'temperature': int(values[3]),
                    'memory_free': int(values[2]) - int(values[1])
                }
        except:
            pass
        
        return {
            'utilization': 0,
            'memory_used': 0,
            'memory_total': self.gpu_memory_total,
            'temperature': 0,
            'memory_free': self.gpu_memory_total
        }
    
    def get_cpu_status(self) -> Dict:
        """è·å–CPUçŠ¶æ€"""
        return {
            'utilization': psutil.cpu_percent(interval=0.1),
            'memory_percent': psutil.virtual_memory().percent,
            'core_count': psutil.cpu_count(),
            'load_avg': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
        }
    
    def update_history(self):
        """æ›´æ–°å†å²è®°å½•"""
        gpu_status = self.get_gpu_status()
        cpu_status = self.get_cpu_status()
        
        self.gpu_utilization_history.append({
            'timestamp': time.time(),
            'utilization': gpu_status['utilization'],
            'memory_used': gpu_status['memory_used']
        })
        
        self.cpu_utilization_history.append({
            'timestamp': time.time(),
            'utilization': cpu_status['utilization'],
            'memory_percent': cpu_status['memory_percent']
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.gpu_utilization_history) > 100:
            self.gpu_utilization_history = self.gpu_utilization_history[-50:]
        if len(self.cpu_utilization_history) > 100:
            self.cpu_utilization_history = self.cpu_utilization_history[-50:]

class GPUTaskScheduler:
    """GPUä»»åŠ¡è°ƒåº¦å™¨ - ä¼˜åŒ–èµ„æºåˆ†é…"""
    
    def __init__(self, max_concurrent_gpu_tasks: int = 3, max_concurrent_cpu_tasks: int = 8):
        self.max_concurrent_gpu_tasks = max_concurrent_gpu_tasks
        self.max_concurrent_cpu_tasks = max_concurrent_cpu_tasks
        
        self.resource_monitor = GPUResourceMonitor()
        self.task_queues = {
            TaskPriority.URGENT: asyncio.PriorityQueue(),
            TaskPriority.HIGH: asyncio.PriorityQueue(),
            TaskPriority.NORMAL: asyncio.PriorityQueue(),
            TaskPriority.LOW: asyncio.PriorityQueue()
        }
        
        self.running_gpu_tasks: Dict[str, GPUTask] = {}
        self.running_cpu_tasks: Dict[str, GPUTask] = {}
        self.completed_tasks: Dict[str, GPUTask] = {}
        
        self.running = False
        self.scheduler_task = None
        self.monitor_task = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'gpu_utilization_avg': 0.0,
            'cpu_utilization_avg': 0.0,
            'throughput': 0.0  # ä»»åŠ¡/ç§’
        }
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            return
        
        self.running = True
        self.scheduler_task = asyncio.create_task(self._scheduler_loop())
        self.monitor_task = asyncio.create_task(self._monitor_loop())
        
        logger.info("ğŸš€ GPUä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info(f"   æœ€å¤§GPUå¹¶å‘ä»»åŠ¡: {self.max_concurrent_gpu_tasks}")
        logger.info(f"   æœ€å¤§CPUå¹¶å‘ä»»åŠ¡: {self.max_concurrent_cpu_tasks}")
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False
        
        if self.scheduler_task:
            self.scheduler_task.cancel()
        if self.monitor_task:
            self.monitor_task.cancel()
        
        # ç­‰å¾…æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡å®Œæˆ
        all_tasks = list(self.running_gpu_tasks.values()) + list(self.running_cpu_tasks.values())
        if all_tasks:
            logger.info(f"ç­‰å¾… {len(all_tasks)} ä¸ªä»»åŠ¡å®Œæˆ...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä»»åŠ¡å–æ¶ˆé€»è¾‘
        
        logger.info("ğŸ›‘ GPUä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
    
    async def submit_task(self, task: GPUTask) -> str:
        """æäº¤ä»»åŠ¡åˆ°è°ƒåº¦å™¨"""
        task.created_at = time.time()
        task.task_id = f"{task.task_type.value}_{int(time.time() * 1000)}_{len(self.completed_tasks)}"
        
        # æ ¹æ®ä¼˜å…ˆçº§æ·»åŠ åˆ°å¯¹åº”é˜Ÿåˆ—
        await self.task_queues[task.priority].put((task.priority.value, task.created_at, task))
        
        self.stats['total_tasks'] += 1
        
        logger.info(f"ğŸ“ ä»»åŠ¡å·²æäº¤: {task.task_id} ({task.task_type.value}, ä¼˜å…ˆçº§: {task.priority.name})")
        
        # ç¡®ä¿è°ƒåº¦å™¨è¿è¡Œ
        if not self.running:
            await self.start()
        
        return task.task_id
    
    async def _scheduler_loop(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯"""
        while self.running:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨èµ„æº
                if not await self._has_available_resources():
                    await asyncio.sleep(0.1)
                    continue
                
                # æŒ‰ä¼˜å…ˆçº§è·å–ä»»åŠ¡
                task = await self._get_next_task()
                if task:
                    await self._execute_task(task)
                else:
                    await asyncio.sleep(0.1)
                    
            except Exception as e:
                logger.error(f"è°ƒåº¦å™¨å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(1)
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                self.resource_monitor.update_history()
                await self._update_performance_stats()
                await self._optimize_resource_allocation()
                await asyncio.sleep(5)  # æ¯5ç§’ç›‘æ§ä¸€æ¬¡
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(5)
    
    async def _has_available_resources(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨èµ„æº"""
        gpu_status = self.resource_monitor.get_gpu_status()
        cpu_status = self.resource_monitor.get_cpu_status()
        
        # GPUèµ„æºæ£€æŸ¥
        gpu_available = (
            len(self.running_gpu_tasks) < self.max_concurrent_gpu_tasks and
            gpu_status['memory_free'] > 2048 and  # è‡³å°‘2GBç©ºé—²å†…å­˜
            gpu_status['utilization'] < 90
        )
        
        # CPUèµ„æºæ£€æŸ¥
        cpu_available = (
            len(self.running_cpu_tasks) < self.max_concurrent_cpu_tasks and
            cpu_status['utilization'] < 80 and
            cpu_status['memory_percent'] < 85
        )
        
        return gpu_available or cpu_available
    
    async def _get_next_task(self) -> Optional[GPUTask]:
        """è·å–ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„ä»»åŠ¡"""
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é˜Ÿåˆ—
        for priority in [TaskPriority.URGENT, TaskPriority.HIGH, TaskPriority.NORMAL, TaskPriority.LOW]:
            queue = self.task_queues[priority]
            if not queue.empty():
                try:
                    _, _, task = await asyncio.wait_for(queue.get(), timeout=0.1)
                    return task
                except asyncio.TimeoutError:
                    continue
        
        return None
    
    async def _execute_task(self, task: GPUTask):
        """æ‰§è¡Œä»»åŠ¡"""
        task.started_at = time.time()
        task.status = "running"
        
        # å†³å®šä½¿ç”¨GPUè¿˜æ˜¯CPU
        gpu_status = self.resource_monitor.get_gpu_status()
        use_gpu = (
            self.resource_monitor.gpu_available and
            len(self.running_gpu_tasks) < self.max_concurrent_gpu_tasks and
            gpu_status['memory_free'] >= task.gpu_memory_required and
            task.task_type in [TaskType.VIDEO_ENCODE, TaskType.VIDEO_FILTER, TaskType.VIDEO_CONCAT]
        )
        
        if use_gpu:
            self.running_gpu_tasks[task.task_id] = task
            logger.info(f"ğŸš€ GPUæ‰§è¡Œä»»åŠ¡: {task.task_id}")
        else:
            self.running_cpu_tasks[task.task_id] = task
            logger.info(f"ğŸ–¥ï¸ CPUæ‰§è¡Œä»»åŠ¡: {task.task_id}")
        
        # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
        asyncio.create_task(self._run_task_command(task, use_gpu))
    
    async def _run_task_command(self, task: GPUTask, use_gpu: bool):
        """è¿è¡Œä»»åŠ¡å‘½ä»¤"""
        try:
            # æ‰§è¡ŒFFmpegå‘½ä»¤
            process = await asyncio.create_subprocess_exec(
                *task.command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            task.completed_at = time.time()
            
            if process.returncode == 0:
                task.status = "completed"
                self.stats['completed_tasks'] += 1
                logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task.task_id} (è€—æ—¶: {task.completed_at - task.started_at:.1f}s)")
            else:
                task.status = "failed"
                self.stats['failed_tasks'] += 1
                logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task.task_id} - {stderr.decode()}")
            
        except Exception as e:
            task.status = "failed"
            task.completed_at = time.time()
            self.stats['failed_tasks'] += 1
            logger.error(f"âŒ ä»»åŠ¡å¼‚å¸¸: {task.task_id} - {e}")
        
        finally:
            # ä»è¿è¡Œé˜Ÿåˆ—ä¸­ç§»é™¤
            if use_gpu and task.task_id in self.running_gpu_tasks:
                del self.running_gpu_tasks[task.task_id]
            elif task.task_id in self.running_cpu_tasks:
                del self.running_cpu_tasks[task.task_id]
            
            # æ·»åŠ åˆ°å®Œæˆé˜Ÿåˆ—
            self.completed_tasks[task.task_id] = task
    
    async def _update_performance_stats(self):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        if len(self.resource_monitor.gpu_utilization_history) > 0:
            recent_gpu = self.resource_monitor.gpu_utilization_history[-10:]
            self.stats['gpu_utilization_avg'] = sum(h['utilization'] for h in recent_gpu) / len(recent_gpu)
        
        if len(self.resource_monitor.cpu_utilization_history) > 0:
            recent_cpu = self.resource_monitor.cpu_utilization_history[-10:]
            self.stats['cpu_utilization_avg'] = sum(h['utilization'] for h in recent_cpu) / len(recent_cpu)
        
        # è®¡ç®—ååé‡
        if self.stats['total_tasks'] > 0:
            total_time = time.time() - (min(task.created_at for task in self.completed_tasks.values()) if self.completed_tasks else time.time())
            if total_time > 0:
                self.stats['throughput'] = self.stats['completed_tasks'] / total_time
    
    async def _optimize_resource_allocation(self):
        """ä¼˜åŒ–èµ„æºåˆ†é…"""
        gpu_status = self.resource_monitor.get_gpu_status()
        cpu_status = self.resource_monitor.get_cpu_status()
        
        # åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
        if gpu_status['utilization'] < 50 and gpu_status['memory_free'] > 8192:
            # GPUåˆ©ç”¨ç‡ä½ï¼Œå¯ä»¥å¢åŠ å¹¶å‘
            self.max_concurrent_gpu_tasks = min(5, self.max_concurrent_gpu_tasks + 1)
        elif gpu_status['utilization'] > 90 or gpu_status['memory_free'] < 2048:
            # GPUè´Ÿè½½é«˜ï¼Œå‡å°‘å¹¶å‘
            self.max_concurrent_gpu_tasks = max(1, self.max_concurrent_gpu_tasks - 1)
        
        if cpu_status['utilization'] < 60:
            self.max_concurrent_cpu_tasks = min(12, self.max_concurrent_cpu_tasks + 1)
        elif cpu_status['utilization'] > 85:
            self.max_concurrent_cpu_tasks = max(2, self.max_concurrent_cpu_tasks - 1)
    
    def get_status(self) -> Dict:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            'running': self.running,
            'gpu_tasks_running': len(self.running_gpu_tasks),
            'cpu_tasks_running': len(self.running_cpu_tasks),
            'max_concurrent_gpu': self.max_concurrent_gpu_tasks,
            'max_concurrent_cpu': self.max_concurrent_cpu_tasks,
            'stats': self.stats,
            'gpu_status': self.resource_monitor.get_gpu_status(),
            'cpu_status': self.resource_monitor.get_cpu_status()
        }

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
gpu_scheduler = GPUTaskScheduler()
