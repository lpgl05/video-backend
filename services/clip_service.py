import os
# è§†é¢‘ç¼–ç å…¼å®¹æ€§ä¼˜åŒ–
try:
    from services.video_encoding_optimizer import get_optimized_encoding_params, check_video_needs_conversion
    ENCODING_OPTIMIZATION_AVAILABLE = True
    print("âœ… è§†é¢‘ç¼–ç ä¼˜åŒ–åŠŸèƒ½å·²åŠ è½½")
except ImportError as e:
    print(f"âš ï¸ è§†é¢‘ç¼–ç ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨: {e}")
    ENCODING_OPTIMIZATION_AVAILABLE = False

import math
import random
import requests
from uuid import uuid4
from models.oss_client import OSSClient
import subprocess
import re

# å¯¼å…¥æ–°çš„ä¼˜åŒ–æ¨¡å—
from services.ass_subtitle_service import ass_generator
from services.smart_material_cache import smart_cache

# è§†é¢‘ç›¸å…³
from moviepy.video.io.VideoFileClip import VideoFileClip
from moviepy.video.VideoClip import TextClip, ColorClip
from moviepy.editor import CompositeVideoClip, concatenate_videoclips, ImageClip

# éŸ³é¢‘ç›¸å…³
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.audio.AudioClip import AudioClip, CompositeAudioClip, concatenate_audioclips

# æ–°å¢ï¼šä½¿ç”¨ PIL ç”Ÿæˆæ–‡å­—è´´å›¾ï¼Œé¿å… ImageMagick ä¾èµ–
from PIL import Image, ImageDraw, ImageFont
import numpy as np

# è¯­éŸ³åˆæˆ
import edge_tts
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# å›¢é˜Ÿåä½œæ¨¡å¼ï¼šä¿ç•™å¿…è¦çš„å¤„ç†ç›®å½•ï¼Œç§»é™¤uploadsä¾èµ–
DOWNLOAD_VIDEO_PATH = "outputs/download_videos"
DOWNLOAD_AUDIO_PATH = "outputs/download_audios"
OUTPUT_DIR = "outputs/clips"
TTS_TEMP_DIR = "outputs/tts_audio"
SUBTITLE_TEMP_DIR = "outputs/subtitle_images"
OSS_UPLOAD_FINAL_VEDIO = "final/videos"  # OSSå­˜å‚¨è·¯å¾„ï¼Œæ— éœ€æœ¬åœ°uploadså‰ç¼€

# ç¡®ä¿å¤„ç†æ‰€éœ€çš„ä¸´æ—¶ç›®å½•å­˜åœ¨
os.makedirs(DOWNLOAD_VIDEO_PATH, exist_ok=True)
os.makedirs(DOWNLOAD_AUDIO_PATH, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TTS_TEMP_DIR, exist_ok=True)
os.makedirs(SUBTITLE_TEMP_DIR, exist_ok=True)
oss_client = OSSClient()

# å…ˆä».envä¸­è¯»å–å­—ä½“è¦æ±‚
VIDEO_FONT = os.getenv("VIDEO_FONT", "msyh.ttc")
FONT_PATH = os.path.join("fonts", VIDEO_FONT)
print(f'æŒ‡å®šçš„å­—ä½“è·¯å¾„æ˜¯: {FONT_PATH}')

# å­—ä½“æ˜ å°„é…ç½®ï¼šå‰ç«¯å­—ä½“ååˆ°åç«¯å­—ä½“æ–‡ä»¶çš„æ˜ å°„
FONT_MAPPING = {
    'Arial, sans-serif': None,  # ä½¿ç”¨ç³»ç»Ÿé»˜è®¤
    'Microsoft YaHei, sans-serif': 'msyh.ttc',
    'SimSun, serif': 'simsun.ttc',
    'SimHei, sans-serif': 'simhei.ttf',
    'KaiTi, serif': 'simkai.ttf',
    'LIULISONG': 'LIULISONG.ttf',
    'MiaobiJunli': 'å¦™ç¬”çºä¿ä½“.ttf',
    'MiaobiDuanmu': 'å¦™ç¬”æ®µæ…•ä½“.ttf',
    'SourceHanSansCN-Heavy': 'SourceHanSansCN-Heavy.otf',  # æ€æºé»‘ä½“Heavy
}

def get_font_path_from_style(style_config, font_type='title'):
    """æ ¹æ®æ ·å¼é…ç½®è·å–å­—ä½“æ–‡ä»¶è·¯å¾„"""
    if not style_config:
        return FONT_PATH
    
    font_style = style_config.get(font_type, {}) if isinstance(style_config, dict) else {}
    font_family = font_style.get('fontFamily', 'Microsoft YaHei, sans-serif')
    
    print(f'æŸ¥æ‰¾å­—ä½“: {font_family} (ç±»å‹: {font_type})')
    
    # æŸ¥æ‰¾å­—ä½“æ˜ å°„
    font_file = FONT_MAPPING.get(font_family)
    if font_file:
        print(f'å­—ä½“æ˜ å°„æ‰¾åˆ°: {font_file}')
        
        # ä¼˜å…ˆä»å‰ç«¯ç›®å½•è·å–
        frontend_font_path = os.path.join("..", "frontend", "public", "fonts", font_file)
        frontend_font_path = os.path.abspath(frontend_font_path)
        
        if os.path.exists(frontend_font_path):
            print(f'âœ… ä½¿ç”¨å‰ç«¯å­—ä½“: {frontend_font_path}')
            return frontend_font_path
        
        # å¦‚æœå‰ç«¯ä¸å­˜åœ¨ï¼Œå°è¯•æœ¬åœ°fontsç›®å½•
        local_font_path = os.path.join("fonts", font_file)
        local_font_path = os.path.abspath(local_font_path)
        
        if os.path.exists(local_font_path):
            print(f'âœ… ä½¿ç”¨æœ¬åœ°å­—ä½“: {local_font_path}')
            return local_font_path
        
        print(f'âŒ å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰ç«¯è·¯å¾„: {frontend_font_path}')
        print(f'âŒ å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæœ¬åœ°è·¯å¾„: {local_font_path}')
    else:
        print(f'âŒ å­—ä½“æ˜ å°„ä¸­æœªæ‰¾åˆ°: {font_family}')
    
    print(f'ğŸ”„ ä½¿ç”¨é»˜è®¤å­—ä½“: {FONT_PATH}')
    return FONT_PATH

def parse_color(value, default=(0, 0, 0, 200)):
    """
    è¿”å› (r,g,b,a) å››å…ƒç»„ï¼Œa ä¸º 0-255
    æ”¯æŒï¼štuple/list, "#RRGGBB", "#RRGGBBAA", "rgb(...)" / "rgba(...)" / ç®€å•æ•°å­—å­—ç¬¦ä¸²
    """
    if value is None:
        return default
    if isinstance(value, (tuple, list)):
        if len(value) >= 4:
            return (int(value[0]), int(value[1]), int(value[2]), int(value[3]))
        if len(value) == 3:
            return (int(value[0]), int(value[1]), int(value[2]), default[3])
    s = str(value).strip()
    # hex with #
    if s.startswith('#'):
        s = s[1:]
    # hex lengths
    if re.fullmatch(r'[0-9a-fA-F]{6}', s):
        r = int(s[0:2], 16); g = int(s[2:4], 16); b = int(s[4:6], 16); a = default[3]
        return (r, g, b, a)
    if re.fullmatch(r'[0-9a-fA-F]{8}', s):
        r = int(s[0:2], 16); g = int(s[2:4], 16); b = int(s[4:6], 16); a = int(s[6:8], 16)
        return (r, g, b, a)
    # rgb / rgba
    m = re.findall(r'[\d.]+', s)
    if m and (s.lower().startswith('rgb')):
        try:
            nums = [float(x) for x in m]
            if len(nums) >= 3:
                r, g, b = int(nums[0]), int(nums[1]), int(nums[2])
                if len(nums) >= 4:
                    a_val = nums[3]
                    a = int(a_val * 255) if 0 <= a_val <= 1 else int(a_val)
                else:
                    a = default[3]
                return (r, g, b, a)
        except Exception:
            pass
    # fallback: try to parse simple numeric comma-separated
    m = re.findall(r'[\d]+', s)
    if m and len(m) >= 3:
        try:
            nums = [int(x) for x in m]
            r, g, b = nums[0], nums[1], nums[2]
            a = nums[3] if len(nums) >= 4 else default[3]
            return (r, g, b, a)
        except Exception:
            pass
    return default

def get_bg_rgba_from_style(style, section_name, default=(0,0,0,200)):
    """
    ä» style ä¸­æå–èƒŒæ™¯é¢œè‰²å¹¶è¿”å› (r,g,b,a)
    æ”¯æŒå¤šç§ç»“æ„å¹¶å…¼å®¹æ—§å­—æ®µ
    """
    if not style or not isinstance(style, dict):
        return default

    lookups = [style, style.get("style", {})]

    possible_keys = [section_name, section_name + 's']
    for base in lookups:
        if not isinstance(base, dict):
            continue
        section = None
        for k in possible_keys:
            if k in base and isinstance(base[k], dict):
                section = base[k]
                break
        if section is None:
            for k in possible_keys:
                if k in base:
                    section = base[k]
                    break
        if section is None:
            continue

        bg = None
        if isinstance(section, dict):
            bg = section.get("background")
            if isinstance(bg, dict):
                color = bg.get("background_color") or bg.get("color") or bg.get("backgroundColor")
                opacity = bg.get("background_opacity") or bg.get("opacity") or bg.get("alpha")
                if color:
                    a = default[3]
                    if opacity is not None:
                        try:
                            a = int(opacity)
                        except:
                            try:
                                a = int(float(opacity) * 255)
                            except:
                                a = default[3]
                    rgba = parse_color(color, default=(default[0], default[1], default[2], a))
                    return (rgba[0], rgba[1], rgba[2], a)
            if isinstance(bg, (str, tuple, list)):
                opacity = section.get("background_opacity") or section.get("opacity") or None
                if opacity is not None:
                    try:
                        a = int(opacity)
                    except:
                        try:
                            a = int(float(opacity) * 255)
                        except:
                            a = default[3]
                    rgba = parse_color(bg, default=default)
                    return (rgba[0], rgba[1], rgba[2], a)
                else:
                    return parse_color(bg, default=default)

            color_field = section.get("background_color") or section.get("color")
            opacity_field = section.get("background_opacity") or section.get("opacity")
            if color_field:
                a = default[3]
                if opacity_field is not None:
                    try:
                        a = int(opacity_field)
                    except:
                        try:
                            a = int(float(opacity_field) * 255)
                        except:
                            a = default[3]
                rgba = parse_color(color_field, default=(default[0], default[1], default[2], a))
                return (rgba[0], rgba[1], rgba[2], a)

        if isinstance(section, (tuple, list, str)):
            return parse_color(section, default=default)

    return default

def rgba_to_ass_backcolour(rgba):
    """
    å°† (r,g,b,a) è½¬ä¸º ASS/FFmpeg å­—å¹•ä¸­ BackColour è¡¨ç¤ºå½¢å¼ &HAABBGGRR
    """
    r, g, b, a = rgba
    aa = f"{int(a) & 0xff:02x}"
    bb = f"{int(b) & 0xff:02x}"
    gg = f"{int(g) & 0xff:02x}"
    rr = f"{int(r) & 0xff:02x}"
    return f"&H{aa}{bb}{gg}{rr}"

async def download_video(url):
    # å›¢é˜Ÿåä½œæ¨¡å¼ï¼šç»Ÿä¸€ä»OSSä¸‹è½½è§†é¢‘æ–‡ä»¶
    filename = url.split("/")[-1]
    print('---------------------------------------')
    print(url)
    print(filename)

    local_file = DOWNLOAD_VIDEO_PATH + "/" + filename
    print(local_file)
    await oss_client.download_video(url, local_file)
    return local_file

async def download_audio(url):
    # å›¢é˜Ÿåä½œæ¨¡å¼ï¼šç»Ÿä¸€ä»OSSä¸‹è½½éŸ³é¢‘æ–‡ä»¶
    filename = url.split("/")[-1]
    print('---------------------------------------')
    print(f"ä¸‹è½½éŸ³é¢‘: {url}")
    print(f"æ–‡ä»¶å: {filename}")

    local_file = DOWNLOAD_AUDIO_PATH + "/" + filename
    print(f"æœ¬åœ°è·¯å¾„: {local_file}")
    await oss_client.download_video(url, local_file)  # OSSå®¢æˆ·ç«¯åªæœ‰download_videoæ–¹æ³•
    return local_file

async def download_poster(url):
    """ä¸‹è½½æµ·æŠ¥å›¾ç‰‡åˆ°æœ¬åœ°"""
    # å›¢é˜Ÿåä½œæ¨¡å¼ï¼šç»Ÿä¸€ä»OSSä¸‹è½½æµ·æŠ¥æ–‡ä»¶
    filename = url.split("/")[-1]
    
    # ç¡®ä¿æµ·æŠ¥ä¸‹è½½ç›®å½•å­˜åœ¨
    poster_download_path = "downloads/posters"
    os.makedirs(poster_download_path, exist_ok=True)
    
    local_file = os.path.join(poster_download_path, filename)
    print(f"ä¸‹è½½æµ·æŠ¥: {url} -> {local_file}")
    await oss_client.download_video(url, local_file)  # å¤ç”¨ä¸‹è½½æ–¹æ³•
    return local_file

def random_cut(video_path, min_duration, max_duration, count):
    video = VideoFileClip(video_path)
    clips = []
    for _ in range(count):
        max_clip_duration = min(max_duration, int(video.duration) - 1)
        if max_clip_duration < min_duration:
            continue
        duration = random.randint(min_duration, max_clip_duration)
        start = random.uniform(0, video.duration - duration)
        clip = video.subclip(start, start + duration)
        clips.append(clip)
    return clips

def add_text(clip, text, style, font_path=None):
    # ä½¿ç”¨ PIL æ¸²æŸ“æ–‡æœ¬ï¼Œé¿å… TextClip ä¾èµ– ImageMagick
    title_style = style.get("title", {}) if isinstance(style, dict) else {}
    fontsize = int(title_style.get("fontSize", 40))
    
    # å¦‚æœå­—ä½“å¤§å°ä¸º0ï¼Œåˆ™ä¸æ˜¾ç¤ºæ ‡é¢˜
    if fontsize <= 0:
        return clip
        
    color = title_style.get("color", "#FFFFFF")
    position = title_style.get("position", "bottom")  # top | center | bottom

    banner_h = max(60, int(fontsize * 2))  # ç®€å•è®¾å®šé«˜åº¦

    # ä» style è¯»å–èƒŒæ™¯é¢œè‰²ï¼Œå…¼å®¹æ–°æ—§ç»“æ„
    bg_rgba = get_bg_rgba_from_style(style, "title", default=(0,0,0,0))  # é»˜è®¤å®Œå…¨é€æ˜

    img = Image.new("RGBA", (int(clip.w), banner_h), bg_rgba)  # ä½¿ç”¨å¯é…ç½®èƒŒæ™¯
    draw = ImageDraw.Draw(img)

    # ä¼˜å…ˆä½¿ç”¨ä»æ ·å¼é…ç½®ä¸­è·å–çš„å­—ä½“
    if not font_path:
        font_path = get_font_path_from_style(style, 'title')
    
    font = None
    if font_path and os.path.exists(font_path):
        try:
            print(f'ä½¿ç”¨å­—ä½“æ–‡ä»¶: {font_path}')
            font = ImageFont.truetype(font_path, fontsize)
        except Exception as e:
            print(f'åŠ è½½å­—ä½“å¤±è´¥: {e}')
            font = None
    else:
        chinese_fonts = [
            "C:\\Windows\\Fonts\\msyh.ttc",      # å¾®è½¯é›…é»‘
            "C:\\Windows\\Fonts\\simsun.ttc",   # å®‹ä½“
            "C:\\Windows\\Fonts\\simhei.ttf",   # é»‘ä½“
            "C:\\Windows\\Fonts\\simkai.ttf",   # æ¥·ä½“
            "/System/Library/Fonts/PingFang.ttc",  # macOS
            "/System/Library/Fonts/Hiragino Sans GB.ttc",  # macOS
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"  # Linuxå¤‡é€‰
        ]
        for fp in chinese_fonts:
            try:
                font = ImageFont.truetype(fp, fontsize)
                break
            except Exception:
                continue

    if font is None:
        try:
            # å°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼ŒæŒ‡å®šå­—ä½“å¤§å°
            font = ImageFont.load_default()
        except Exception:
            # å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„é»˜è®¤å­—ä½“
            font = ImageFont.load_default()

    # æ–‡æœ¬æ¢è¡Œä»¥é€‚é…å®½åº¦
    max_width = clip.w - 40
    if not text:
        text = ""
    
    # æ”¹è¿›æ–‡æœ¬æ¢è¡Œé€»è¾‘ï¼ŒæŒ‰è¯æˆ–å­—ç¬¦åˆ†å‰²
    lines = []
    words = text.split() if ' ' in text else list(text)  # è‹±æ–‡æŒ‰è¯åˆ†å‰²ï¼Œä¸­æ–‡æŒ‰å­—ç¬¦åˆ†å‰²
    current = ""
    
    for word in words:
        test = current + (" " if current and ' ' in text else "") + word
        try:
            bbox = draw.textbbox((0, 0), test, font=font)
            text_width = bbox[2] - bbox[0]
        except Exception:
            text_width = len(test) * fontsize // 2  # å¤‡é€‰è®¡ç®—æ–¹æ³•
            
        if text_width > max_width and current:
            lines.append(current)
            current = word
        else:
            current = test
    
    if current:
        lines.append(current)
    if not lines:
        lines = [""]  # é˜²æ­¢ç©ºæ–‡æœ¬å¼‚å¸¸

    # å±…ä¸­ç»˜åˆ¶æ–‡æœ¬
    total_height = len(lines) * (fontsize + 4)
    y = max(0, (banner_h - total_height) // 2)
    
    for line in lines:
        try:
            bbox = draw.textbbox((0, 0), line, font=font)
            tw = bbox[2] - bbox[0]
        except Exception:
            tw = len(line) * fontsize // 2  # å¤‡é€‰è®¡ç®—æ–¹æ³•
            
        x = max(0, (clip.w - tw) // 2)
        
        try:
            draw.text((x, y), line, font=font, fill=color)
        except Exception:
            # å¦‚æœç»˜åˆ¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“
            draw.text((x, y), line, fill=color)
            
        y += fontsize + 4

    # ç”Ÿæˆ ImageClip è¦†ç›–åœ¨è§†é¢‘ä¸Š
    banner_clip = ImageClip(np.array(img)).set_duration(clip.duration)
    if position == "top":
        banner_clip = banner_clip.set_position(("center", "top"))
    elif position == "center":
        banner_clip = banner_clip.set_position(("center", "center"))
    else:
        banner_clip = banner_clip.set_position(("center", "bottom"))

    return CompositeVideoClip([clip, banner_clip])

def add_bgm(clip, bgm_path):
    bgm = AudioFileClip(bgm_path).volumex(0.2)
    if bgm.duration < clip.duration:
        bgm = bgm.audio_loop(duration=clip.duration)
    else:
        bgm = bgm.subclip(0, clip.duration)
    final_audio = bgm.set_duration(clip.duration)
    return clip.set_audio(final_audio)

def build_montage_clips(source_paths, target_duration, count):
    """
    ä¸ºæ¯ä¸ªç›®æ ‡è¾“å‡ºæ„å»ºä¸€ä¸ªç”±å¤šä¸ªæºè§†é¢‘ç‰‡æ®µæ‹¼æ¥è€Œæˆçš„çŸ­è§†é¢‘ï¼Œ
    å°½é‡ä¿è¯æ¯ä¸ªè¾“å‡ºéƒ½åŒ…å«æ‰€æœ‰æºè§†é¢‘çš„ä¸€éƒ¨åˆ†ã€‚
    """
    if not source_paths:
        return []

    # é¢„åŠ è½½æºè§†é¢‘ï¼Œé¿å…é‡å¤æ‰“å¼€
    sources = [VideoFileClip(p) for p in source_paths]
    outputs = []

    for _ in range(count):
        remaining = target_duration
        segments = []
        n = len(sources)
        # åŸºç¡€åˆ†é…ï¼šå°½é‡å‡åˆ†ç»™æ¯ä¸ªæºè§†é¢‘
        base_share = max(1, target_duration // max(1, n))

        for idx, src in enumerate(sources):
            if remaining <= 0:
                break
            # å½“å‰æºè§†é¢‘å¯ç”¨æœ€å¤§ç‰‡æ®µæ—¶é•¿ï¼ˆç•™ 0.5s ä½™é‡é¿å…æº¢å‡ºï¼‰
            src_max = max(0, int(src.duration) - 1)
            if src_max <= 0:
                continue

            # æœ€åä¸€ä¸ªæºè§†é¢‘ç”¨å‰©ä½™æ—¶é•¿è¡¥é½
            alloc = base_share if idx < n - 1 else remaining
            seg_dur = min(max(1, int(alloc)), src_max)
            if seg_dur <= 0:
                continue

            start_max = max(0, src.duration - seg_dur - 0.1)
            start = random.uniform(0, start_max) if start_max > 0 else 0
            seg = src.subclip(start, start + seg_dur)
            segments.append(seg)
            remaining -= seg_dur

        # å¦‚æœè¿˜æ²¡å‡‘å¤Ÿç›®æ ‡æ—¶é•¿ï¼Œå¾ªç¯ä»å¯ç”¨æºè§†é¢‘å†è¡¥ç‰‡æ®µ
        safe_guard = 0
        while remaining > 0 and safe_guard < 10 * n:
            safe_guard += 1
            src = random.choice(sources)
            src_max = max(0, int(src.duration) - 1)
            if src_max <= 0:
                continue
            seg_dur = min(max(1, int(remaining)), src_max)
            if seg_dur <= 0:
                continue
            start_max = max(0, src.duration - seg_dur - 0.1)
            start = random.uniform(0, start_max) if start_max > 0 else 0
            seg = src.subclip(start, start + seg_dur)
            segments.append(seg)
            remaining -= seg_dur

        if not segments:
            continue

        # æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ
        final = concatenate_videoclips(segments, method="compose")
        # è¶…å‡ºç›®æ ‡æ—¶é•¿åˆ™è£å‰ª
        if final.duration > target_duration:
            final = final.subclip(0, target_duration)
        outputs.append(final)

    # æ³¨æ„ï¼šsources ç”±è°ƒç”¨æ–¹ç»Ÿä¸€åœ¨å†™æ–‡ä»¶åå…³é—­
    return outputs

def get_rotation(video_path):
    cmd = [
        "ffprobe",
        "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "side_data=displaymatrix",
        "-of", "default=noprint_wrappers=1",
        "-read_intervals", "%+#1",
        video_path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    output = result.stdout

    # æå–çŸ©é˜µ
    lines = [line.strip() for line in output.splitlines() if line.startswith("00000000") or line.startswith("00000001")]
    if len(lines) < 2:
        return 0  # æ²¡æœ‰æ—‹è½¬çŸ©é˜µï¼Œè®¤ä¸º0åº¦

    a, b, _ = map(int, lines[0].split(":")[1].split())
    c, d, _ = map(int, lines[1].split(":")[1].split())

    # Q16 è½¬ä¸ºæµ®ç‚¹
    a /= 65536
    b /= 65536
    c /= 65536
    d /= 65536

    # è®¡ç®—è§’åº¦
    angle = math.degrees(math.atan2(c, a))
    angle = int((angle + 360) % 360)  # è½¬æ¢ä¸º 0~359 åº¦
    return angle

def process_original_video(videos_file):
    # ä½¿ç”¨å‘½ä»¤ ffprobe -v error -select_streams v:0 -show_frames -show_entries frame=pict_type -count_frames -read_intervals "%+#5" video01.mp4
    # å»åˆ¤æ–­ï¼Œå¦‚æœè¿”å›å€¼ä¸­å­˜åœ¨90,åˆ™éœ€è¦å¤„ç†ï¼Œå¦åˆ™ä¸å¤„ç†
    videos_path = []
    for video_file in videos_file:
        video_file_name = os.path.splitext(os.path.basename(video_file))[0]
        # è·å–å…¶æ‰€åœ¨ç›®å½•
        video_file_dir = os.path.dirname(video_file)
        # å¤„ç†åçš„è§†é¢‘åç§°
        xuanzhuan_video = f"{video_file_dir}/{video_file_name}_rotated.mp4"

        ffmpeg_xuanzhuan_cmd = ""
        rotation = get_rotation(video_file)
        match rotation:
            case 0 | 180:
                print(f"è§†é¢‘ {video_file} ä¸éœ€è¦å¤„ç†")
                ffmpeg_xuanzhuan_cmd = f'ffmpeg -hwaccel cuda -i "{video_file}" -vf "hflip,hflip,scale=1080:1920" -c:v h264_nvenc -profile:v main -pix_fmt yuv420p -preset fast -r 30 -c:a copy -metadata:s:v:0 rotate=0 "{xuanzhuan_video}"'
            case 90:
                print(f"è§†é¢‘ {video_file} æ—‹è½¬è§’åº¦ä¸º 90Â° éœ€è¦å¤„ç†")
                ffmpeg_xuanzhuan_cmd = f'ffmpeg -hwaccel cuda -i "{video_file}" -vf "hflip,hflip,scale=1080:1920" -c:v h264_nvenc -profile:v main -pix_fmt yuv420p -preset fast -r 30 -c:a copy -metadata:s:v:0 rotate=0 "{xuanzhuan_video}"'
            case 270:
                print(f"è§†é¢‘ {video_file} æ—‹è½¬è§’åº¦ä¸º 270Â° éœ€è¦å¤„ç†")
                ffmpeg_xuanzhuan_cmd = f'ffmpeg -hwaccel cuda -i "{video_file}" -vf "vflip,vflip,scale=1080:1920" -c:v h264_nvenc -profile:v main -pix_fmt yuv420p -preset fast -r 30 -c:a copy -metadata:s:v:0 rotate=0 "{xuanzhuan_video}"'

        if os.path.exists(xuanzhuan_video):
            # è¯´æ˜è§†é¢‘å·²ç»æ—‹è½¬ï¼Œæ— é¡»å†è¿›è¡Œä¸€æ¬¡æ—‹è½¬
            videos_path.append(f"{xuanzhuan_video}")
            # åˆ é™¤åŸè§†é¢‘
            os.remove(video_file)
        else:
            # æ‰§è¡Œæ—‹è½¬å‘½ä»¤
            rr = subprocess.run(ffmpeg_xuanzhuan_cmd, shell=True)
            if rr.returncode == 0:
                print(f"è§†é¢‘ {video_file} æ—‹è½¬å®Œæˆ")
                videos_path.append(f"{xuanzhuan_video}")
                # åˆ é™¤åŸè§†é¢‘
                os.remove(video_file)
            else:
                print(f"è§†é¢‘ {video_file} æ—‹è½¬å¤±è´¥, ç§»é™¤è¯¥åŸå§‹è§†é¢‘")
    return videos_path

def process_original_video001(videos_file):
    # ä½¿ç”¨å‘½ä»¤ ffprobe -v error -select_streams v:0 -show_frames -show_entries frame=pict_type -count_frames -read_intervals "%+#5" video01.mp4
    # å»åˆ¤æ–­ï¼Œå¦‚æœè¿”å›å€¼ä¸­å­˜åœ¨90,åˆ™éœ€è¦å¤„ç†ï¼Œå¦åˆ™ä¸å¤„ç†
    videos_path = []
    for video_file in videos_file:
        ffprobe_cmd = f"ffprobe -v error -select_streams v:0 -show_frames -show_entries frame=pict_type -count_frames -read_intervals \"%+#3\" {video_file}"
        # æ‰§è¡Œå‘½ä»¤å¹¶è·å–è¿”å›å€¼
        result = subprocess.run(ffprobe_cmd, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            # åˆ¤æ–­è¿”å›å€¼ä¸­æ˜¯å¦å­˜åœ¨90
            if "rotation=90" in result.stdout or "rotation=-90" in result.stdout:
                rotation = "90" if "rotation=90" in result.stdout else "-90"
                print(f"è§†é¢‘ {video_file} æ˜¯ä¸€ä¸ªé¢ å€’è§†é¢‘ (rotation={rotation})")

                video_file_name = os.path.splitext(os.path.basename(video_file))[0]
                # è·å–å…¶æ‰€åœ¨ç›®å½•
                video_file_dir = os.path.dirname(video_file)

                # å¤„ç†åçš„è§†é¢‘åç§°
                xuanzhuan_video = f"{video_file_dir}/{video_file_name}_rotated.mp4"

                if os.path.exists(xuanzhuan_video):
                    # è¯´æ˜è§†é¢‘å·²ç»æ—‹è½¬ï¼Œæ— é¡»å†è¿›è¡Œä¸€æ¬¡æ—‹è½¬
                    videos_path.append(f"{xuanzhuan_video}")
                    # åˆ é™¤åŸè§†é¢‘
                    os.remove(video_file)
                else:
                    if rotation == "90":
                        # è¿›è¡Œ180åº¦æ—‹è½¬
                        # ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œæ—‹è½¬
                        # ffmpeg -hwaccel cuda -i video01.mp4 -vf "hflip,vflip" -c:v hevc_nvenc -pix_fmt p010le -preset fast -c:a copy -metadata:s:v:0 rotate=0 ddd.mp4
                        ffmpeg_xuanzhuan_cmd = f"ffmpeg -hwaccel cuda -i {video_file} -vf \"hflip,vflip\" -c:v hevc_nvenc -pix_fmt p010le -preset fast -c:a copy -metadata:s:v:0 rotate=0 {xuanzhuan_video}"
                    else:
                        # rotation == "-90"
                        # è¿›è¡Œ180åº¦æ—‹è½¬
                        # ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œæ—‹è½¬
                        # ffmpeg -hwaccel cuda -i video01.mp4 -vf "vflip,hflip" -c:v hevc_nvenc -pix_fmt p010le -preset fast -c:a copy -metadata:s:v:0 rotate=0 ddd.mp4
                        ffmpeg_xuanzhuan_cmd = f"ffmpeg -hwaccel cuda -i {video_file} -vf \"hflip,hflip\" -c:v hevc_nvenc -pix_fmt p010le -preset fast -c:a copy -metadata:s:v:0 rotate=0 {xuanzhuan_video}"
                    # æ‰§è¡Œæ—‹è½¬å‘½ä»¤
                    rr = subprocess.run(ffmpeg_xuanzhuan_cmd, shell=True)
                    if rr.returncode == 0:
                        print(f"è§†é¢‘ {video_file} æ—‹è½¬å®Œæˆ")
                        videos_path.append(f"{xuanzhuan_video}")
                        # åˆ é™¤åŸè§†é¢‘
                        os.remove(video_file)
                    else:
                        print(f"è§†é¢‘ {video_file} æ—‹è½¬å¤±è´¥, ç§»é™¤è¯¥åŸå§‹è§†é¢‘")
            else:
                print(f"è§†é¢‘ {video_file} ä¸éœ€è¦å¤„ç†")
                videos_path.append(video_file)
        else:
            print(f"ffprobe å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")

    return videos_path
    
def add_bgm_with_tts(clip, bgm_path, tts_audio_path):
    """
    æ·»åŠ BGMå’ŒTTSè¯­éŸ³ï¼Œä¸¤è€…æ··åˆæ’­æ”¾
    
    Args:
        clip: è§†é¢‘ç‰‡æ®µ
        bgm_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
        tts_audio_path: TTSè¯­éŸ³æ–‡ä»¶è·¯å¾„
    """
    try:
        # åŠ è½½TTSè¯­éŸ³
        tts_audio = AudioFileClip(tts_audio_path)
        
        # åŠ è½½BGMå¹¶é™ä½éŸ³é‡
        bgm = AudioFileClip(bgm_path).volumex(0.15)  # é™ä½BGMéŸ³é‡ä»¥çªå‡ºè¯­éŸ³
        
        # è°ƒæ•´TTSè¯­éŸ³éŸ³é‡
        tts_audio = tts_audio.volumex(0.8)
        
        # å¦‚æœBGMæ—¶é•¿å°äºè§†é¢‘æ—¶é•¿ï¼Œå¾ªç¯æ’­æ”¾
        if bgm.duration < clip.duration:
            bgm = bgm.audio_loop(duration=clip.duration)
        else:
            bgm = bgm.subclip(0, clip.duration)
        
        # å¦‚æœTTSæ—¶é•¿å°äºè§†é¢‘æ—¶é•¿ï¼Œåœ¨å¼€å¤´æ’­æ”¾TTSï¼Œå‰©ä½™æ—¶é—´åªæœ‰BGM
        if tts_audio.duration < clip.duration:
            # åˆ›å»ºé™éŸ³å¡«å……
            silence_duration = clip.duration - tts_audio.duration
            silence = AudioClip(lambda t: [0, 0], duration=silence_duration)
            tts_audio = concatenate_audioclips([tts_audio, silence])
        else:
            # å¦‚æœTTSæ›´é•¿ï¼Œæˆªå–åˆ°è§†é¢‘é•¿åº¦
            tts_audio = tts_audio.subclip(0, clip.duration)
        
        # æ··åˆä¸¤ä¸ªéŸ³é¢‘è½¨é“
        final_audio = CompositeAudioClip([bgm, tts_audio])
        final_audio = final_audio.set_duration(clip.duration)
        
        return clip.set_audio(final_audio)
        
    except Exception as e:
        print(f"éŸ³é¢‘æ··åˆå¤±è´¥: {e}")
        # å¦‚æœæ··åˆå¤±è´¥ï¼Œè‡³å°‘ä¿ç•™åŸBGM
        return add_bgm(clip, bgm_path)


def parse_duration(duration_str):
    # æ”¯æŒ '15s' | '30s' | '30-60s'
    if not duration_str:
        return 30
    s = duration_str.strip().lower()
    if s.endswith('s'):
        s = s[:-1]
    if '-' in s:
        try:
            a, b = s.split('-', 1)
            lo, hi = int(a), int(b)
            if lo > hi:
                lo, hi = hi, lo
            return random.randint(lo, hi)
        except Exception:
            return 30
    try:
        return int(s)
    except Exception:
        return 30

def load_font_for_title(title_config, style, title_type='title'):
    """ä¸ºæ ‡é¢˜åŠ è½½å­—ä½“"""
    font_size = title_config.get("fontSize", 64)
    font_family = title_config.get("fontFamily")
    
    # å°è¯•ä»é…ç½®ä¸­è·å–å­—ä½“è·¯å¾„
    font_path = None
    if font_family:
        font_path = get_font_path_from_style({title_type: {"fontFamily": font_family}}, title_type)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»styleä¸­è·å–
    if not font_path:
        font_path = get_font_path_from_style(style, title_type)
    
    font = None
    if font_path and os.path.exists(font_path):
        try:
            print(f'æ ‡é¢˜ä½¿ç”¨å­—ä½“æ–‡ä»¶: {font_path}')
            font = ImageFont.truetype(font_path, font_size)
        except Exception as e:
            print(f'æ ‡é¢˜å­—ä½“åŠ è½½å¤±è´¥: {e}')
            font = None
    
    if font is None:
        # å›é€€åˆ°ç³»ç»Ÿå­—ä½“
        chinese_fonts = [
            "C:\\Windows\\Fonts\\msyh.ttc",
            "C:\\Windows\\Fonts\\simsun.ttc",
            "/System/Library/Fonts/PingFang.ttc",
            "/usr/share/fonts/winfonts/msyh.ttc"
        ]
        
        for fp in chinese_fonts:
            try:
                font = ImageFont.truetype(fp, font_size)
                break
            except:
                continue
    
    if font is None:
        font = ImageFont.load_default()
    
    return font

def wrap_text_for_title(text, font, max_width):
    """æ–‡æœ¬æ¢è¡Œå¤„ç†"""
    lines = []
    current_line = ""
    
    # åˆ›å»ºä¸´æ—¶drawå¯¹è±¡ç”¨äºæµ‹é‡
    temp_img = Image.new("RGBA", (max_width + 200, 100), (0, 0, 0, 0))
    temp_draw = ImageDraw.Draw(temp_img)
    
    for char in text:
        test_line = current_line + char
        try:
            bbox = temp_draw.textbbox((0, 0), test_line, font=font)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(test_line) * (font.size // 2)
            
        if text_width > max_width and current_line:
            lines.append(current_line)
            current_line = char
        else:
            current_line = test_line
    
    if current_line:
        lines.append(current_line)
    
    # é™åˆ¶è¡Œæ•°
    lines = lines[:2]
    return lines

def calculate_text_x_position(draw, text, font, target_width, alignment):
    """è®¡ç®—æ–‡æœ¬çš„Xä½ç½®"""
    try:
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
    except:
        text_width = len(text) * (font.size // 2)
    
    if alignment == "left":
        return 60  # å·¦è¾¹è·
    elif alignment == "right":
        return target_width - text_width - 60  # å³è¾¹è·
    else:  # center
        return (target_width - text_width) // 2

def draw_text_with_effects(draw, text, font, x, y, color, title_config):
    """ç»˜åˆ¶å¸¦æ•ˆæœçš„æ–‡æœ¬"""
    # ç»˜åˆ¶é˜´å½±
    if title_config.get("shadow"):
        shadow_color = title_config.get("shadowColor", "#000000")
        draw.text((x+2, y+2), text, font=font, fill=shadow_color)
    
    # ç»˜åˆ¶æè¾¹
    if title_config.get("strokeColor") and title_config.get("strokeWidth", 0) > 0:
        stroke_width = title_config.get("strokeWidth", 1)
        stroke_color = title_config.get("strokeColor", "#000000")
        
        # ç®€å•æè¾¹å®ç°
        for dx in range(-stroke_width, stroke_width + 1):
            for dy in range(-stroke_width, stroke_width + 1):
                if dx != 0 or dy != 0:
                    draw.text((x + dx, y + dy), text, font=font, fill=stroke_color)
    
    # ç»˜åˆ¶ä¸»æ–‡å­—
    draw.text((x, y), text, font=font, fill=color)

def create_title_image(text, width=1080, height=1920, style=None):
    """ç”Ÿæˆæ ‡é¢˜å­—å¹•å›¾ç‰‡ - æ”¯æŒä¸»å‰¯æ ‡é¢˜"""
    if not style:
        style = {}
    
    title_config = style.get("title", {})
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»å‰¯æ ‡é¢˜é…ç½®
    main_title = title_config.get("mainTitle")
    sub_title = title_config.get("subTitle")
    
    # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ä¸»å‰¯æ ‡é¢˜é…ç½®ï¼Œä½†æœ‰æ—§çš„é…ç½®æ–¹å¼
    if not main_title and not sub_title:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—§çš„titleé…ç½®
        if title_config.get("fontSize") and title_config.get("fontSize", 0) > 0:
            # ä½¿ç”¨æ—§çš„é€ä¸ªå±æ€§ä½œä¸ºä¸»æ ‡é¢˜
            main_title = {
                "text": text or "",
                "fontSize": title_config.get("fontSize", 64),
                "color": title_config.get("color", "#000000"),
                "fontFamily": title_config.get("fontFamily"),
                "bold": title_config.get("bold", False),
                "italic": title_config.get("italic", False)
            }
        elif text:  # å¦‚æœåªæœ‰textå‚æ•°ï¼Œä¹Ÿä½œä¸ºä¸»æ ‡é¢˜å¤„ç†
            main_title = {
                "text": text,
                "fontSize": title_config.get("fontSize", 64),
                "color": title_config.get("color", "#000000"),
                "fontFamily": title_config.get("fontFamily")
            }
    
    # å¦‚æœæ²¡æœ‰ä»»ä½•å¯æ˜¾ç¤ºçš„æ ‡é¢˜ï¼Œè¿”å›é€æ˜å›¾ç‰‡
    main_text = main_title.get("text", "") if main_title else ""
    main_font_size = main_title.get("fontSize", 0) if main_title else 0
    sub_text = sub_title.get("text", "") if sub_title else ""
    sub_font_size = sub_title.get("fontSize", 0) if sub_title else 0
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•éœ€è¦æ¸²æŸ“çš„å†…å®¹
    has_main_title = main_title and main_text and main_font_size > 0
    has_sub_title = sub_title and sub_text and sub_font_size > 0
    has_legacy_title = not has_main_title and not has_sub_title and text and title_config.get("fontSize", 0) > 0
    
    if not has_main_title and not has_sub_title and not has_legacy_title:
        # åˆ›å»º1x1é€æ˜å›¾ç‰‡
        img = Image.new("RGBA", (1, 1), (0, 0, 0, 0))
        return img
    
    # è®¡ç®—å®é™…éœ€è¦çš„æ¨ªå¹…å°ºå¯¸
    target_width = 1080  # è§†é¢‘å®½åº¦
    
    # å¦‚æœæ˜¯æ—§ç‰ˆæœ¬å…¼å®¹æ¨¡å¼ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
    if has_legacy_title:
        fontsize = int(title_config.get("fontSize", 64))
        color = title_config.get("color", "#FFD700")
        return create_legacy_title_image(text, target_width, style, fontsize, color)
    
    # æ–°çš„ä¸»å‰¯æ ‡é¢˜æ¸²æŸ“é€»è¾‘
    spacing = title_config.get("spacing", 1)  # ä¸»å‰¯æ ‡é¢˜ä¹‹é—´çš„é—´è·
    alignment = title_config.get("alignment", "center")  # å¯¹é½æ–¹å¼
    
    # è®¡ç®—æ¯ä¸ªæ ‡é¢˜çš„å°ºå¯¸å’Œæ–‡æœ¬è¡Œ
    main_title_info = None
    sub_title_info = None
    
    if has_main_title:
        main_title_info = calculate_title_layout(main_text, main_font_size, target_width, main_title, style)
        
    if has_sub_title:
        sub_title_info = calculate_title_layout(sub_text, sub_font_size, target_width, sub_title, style)
    
    # è®¡ç®—æ€»é«˜åº¦
    total_height = 0
    padding_vertical = 60  # ä¸Šä¸‹å†…è¾¹è·
    
    if main_title_info:
        total_height += main_title_info['height']
        
    if sub_title_info:
        if main_title_info:
            total_height += spacing  # ä¸»å‰¯æ ‡é¢˜ä¹‹é—´çš„é—´è·
        total_height += sub_title_info['height']
    
    total_height += padding_vertical
    total_height = max(140, total_height)  # æœ€å°é«˜åº¦
    
    print(f"ä¸»å‰¯æ ‡é¢˜è®¡ç®—: ä¸»æ ‡é¢˜é«˜åº¦={main_title_info['height'] if main_title_info else 0}, å‰¯æ ‡é¢˜é«˜åº¦={sub_title_info['height'] if sub_title_info else 0}, é—´è·={spacing}, æ€»é«˜åº¦={total_height}")
    
    # åˆ›å»ºå›¾ç‰‡
    bg_rgba = get_bg_rgba_from_style(style, "title", default=(0,0,0,0))
    img = Image.new("RGBA", (target_width, total_height), bg_rgba)
    draw = ImageDraw.Draw(img)
    
    # å¼€å§‹ç»˜åˆ¶
    current_y = padding_vertical // 2  # ä»ä¸Šè¾¹è·å¼€å§‹
    
    # ç»˜åˆ¶ä¸»æ ‡é¢˜
    if main_title_info:
        current_y = draw_title_text(draw, main_title_info, target_width, current_y, alignment)
        if sub_title_info:
            current_y += spacing  # æ·»åŠ é—´è·
    
    # ç»˜åˆ¶å‰¯æ ‡é¢˜
    if sub_title_info:
        draw_title_text(draw, sub_title_info, target_width, current_y, alignment)
    
    return img


def create_legacy_title_image(text, target_width, style, fontsize, color):
    """åˆ›å»ºæ—§ç‰ˆæœ¬å…¼å®¹çš„æ ‡é¢˜å›¾ç‰‡"""
    # è·å–å­—ä½“
    font = load_font_for_title({'fontSize': fontsize}, style, 'title')
    
    # æ–‡æœ¬æ¢è¡Œ
    max_width = target_width - 120
    lines = wrap_text_for_title(text, font, max_width)
    lines = lines[:2]  # æœ€å¤š2è¡Œ
    
    # è®¡ç®—é«˜åº¦
    line_height = fontsize + 20
    text_total_height = len(lines) * line_height
    padding_vertical = 60
    banner_h = max(140, text_total_height + padding_vertical)
    
    # åˆ›å»ºå›¾ç‰‡
    bg_rgba = get_bg_rgba_from_style(style, "title", default=(0,0,0,0))
    img = Image.new("RGBA", (target_width, banner_h), bg_rgba)
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶æ–‡æœ¬
    start_y = (banner_h - text_total_height) // 2
    for line in lines:
        try:
            bbox = draw.textbbox((0, 0), line, font=font)
            tw = bbox[2] - bbox[0]
        except:
            tw = len(line) * fontsize // 2
            
        x = (target_width - tw) // 2
        try:
            draw.text((x+2, start_y+2), line, font=font, fill=(0, 0, 0, 128))  # é˜´å½±
            draw.text((x, start_y), line, font=font, fill=color)  # ä¸»æ–‡å­—
        except:
            draw.text((x, start_y), line, fill=color)
        start_y += line_height
    
    return img


def calculate_title_layout(text, font_size, target_width, title_config, style):
    """è®¡ç®—å•ä¸ªæ ‡é¢˜çš„å¸ƒå±€ä¿¡æ¯"""
    font = load_font_for_title(title_config, style, 'title')
    max_width = target_width - 120  # å·¦å³è¾¹è·
    lines = wrap_text_for_title(text, font, max_width)
    lines = lines[:2]  # æœ€å¤š2è¡Œ
    
    line_height = font_size + 20
    height = len(lines) * line_height
    
    return {
        'text': text,
        'lines': lines,
        'font': font,
        'font_size': font_size,
        'color': title_config.get('color', '#000000'),
        'height': height,
        'line_height': line_height,
        'letter_spacing': title_config.get('letterSpacing', 0)  # æ·»åŠ å­—é—´è·å‚æ•°
    }


def draw_title_text(draw, title_info, target_width, start_y, alignment):
    """ç»˜åˆ¶å•ä¸ªæ ‡é¢˜çš„æ–‡æœ¬ï¼Œæ”¯æŒå­—é—´è·"""
    current_y = start_y
    letter_spacing = title_info.get('letter_spacing', 0)  # è·å–å­—é—´è·
    
    for line in title_info['lines']:
        if letter_spacing != 0:
            # æœ‰å­—é—´è·æ—¶ï¼Œæ‰‹åŠ¨ç»˜åˆ¶æ¯ä¸ªå­—ç¬¦
            total_width = 0
            char_widths = []
            
            # å…ˆè®¡ç®—æ¯ä¸ªå­—ç¬¦çš„å®½åº¦
            for char in line:
                try:
                    bbox = draw.textbbox((0, 0), char, font=title_info['font'])
                    char_width = bbox[2] - bbox[0]
                except:
                    char_width = title_info['font_size'] // 2
                char_widths.append(char_width)
                total_width += char_width
            
            # è®¡ç®—æ€»å®½åº¦ï¼ˆåŒ…æ‹¬å­—é—´è·ï¼‰
            if len(line) > 1:
                total_width += (len(line) - 1) * letter_spacing
            
            # æ ¹æ®å¯¹é½æ–¹å¼è®¡ç®—èµ·å§‹xä½ç½®
            if alignment == 'left':
                x = 60  # å·¦è¾¹è·
            elif alignment == 'right':
                x = target_width - total_width - 60  # å³è¾¹è·
            else:  # center
                x = (target_width - total_width) // 2
            
            # ç»˜åˆ¶æ¯ä¸ªå­—ç¬¦
            current_x = x
            for i, char in enumerate(line):
                try:
                    # æ·»åŠ é˜´å½±æ•ˆæœ
                    draw.text((current_x+2, current_y+2), char, font=title_info['font'], fill=(0, 0, 0, 128))
                    draw.text((current_x, current_y), char, font=title_info['font'], fill=title_info['color'])
                except:
                    draw.text((current_x, current_y), char, fill=title_info['color'])
                
                # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå­—ç¬¦ä½ç½®
                current_x += char_widths[i] + letter_spacing
        else:
            # æ²¡æœ‰å­—é—´è·æ—¶ï¼Œä½¿ç”¨åŸæ¥çš„æ–¹æ³•
            try:
                bbox = draw.textbbox((0, 0), line, font=title_info['font'])
                tw = bbox[2] - bbox[0]
            except:
                tw = len(line) * title_info['font_size'] // 2
            
            # æ ¹æ®å¯¹é½æ–¹å¼è®¡ç®—xä½ç½®
            if alignment == 'left':
                x = 60  # å·¦è¾¹è·
            elif alignment == 'right':
                x = target_width - tw - 60  # å³è¾¹è·
            else:  # center
                x = (target_width - tw) // 2
            
            try:
                # æ·»åŠ é˜´å½±æ•ˆæœ
                draw.text((x+2, current_y+2), line, font=title_info['font'], fill=(0, 0, 0, 128))
                draw.text((x, current_y), line, font=title_info['font'], fill=title_info['color'])
            except:
                draw.text((x, current_y), line, fill=title_info['color'])
        
        current_y += title_info['line_height']
    
    return current_y

def create_subtitle_image(text, width=480, height=854, style=None):
    """ç”Ÿæˆå­—å¹•å›¾ç‰‡ - åªç”Ÿæˆå­—å¹•æ¨ªå¹…å¤§å°çš„å›¾ç‰‡"""
    if not text:
        # åˆ›å»º1x1é€æ˜å›¾ç‰‡
        img = Image.new("RGBA", (1, 1), (0, 0, 0, 0))
        return img
    
    subtitle_style = style.get("subtitle", {}) if style else {}
    fontsize = int(subtitle_style.get("fontSize", 48))
    color = subtitle_style.get("color", "#FFFFFF")
    
    # è®¡ç®—å®é™…éœ€è¦çš„æ¨ªå¹…å°ºå¯¸
    target_width = 1080  # è§†é¢‘å®½åº¦
    
    # å…ˆåˆ›å»ºä¸´æ—¶ç”»å¸ƒæ¥è®¡ç®—å®é™…éœ€è¦çš„é«˜åº¦
    temp_img = Image.new("RGBA", (target_width, 500), (0, 0, 0, 0))
    temp_draw = ImageDraw.Draw(temp_img)
    
    # ä½¿ç”¨ä»æ ·å¼é…ç½®ä¸­è·å–çš„å­—ä½“
    font_path = get_font_path_from_style(style, 'subtitle')
    font = None
    if font_path and os.path.exists(font_path):
        try:
            print(f'å­—å¹•ä½¿ç”¨å­—ä½“æ–‡ä»¶: {font_path}')
            font = ImageFont.truetype(font_path, fontsize)
        except Exception as e:
            print(f'å­—å¹•å­—ä½“åŠ è½½å¤±è´¥: {e}')
            font = None
    else:
        chinese_fonts = [
            "C:\\Windows\\Fonts\\msyh.ttc",      # å¾®è½¯é›…é»‘
            "C:\\Windows\\Fonts\\simsun.ttc",   # å®‹ä½“
            "C:\\Windows\\Fonts\\simhei.ttf",   # é»‘ä½“
            "C:\\Windows\\Fonts\\simkai.ttf",   # æ¥·ä½“
            "/System/Library/Fonts/PingFang.ttc",  # macOS
            "/System/Library/Fonts/Hiragino Sans GB.ttc",  # macOS
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"  # Linuxå¤‡é€‰
        ]
        for fp in chinese_fonts:
            try:
                font = ImageFont.truetype(fp, fontsize)
                break
            except Exception:
                continue

    if font is None:
        try:
            # å°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼ŒæŒ‡å®šå­—ä½“å¤§å°
            font = ImageFont.load_default()
        except Exception:
            # å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„é»˜è®¤å­—ä½“
            font = ImageFont.load_default()

    # æ–‡æœ¬æ¢è¡Œ
    max_width = target_width - 80  # å·¦å³å„ç•™40åƒç´ è¾¹è·
    lines = []
    current_line = ""
    
    for char in text:
        test_line = current_line + char
        try:
            bbox = temp_draw.textbbox((0, 0), test_line, font=font)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(test_line) * fontsize // 2
            
        if text_width > max_width and current_line:
            lines.append(current_line)
            current_line = char
        else:
            current_line = test_line
    
    if current_line:
        lines.append(current_line)
    
    # é™åˆ¶è¡Œæ•°
    lines = lines[:3]
    
    # è®¡ç®—å®é™…éœ€è¦çš„é«˜åº¦
    line_height = fontsize + 16  # æ¯è¡Œé«˜åº¦å¢åŠ é—´è·
    text_total_height = len(lines) * line_height
    padding_vertical = 40  # ä¸Šä¸‹å„20åƒç´ å†…è¾¹è·
    banner_h = text_total_height + padding_vertical
    
    # ç¡®ä¿æœ€å°é«˜åº¦
    banner_h = max(120, banner_h)  # æœ€å°120åƒç´ é«˜åº¦
    
    print(f"å­—å¹•è®¡ç®—: å­—ä½“={fontsize}, è¡Œæ•°={len(lines)}, æ¨ªå¹…é«˜åº¦={banner_h}")

    # åˆ›å»ºå®é™…çš„å­—å¹•æ¨ªå¹…ï¼ŒèƒŒæ™¯ä½¿ç”¨å¯é…ç½®é¢œè‰²
    bg_rgba = get_bg_rgba_from_style(style, "subtitle", default=(0,0,0,0))  # é»˜è®¤å®Œå…¨é€æ˜
    img = Image.new("RGBA", (target_width, banner_h), bg_rgba)  # ä½¿ç”¨å¯é…ç½®èƒŒæ™¯
    draw = ImageDraw.Draw(img)

    # ç»˜åˆ¶æ–‡æœ¬ï¼Œå‚ç›´å±…ä¸­
    start_y = (banner_h - text_total_height) // 2
    
    for line in lines:
        try:
            bbox = draw.textbbox((0, 0), line, font=font)
            tw = bbox[2] - bbox[0]
        except:
            tw = len(line) * fontsize // 2
            
        x = (target_width - tw) // 2  # å±…ä¸­
        try:
            draw.text((x, start_y), line, font=font, fill=color)
        except:
            draw.text((x, start_y), line, fill=color)
        start_y += line_height

    return img

async def generate_tts_audio(text: str, output_path: str, voice: str = "zh-CN-XiaoxiaoNeural"):
    """ä½¿ç”¨ edge_tts ç”Ÿæˆè¯­éŸ³æ–‡ä»¶"""
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_path)
        print(f"TTSéŸ³é¢‘ç”Ÿæˆå®Œæˆ: {output_path}, {voice}")
    except Exception as e:
        print(f"TTSç”Ÿæˆå¤±è´¥: {e}")
        raise Exception("è¯­éŸ³åˆæˆå¤±è´¥")

def create_9_16_video_with_title_ffmpeg(source_video, title_image, subtitle_image, tts_audio, bgm_audio, output_path, duration, title_position="top", subtitle_position="bottom", poster_image=None, use_gpu=True):
    """ä½¿ç”¨FFmpegåˆ›å»º9:16è§†é¢‘ï¼ŒåŒ…å«æ¨¡ç³ŠèƒŒæ™¯ã€Titleã€Subtitleå’ŒéŸ³é¢‘æ··åˆ"""
    ffmpeg = find_ffmpeg()
    
    target_width = 1080
    target_height = 1920
    
    # è®¡ç®—Titleä½ç½®
    title_margin = 200
    if title_position == "top":
        title_overlay_y = title_margin
        title_desc = "é¡¶éƒ¨"
    elif title_position == "center":
        title_overlay_y = f"(H-h)/2-100"  # ç¨å¾®åä¸Šä¸€äº›
        title_desc = "ä¸­éƒ¨"
    else:  # bottom
        title_overlay_y = f"H-h-{title_margin}"
        title_desc = "åº•éƒ¨"
    
    # è®¡ç®—Subtitleä½ç½®
    subtitle_margin = 250
    if subtitle_position == "top":
        subtitle_overlay_y = subtitle_margin
        subtitle_overlay_x = "0"
        subtitle_desc = "é¡¶éƒ¨"
    elif subtitle_position == "center":
        subtitle_overlay_y = f"(H-h)/2+100"  # ç¨å¾®åä¸‹ä¸€äº›
        subtitle_overlay_x = "0"
        subtitle_desc = "ä¸­éƒ¨"
    elif subtitle_position == "template1":
        # æ¨¡æ¿ä½ç½®1ï¼šè·ä¸Šè¾¹æ¡†1372.4åƒç´  - éœ€è¦è€ƒè™‘å­—å¹•å›¾ç‰‡å†…éƒ¨çš„åç§»
        # å­—å¹•å›¾ç‰‡æœ‰ä¸Šä¸‹40åƒç´ çš„paddingï¼Œæ–‡å­—åœ¨å›¾ç‰‡ä¸­å¿ƒï¼Œæ‰€ä»¥éœ€è¦å‘ä¸Šè°ƒæ•´
        subtitle_overlay_y = str(1372.4 - 60)  # å‡å»å­—å¹•å›¾ç‰‡é«˜åº¦çš„ä¸€åŠï¼Œè®©æ–‡å­—ä¸­å¿ƒåœ¨1372.4ä½ç½®
        subtitle_overlay_x = "0"  # æ¨¡æ¿ä½ç½®1ï¼šæ°´å¹³å±…ä¸­ï¼ˆX=0è¡¨ç¤ºå±…ä¸­ï¼‰
        subtitle_desc = "æ¨¡æ¿ä½ç½®1"
    else:  # bottom
        subtitle_overlay_y = f"H-h-{subtitle_margin}"
        subtitle_overlay_x = "0"
        subtitle_desc = "åº•éƒ¨"
    
    print(f"Titleä½ç½®è®¾ç½®: {title_desc} (overlay_y={title_overlay_y})")
    print(f"Subtitleä½ç½®è®¾ç½®: {subtitle_desc} (overlay_y={subtitle_overlay_y})")
    print(f"æµ·æŠ¥èƒŒæ™¯: {'å¯ç”¨' if poster_image else 'æœªå¯ç”¨'}")
    
    # æ ¹æ®æ˜¯å¦æœ‰æµ·æŠ¥èƒŒæ™¯é€‰æ‹©ä¸åŒçš„æ»¤é•œé“¾
    if poster_image and poster_image != "":
        # æœ‰æµ·æŠ¥èƒŒæ™¯ï¼šæµ·æŠ¥ä½œä¸ºèƒŒæ™¯ï¼Œæºè§†é¢‘ä½œä¸ºå‰æ™¯
        filter_complex = f"""
        [5:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}[bg];
        [0:v]scale={target_width}:-1[fg_scale];
        [fg_scale]scale={target_width}:{target_width*9//16}[fg];
        [bg][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];
        [1:v]format=rgba[title];
        [2:v]format=rgba[subtitle];
        [bg_with_fg][title]overlay=0:{title_overlay_y}:format=auto[bg_with_title];
        [bg_with_title][subtitle]overlay={subtitle_overlay_x}:{subtitle_overlay_y}:format=auto,format=yuv420p[video_out];
        [3:a]volume=0.8[tts];
        [4:a]volume=0.15[bgm];
        [tts][bgm]amix=inputs=2:duration=first:dropout_transition=0[audio_out]
        """
        
        # å°†æºè§†é¢‘å¾ªç¯è¾“å…¥ï¼Œå›¾ç‰‡è¾“å…¥ä½œä¸º looped é™æ€å¸§æµï¼ŒéŸ³é¢‘åœ¨æ»¤é•œé‡Œè¢« trim
        cmd = [
            ffmpeg, '-y',
            '-hwaccel', 'cuda',                            # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
            '-hwaccel_output_format', 'cuda',              # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
            '-c:v', 'h264_cuvid',                          # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
            '-stream_loop', '-1', '-i', source_video,      # è¾“å…¥0: æºè§†é¢‘ï¼ˆå¾ªç¯ï¼‰
            '-loop', '1', '-i', title_image,               # è¾“å…¥1: Titleå›¾ç‰‡ï¼ˆloopï¼‰
            '-loop', '1', '-i', subtitle_image,            # è¾“å…¥2: Subtitleå›¾ç‰‡ï¼ˆloopï¼‰
            '-i', tts_audio,                               # è¾“å…¥3: TTSéŸ³é¢‘
            '-i', bgm_audio,                               # è¾“å…¥4: BGMéŸ³é¢‘
            '-loop', '1', '-i', poster_image,              # è¾“å…¥5: æµ·æŠ¥èƒŒæ™¯ï¼ˆloopï¼‰
            '-filter_complex', filter_complex,
            '-map', '[video_out]',                         # æ˜ å°„è§†é¢‘æµ
            '-map', '[audio_out]',                         # æ˜ å°„éŸ³é¢‘æµ
            '-t', str(duration),                           # è®¾ç½®æ—¶é•¿ï¼ˆå¼ºåˆ¶è¾“å‡ºæ—¶é•¿ï¼‰
            *get_gpu_encoding_params(use_gpu, 'balanced'), # GPUåŠ é€Ÿç¼–ç å‚æ•°
            '-c:a', 'aac',
            '-b:a', '192k',
            '-movflags', '+faststart',
            output_path
        ]
    else:
        # æ— æµ·æŠ¥èƒŒæ™¯ï¼šä½¿ç”¨åŸé€»è¾‘ï¼ˆæ¨¡ç³Šæºè§†é¢‘ä½œä¸ºèƒŒæ™¯ï¼‰
        filter_complex = f"""
        [0:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}[bg];
        [bg]boxblur=luma_radius=50:chroma_radius=50:luma_power=3[bg_blur];
        [0:v]scale={target_width}:-1[fg_scale];
        [fg_scale]scale={target_width}:{target_width*9//16}[fg];
        [bg_blur][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];
        [1:v]format=rgba[title];
        [2:v]format=rgba[subtitle];
        [bg_with_fg][title]overlay=0:{title_overlay_y}:format=auto[bg_with_title];
        [bg_with_title][subtitle]overlay={subtitle_overlay_x}:{subtitle_overlay_y}:format=auto,format=yuv420p[video_out];
        [3:a]volume=0.8[tts];
        [4:a]volume=0.15[bgm];
        [tts][bgm]amix=inputs=2:duration=first:dropout_transition=0[audio_out]
        """
        
        cmd = [
            ffmpeg, '-y',
            '-hwaccel', 'cuda',                            # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
            '-hwaccel_output_format', 'cuda',              # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
            '-c:v', 'h264_cuvid',                          # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
            '-stream_loop', '-1', '-i', source_video,      # è¾“å…¥0: æºè§†é¢‘ï¼ˆå¾ªç¯ï¼‰
            '-loop', '1', '-i', title_image,               # è¾“å…¥1: Titleå›¾ç‰‡ï¼ˆloopï¼‰
            '-loop', '1', '-i', subtitle_image,            # è¾“å…¥2: Subtitleå›¾ç‰‡ï¼ˆloopï¼‰
            '-i', tts_audio,                               # è¾“å…¥3: TTSéŸ³é¢‘
            '-i', bgm_audio,                               # è¾“å…¥4: BGMéŸ³é¢‘
            '-filter_complex', filter_complex,
            '-map', '[video_out]',                         # æ˜ å°„è§†é¢‘æµ
            '-map', '[audio_out]',                         # æ˜ å°„éŸ³é¢‘æµ
            '-t', str(duration),                           # è®¾ç½®æ—¶é•¿ï¼ˆå¼ºåˆ¶è¾“å‡ºæ—¶é•¿ï¼‰
            *get_gpu_encoding_params(use_gpu, 'balanced'), # GPUåŠ é€Ÿç¼–ç å‚æ•°
            '-c:a', 'aac',
            '-b:a', '192k',
            '-movflags', '+faststart',
            output_path
        ]
    
    try:
        print("å¼€å§‹FFmpegå¤„ç†...")
        result = subprocess.run(cmd, capture_output=True, text=False)
        if result.returncode != 0:
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                stderr_text = str(result.stderr)
            print(f"FFmpegé”™è¯¯: {stderr_text}")
            return False
        print("FFmpegå¤„ç†å®Œæˆ")
        return True
    except Exception as e:
        print(f"FFmpegæ‰§è¡Œå¤±è´¥: {e}")
        return False

def extract_random_clip_ffmpeg(source_video, output_path, start_time, duration, use_gpu=True):
    """ä½¿ç”¨FFmpegæå–éšæœºç‰‡æ®µï¼Œå¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç """
    ffmpeg = find_ffmpeg()
    
    print(f"ğŸ¬ æå–è§†é¢‘ç‰‡æ®µ: {os.path.basename(source_video)} ({start_time:.1f}s-{start_time+duration:.1f}s)")
    
    # å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç 
    cmd_gpu = [
        ffmpeg, '-y',
        '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
        '-hwaccel_output_format', 'cuda',      # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
        '-c:v', 'h264_cuvid',                  # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
        '-ss', str(start_time),
        '-i', source_video,
        '-t', str(duration),
        '-c:v', 'h264_nvenc',                  # å¼ºåˆ¶ä½¿ç”¨h264_nvencç¼–ç 
        '-preset', 'fast',
        '-crf', '23',
        '-c:a', 'aac',                         # éŸ³é¢‘ç¼–ç 
        '-movflags', '+faststart',             # ä¼˜åŒ–æ’­æ”¾
        output_path
    ]
    
    try:
        print("ğŸš€ ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç æå–ç‰‡æ®µ")
        result = subprocess.run(cmd_gpu, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… GPUç‰‡æ®µæå–æˆåŠŸ")
            return True
        else:
            print(f"âŒ GPUç‰‡æ®µæå–å¤±è´¥: {result.stderr}")
            
            # å¦‚æœGPUå¤±è´¥ï¼Œå›é€€åˆ°CPU
            print("ğŸ–¥ï¸ å›é€€åˆ°CPUç¼–ç æå–ç‰‡æ®µ")
            cmd_cpu = [
                ffmpeg, '-y',
                '-ss', str(start_time),
                '-i', source_video,
                '-t', str(duration),
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-crf', '23',
                '-c:a', 'aac',
                '-movflags', '+faststart',
                output_path
            ]
            
            result_cpu = subprocess.run(cmd_cpu, capture_output=True, text=True)
            if result_cpu.returncode == 0:
                print("âœ… CPUç‰‡æ®µæå–æˆåŠŸ")
                return True
            else:
                print(f"âŒ CPUç‰‡æ®µæå–å¤±è´¥: {result_cpu.stderr}")
                return False
                
    except Exception as e:
        print(f"âŒ ç‰‡æ®µæå–å¼‚å¸¸: {e}")
        return False

def create_silence_audio(duration, output_path):
    """åˆ›å»ºé™éŸ³éŸ³é¢‘æ–‡ä»¶"""
    ffmpeg = find_ffmpeg()
    
    cmd = [
        ffmpeg, '-y',
        '-f', 'lavfi',
        '-i', f'anullsrc=channel_layout=stereo:sample_rate=44100',
        '-t', str(duration),
        '-c:a', 'aac',
        output_path
    ]
    
    try:
        subprocess.run(cmd, capture_output=True, check=True)
        return True
    except:
        return False

def split_long_sentence_by_screen(sentence, video_width=1080, style=None, max_chars_per_screen=15):
    """
    å°†é•¿å¥å­æŒ‰å±å¹•æ˜¾ç¤ºèƒ½åŠ›åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ
    æ¯ä¸ªç‰‡æ®µç¡®ä¿èƒ½åœ¨ä¸€å±å†…å®Œæ•´æ˜¾ç¤º
    """
    if not sentence:
        return []
    
    subtitle_style = style.get("subtitle", {}) if style else {}
    fontsize = int(subtitle_style.get("fontSize", 48))
    
    # è·å–å­—ä½“
    font_path = get_font_path_from_style(style, 'subtitle')
    font = None
    if font_path and os.path.exists(font_path):
        try:
            print(f'åˆ†å±å­—å¹•ä½¿ç”¨å­—ä½“: {font_path}')
            font = ImageFont.truetype(font_path, fontsize)
        except Exception as e:
            print(f'åˆ†å±å­—å¹•å­—ä½“åŠ è½½å¤±è´¥: {e}')
            font = None
    
    if font is None:
        chinese_fonts = [
            "C:\\Windows\\Fonts\\msyh.ttc",
            "C:\\Windows\\Fonts\\simsun.ttc",
            "C:\\Windows\\Fonts\\simhei.ttf",
        ]
        for fp in chinese_fonts:
            try:
                font = ImageFont.truetype(fp, fontsize)
                break
            except Exception:
                continue
    
    if font is None:
        font = ImageFont.load_default()
    
    # è®¡ç®—å•å±æœ€å¤§å®½åº¦
    max_width = video_width - 120  # å·¦å³å„ç•™60åƒç´ è¾¹è·
    
    # åˆ›å»ºä¸´æ—¶ç”»å¸ƒæµ‹è¯•æ–‡æœ¬å®½åº¦
    temp_img = Image.new("RGBA", (video_width, 200), (0, 0, 0, 0))
    temp_draw = ImageDraw.Draw(temp_img)
    
    segments = []
    current_segment = ""
    
    # æŒ‰å­—ç¬¦é€ä¸ªæ·»åŠ ï¼Œæµ‹è¯•æ˜¯å¦è¶…å‡ºå±å¹•å®½åº¦
    for char in sentence:
        test_segment = current_segment + char
        
        try:
            bbox = temp_draw.textbbox((0, 0), test_segment, font=font)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(test_segment) * fontsize // 2
        
        # å¦‚æœè¶…å‡ºæœ€å¤§å®½åº¦ä¸”å½“å‰ç‰‡æ®µä¸ä¸ºç©ºï¼Œåˆ†å‰²
        if text_width > max_width and current_segment:
            segments.append(current_segment.strip())
            current_segment = char
        else:
            current_segment = test_segment
    
    # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
    if current_segment.strip():
        segments.append(current_segment.strip())
    
    # å¦‚æœæ²¡æœ‰åˆ†å‰²ï¼Œè¿”å›åŸå¥å­
    if not segments:
        segments = [sentence]
    
    return segments

def split_text_into_screen_friendly_sentences(text, video_width=1080, style=None):
    """
    å°†æ–‡æœ¬åˆ†å‰²æˆé€‚åˆå±å¹•æ˜¾ç¤ºçš„å¥å­ç‰‡æ®µ
    ä¼˜å…ˆæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œå¦‚æœå•å¥å¤ªé•¿åˆ™æŒ‰å±å¹•å®½åº¦å†æ¬¡åˆ†å‰²
    """
    if not text:
        return []
    import re

    # æŒ‰ä¸­è‹±æ–‡å¸¸ç”¨æ ‡ç‚¹æ‹†åˆ†å¹¶å»æ‰è¿™äº›æ ‡ç‚¹
    split_re = re.compile(r"[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š,\.!\?;:]+")

    parts = [p.strip() for p in split_re.split(text) if p and p.strip()]

    # å›é€€ï¼šå¦‚æœæ²¡æœ‰åˆ†å‰²å‡ºå†…å®¹ï¼Œä¿ç•™åŸæ–‡æœ¬
    if not parts:
        parts = [text.strip()]

    # å¯¹æ¯ä¸ªåˆ†æ®µï¼Œä½¿ç”¨æŒ‰å±å®½å†ç»†åˆ†çš„å‡½æ•°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
    final_segments = []
    for part in parts:
        segments = split_long_sentence_by_screen(part, video_width, style)
        if segments:
            final_segments.extend(segments)
        else:
            final_segments.append(part)

    if not final_segments:
        final_segments = [text.strip()]

    print(f"æ–‡æœ¬åˆ†å‰²ç»“æœï¼šåŸæ–‡ -> {len(parts)}ä¸ªå¥å­ -> {len(final_segments)}ä¸ªæ˜¾ç¤ºç‰‡æ®µ")
    for i, segment in enumerate(final_segments):
        print(f"  ç‰‡æ®µ{i+1}: '{segment[:30]}{'...' if len(segment) > 30 else ''}'")

    return final_segments

def create_single_line_subtitle_image(text, video_width=1080, style=None):
    """
    åˆ›å»ºå•è¡Œå­—å¹•å›¾ç‰‡ï¼Œç¡®ä¿æ–‡æœ¬åœ¨ä¸€è¡Œå†…æ˜¾ç¤º
    å¦‚æœæ–‡æœ¬è¿‡é•¿ä¼šè‡ªåŠ¨è°ƒæ•´å­—ä½“å¤§å°
    """
    if not text:
        return Image.new("RGBA", (1, 1), (0, 0, 0, 0))
    
    subtitle_style = style.get("subtitle", {}) if style else {}
    base_fontsize = int(subtitle_style.get("fontSize", 48))
    color = subtitle_style.get("color", "#FFFFFF")
    
    # å­—ä½“å¤„ç†
    font_path = get_font_path_from_style(style, 'subtitle')
    font = None
    if font_path and os.path.exists(font_path):
        try:
            print(f'å•è¡Œå­—å¹•ä½¿ç”¨å­—ä½“: {font_path}')
            font = ImageFont.truetype(font_path, base_fontsize)
        except Exception as e:
            print(f'å•è¡Œå­—å¹•å­—ä½“åŠ è½½å¤±è´¥: {e}')
            font = None
    
    if font is None:
        chinese_fonts = [
            "C:\\Windows\\Fonts\\msyh.ttc",
            "C:\\Windows\\Fonts\\simsun.ttc",
            "C:\\Windows\\Fonts\\simhei.ttf",
        ]
        for fp in chinese_fonts:
            try:
                font = ImageFont.truetype(fp, base_fontsize)
                break
            except Exception:
                continue
    
    if font is None:
        font = ImageFont.load_default()

    # è®¡ç®—åˆé€‚çš„å­—ä½“å¤§å°ï¼Œç¡®ä¿æ–‡æœ¬èƒ½åœ¨ä¸€è¡Œæ˜¾ç¤º
    max_width = video_width - 120  # å·¦å³å„ç•™60åƒç´ è¾¹è·
    fontsize = base_fontsize
    
    # åˆ›å»ºä¸´æ—¶ç”»å¸ƒæµ‹è¯•
    temp_img = Image.new("RGBA", (video_width, 200), (0, 0, 0, 0))
    temp_draw = ImageDraw.Draw(temp_img)
    
    # è‡ªåŠ¨è°ƒæ•´å­—ä½“å¤§å°
    while fontsize > 20:  # æœ€å°å­—ä½“å¤§å°
        try:
            if font_path and os.path.exists(font_path):
                test_font = ImageFont.truetype(font_path, fontsize)
            else:
                test_font = ImageFont.truetype("C:\\Windows\\Fonts\\msyh.ttc", fontsize)
        except:
            test_font = ImageFont.load_default()
        
        try:
            bbox = temp_draw.textbbox((0, 0), text, font=test_font)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(text) * fontsize // 2
        
        if text_width <= max_width:
            font = test_font
            break
    # è®¡ç®—å›¾ç‰‡å°ºå¯¸
    line_height = fontsize + 12
    padding = 30
    banner_h = line_height + padding * 2
    
    # åˆ›å»ºå­—å¹•å›¾ç‰‡ï¼ˆä½¿ç”¨å¯é…ç½®èƒŒæ™¯é¢œè‰²ï¼‰
    bg_rgba = get_bg_rgba_from_style(style, "subtitle", default=(0,0,0,0))  # é»˜è®¤å®Œå…¨é€æ˜
    img = Image.new("RGBA", (video_width, banner_h), bg_rgba)
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶å•è¡Œæ–‡æœ¬
    try:
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
    except Exception:
        # å¦‚æœæ— æ³•è·å–ç²¾ç¡®è¾¹ç•Œï¼Œä½¿ç”¨ä¼°ç®—å®½åº¦ä½œä¸ºå›é€€
        text_width = len(text) * fontsize // 2
    
    x = (video_width - text_width) // 2  # å±…ä¸­
    y = padding
    
    # æ·»åŠ æ–‡å­—é˜´å½±å’Œä¸»æ–‡å­—
    draw.text((x+2, y+2), text, font=font, fill=(0, 0, 0, 128))  # é˜´å½±
    draw.text((x, y), text, font=font, fill=color)  # ä¸»æ–‡å­—
    
    print(f"å•è¡Œå­—å¹•: å­—ä½“{fontsize}px, æ–‡æœ¬'{text[:20]}...', å®½åº¦{text_width}px")
    
    return img

def create_dynamic_subtitles(sentences, total_duration, video_width=1080, style=None, temp_dir=None):
    """åˆ›å»ºåŠ¨æ€å­—å¹•ç‰‡æ®µï¼Œæ¯å¥å­—å¹•æŒ‰æ—¶é—´æ˜¾ç¤º"""
    if not sentences:
        return []
    
    if temp_dir is None:
        temp_dir = SUBTITLE_TEMP_DIR
    
    subtitle_clips = []
    
    # è®¡ç®—æ¯å¥å­—å¹•çš„æ˜¾ç¤ºæ—¶é—´ - åŸºäºå¥å­é•¿åº¦åˆ†é…æ—¶é—´
    sentence_count = len(sentences)
    
    # è®¡ç®—æ¯ä¸ªå¥å­çš„ç›¸å¯¹é•¿åº¦æƒé‡
    sentence_lengths = [len(sentence) for sentence in sentences]
    total_length = sum(sentence_lengths)
    
    current_time = 0
    
    for i, sentence in enumerate(sentences):
        # ä¸ºæ¯å¥åˆ›å»ºå•è¡Œå­—å¹•å›¾ç‰‡
        subtitle_id = str(uuid4())[:8]
        subtitle_path = os.path.join(temp_dir, f"dynamic_subtitle_{i}_{subtitle_id}.png")
        
        # ä½¿ç”¨æ–°çš„å•è¡Œå­—å¹•ç”Ÿæˆå‡½æ•°
        subtitle_img = create_single_line_subtitle_image(sentence, video_width, style)
        subtitle_img.save(subtitle_path)
        
        # æ ¹æ®å¥å­é•¿åº¦æŒ‰æ¯”ä¾‹åˆ†é…æ—¶é—´
        if total_length > 0:
            sentence_ratio = sentence_lengths[i] / total_length
            allocated_duration = total_duration * sentence_ratio
        else:
            allocated_duration = total_duration / sentence_count
        
        # è®¾ç½®æœ€å°å’Œæœ€å¤§æ˜¾ç¤ºæ—¶é—´
        min_duration = 1.2  # æœ€å°‘æ˜¾ç¤º1.2ç§’
        max_duration = 4.0   # æœ€å¤šæ˜¾ç¤º4ç§’
        
        # è°ƒæ•´æ˜¾ç¤ºæ—¶é—´
        duration = max(min_duration, min(allocated_duration, max_duration))
        
        # å¦‚æœæ˜¯æœ€åä¸€å¥ï¼Œç¡®ä¿ä¸è¶…è¿‡æ€»æ—¶é•¿
        if i == len(sentences) - 1:
            duration = min(duration, total_duration - current_time)
        
        start_time = current_time
        end_time = start_time + duration
        
        if duration > 0:
            subtitle_clips.append({
                'path': subtitle_path,
                'start_time': start_time,
                'end_time': end_time,
                'duration': duration,
                'text': sentence
            })
            
            print(f"å­—å¹•ç‰‡æ®µ{i+1}: {start_time:.1f}s-{end_time:.1f}s (æ—¶é•¿{duration:.1f}s) '{sentence[:25]}...'")
        
        current_time = end_time
        
        # å¦‚æœå·²ç»è¾¾åˆ°æ€»æ—¶é•¿ï¼Œåœæ­¢åˆ›å»º
        if current_time >= total_duration:
            break
    
    # å¦‚æœæ—¶é—´åˆ†é…æœ‰å‰©ä½™ï¼Œå°†å‰©ä½™æ—¶é—´å¹³å‡åˆ†é…ç»™æ‰€æœ‰å­—å¹•
    if current_time < total_duration and subtitle_clips:
        remaining_time = total_duration - current_time
        time_per_clip = remaining_time / len(subtitle_clips)
        
        print(f"è°ƒæ•´å­—å¹•æ—¶é—´ï¼šå‰©ä½™{remaining_time:.1f}sï¼Œå¹³å‡åˆ†é…ç»™{len(subtitle_clips)}ä¸ªå­—å¹•")
        
        for i, clip in enumerate(subtitle_clips):
            clip['duration'] += time_per_clip
            if i > 0:
                clip['start_time'] = subtitle_clips[i-1]['end_time']
            clip['end_time'] = clip['start_time'] + clip['duration']
            
            print(f"è°ƒæ•´åå­—å¹•{i+1}: {clip['start_time']:.1f}s-{clip['end_time']:.1f}s (æ—¶é•¿{clip['duration']:.1f}s)")
    
    print(f"åˆ›å»ºäº†{len(subtitle_clips)}ä¸ªåŠ¨æ€å­—å¹•ç‰‡æ®µï¼Œæ€»æ—¶é•¿{total_duration}ç§’")
    return subtitle_clips

async def process_clips_parallel_gpu(req):
    """
    ã€å¹¶è¡ŒGPUç‰ˆæœ¬ã€‘è§†é¢‘å¤„ç†æ–¹æ³• - å¤šçº¿ç¨‹GPUå¹¶è¡Œç”Ÿæˆ
    æ€§èƒ½ç›®æ ‡ï¼š1-2åˆ†é’Ÿç”Ÿæˆå¤šä¸ªè§†é¢‘ï¼Œå……åˆ†åˆ©ç”¨GPUèµ„æº
    """
    from services.enhanced_clip_service import enhanced_clip_service
    return await enhanced_clip_service.process_clips_enhanced(req)

async def process_clips_optimized(req):
    """
    ã€ä¼˜åŒ–ç‰ˆæœ¬ã€‘è§†é¢‘å¤„ç†æ–¹æ³• - ä½¿ç”¨ASSå­—å¹• + æ™ºèƒ½ç¼“å­˜
    æ€§èƒ½ç›®æ ‡ï¼š3-5åˆ†é’Ÿç”Ÿæˆï¼Œä¿ç•™æ‰€æœ‰é«˜çº§åŠŸèƒ½
    """
    import time
    start_time = time.time()

    video_count = req.videoCount
    duration_sec = parse_duration(req.duration)
    video_files = req.videos
    audio_files = req.audios
    poster_files = req.posters if hasattr(req, 'posters') else []
    scripts = [s for s in req.scripts if s.selected]
    style = req.style.dict() if hasattr(req.style, "dict") else req.style

    # é¡¹ç›®çš„æ ‡é¢˜å’Œæ ·å¼
    title = req.name
    title_position = style.get("title", {}).get("position", "top")
    subtitle_position = style.get("subtitle", {}).get("position", "bottom")
    
    # æ”¯æŒä¸»å‰¯æ ‡é¢˜ï¼šä¼˜å…ˆä½¿ç”¨ä¸»æ ‡é¢˜çš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é¡¹ç›®åç§°
    title_config = style.get("title", {})
    if title_config.get("mainTitle") and title_config.get("mainTitle", {}).get("text"):
        title = title_config["mainTitle"]["text"]
    
    print(f"ğŸš€ å¼€å§‹ä¼˜åŒ–ç‰ˆæœ¬è§†é¢‘ç”Ÿæˆ...")
    print(f"   é¡¹ç›®æ ‡é¢˜: {title}")
    print(f"   è§†é¢‘æ•°é‡: {video_count}")
    print(f"   ç›®æ ‡æ—¶é•¿: {duration_sec}ç§’")
    print(f"   è„šæœ¬æ•°é‡: {len(scripts)}")
    print("=" * 50)

    # ğŸ¯ ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½ç´ æé¢„åŠ è½½ï¼ˆå¹¶è¡Œä¸‹è½½ï¼‰
    print("ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½é¢„åŠ è½½ç´ æ...")
    preload_start = time.time()
    
    # æ”¶é›†æ‰€æœ‰ç´ æURL
    all_urls = []
    all_urls.extend([v.url for v in video_files])
    all_urls.extend([a.url for a in audio_files])
    if poster_files:
        all_urls.extend([p.url for p in poster_files])
    
    # å¹¶è¡Œé¢„åŠ è½½æ‰€æœ‰ç´ æ
    url_to_path = await smart_cache.preload_materials(all_urls)
    
    preload_time = time.time() - preload_start
    print(f"âœ… ç´ æé¢„åŠ è½½å®Œæˆï¼Œè€—æ—¶: {preload_time:.1f}ç§’")
    print(f"   æˆåŠŸåŠ è½½: {len(url_to_path)}/{len(all_urls)} ä¸ªç´ æ")

    # æ˜ å°„åˆ°æœ¬åœ°è·¯å¾„
    local_video_paths = [url_to_path.get(v.url) for v in video_files if url_to_path.get(v.url)]
    local_audio_paths = [url_to_path.get(a.url) for a in audio_files if url_to_path.get(a.url)]

    local_audio_paths = process_original_video(local_audio_paths)
    
    local_poster_path = None
    if poster_files and len(poster_files) > 0:
        poster_url = poster_files[0].url
        local_poster_path = url_to_path.get(poster_url)
        if local_poster_path:
            print(f"ğŸ–¼ï¸  æµ·æŠ¥åŠ è½½å®Œæˆ: {local_poster_path}")

    if not local_video_paths:
        return {"success": False, "error": "æ‰¾ä¸åˆ°å¯ç”¨çš„è§†é¢‘æ–‡ä»¶"}

    result_videos = []

    try:
        ffmpeg = find_ffmpeg()
        
        # ğŸ¯ ç¬¬äºŒæ­¥ï¼šè·å–è§†é¢‘ä¿¡æ¯ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
        print("ğŸ“Š ç¬¬äºŒæ­¥ï¼šåˆ†æè§†é¢‘ä¿¡æ¯...")
        video_info_start = time.time()
        
        video_infos = []
        for video_path in local_video_paths:
            if os.path.exists(video_path):
                info = get_video_info(video_path)
                video_infos.append(info)

        if not video_infos:
            return {"success": False, "error": "æ— æœ‰æ•ˆè§†é¢‘æ–‡ä»¶"}
        
        video_info_time = time.time() - video_info_start
        print(f"âœ… è§†é¢‘ä¿¡æ¯åˆ†æå®Œæˆï¼Œè€—æ—¶: {video_info_time:.1f}ç§’")

        # ğŸ¯ ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡ç”Ÿæˆè§†é¢‘
        print("ğŸ¬ ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹æ‰¹é‡ç”Ÿæˆè§†é¢‘...")
        generation_start = time.time()

        # ğŸš€ å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼šå½“è§†é¢‘æ•°é‡>=2æ—¶å¯ç”¨å¤šçº¿ç¨‹
        if video_count >= 2:
            print(f"âš¡ å¯ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† ({video_count}ä¸ªè§†é¢‘)")
            import concurrent.futures
            import threading
            
            # åŠ¨æ€è°ƒæ•´å¹¶å‘çº¿ç¨‹æ•°ï¼Œé¿å…GPUèµ„æºè¿‡åº¦ç«äº‰
            # æ£€æŸ¥å½“å‰GPUè´Ÿè½½ï¼Œå¦‚æœè´Ÿè½½é«˜åˆ™å‡å°‘å¹¶å‘æ•°
            try:
                import psutil
                gpu_memory_percent = 0  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ£€æŸ¥GPUä½¿ç”¨ç‡
                if gpu_memory_percent > 80:
                    max_workers = min(2, video_count)  # é«˜è´Ÿè½½æ—¶å‡å°‘å¹¶å‘
                    print(f"   æ£€æµ‹åˆ°GPUé«˜è´Ÿè½½ï¼Œå‡å°‘å¹¶å‘æ•°è‡³{max_workers}")
                else:
                    max_workers = min(3, video_count)  # æ­£å¸¸è´Ÿè½½
                    print(f"   GPUè´Ÿè½½æ­£å¸¸ï¼Œä½¿ç”¨{max_workers}ä¸ªå¹¶è¡Œçº¿ç¨‹")
            except:
                max_workers = min(2, video_count)  # ä¿å®ˆç­–ç•¥
                print(f"   ä½¿ç”¨ä¿å®ˆå¹¶å‘æ•°{max_workers}ä¸ªçº¿ç¨‹ï¼Œé¿å…èµ„æºç«äº‰")
            
            def process_single_video_thread(video_index):
                """å•ä¸ªè§†é¢‘å¤„ç†çº¿ç¨‹å‡½æ•°"""
                return _process_single_video_optimized(
                    video_index, video_count, local_video_paths, local_audio_paths, 
                    local_poster_path, video_infos, duration_sec, title, scripts, 
                    style, title_position, subtitle_position, req
                )
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_index = {
                    executor.submit(process_single_video_thread, i): i 
                    for i in range(video_count)
                }
                
                # æ”¶é›†ç»“æœ
                parallel_results = []
                for future in concurrent.futures.as_completed(future_to_index):
                    video_index = future_to_index[future]
                    try:
                        result = future.result()
                        if result:
                            parallel_results.append(result)
                            print(f"âœ… çº¿ç¨‹{video_index+1}å®Œæˆ")
                        else:
                            print(f"âŒ çº¿ç¨‹{video_index+1}å¤±è´¥")
                    except Exception as e:
                        print(f"âŒ çº¿ç¨‹{video_index+1}å¼‚å¸¸: {e}")
                
                # å°†å¹¶è¡Œç»“æœæ·»åŠ åˆ°result_videos
                result_videos.extend(parallel_results)
        else:
            print("ğŸ”„ å•è§†é¢‘ä½¿ç”¨ä¸²è¡Œå¤„ç†")
            # å•ä¸ªè§†é¢‘æ—¶ä½¿ç”¨åŸæœ‰ä¸²è¡Œé€»è¾‘ï¼Œç›´æ¥è°ƒç”¨å•ä¸ªè§†é¢‘å¤„ç†å‡½æ•°
            for i in range(video_count):
                result = _process_single_video_optimized(
                    i, video_count, local_video_paths, local_audio_paths, 
                    local_poster_path, video_infos, duration_sec, title, scripts, 
                    style, title_position, subtitle_position, req
                )
                if result:
                    result_videos.append(result)
                    print(f"âœ… ä¸²è¡Œè§†é¢‘{i+1}å®Œæˆ")
                else:
                    print(f"âŒ ä¸²è¡Œè§†é¢‘{i+1}å¤±è´¥")
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        generation_time = time.time() - generation_start
        total_time = time.time() - start_time
        
        print("\n" + "=" * 50)
        print("ğŸŠ ä¼˜åŒ–ç‰ˆæœ¬ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   ç´ æé¢„åŠ è½½: {preload_time:.1f}ç§’")
        print(f"   è§†é¢‘ä¿¡æ¯åˆ†æ: {video_info_time:.1f}ç§’") 
        print(f"   è§†é¢‘ç”Ÿæˆ: {generation_time:.1f}ç§’")
        print(f"   æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"   å¹³å‡æ¯ä¸ªè§†é¢‘: {generation_time/max(video_count,1):.1f}ç§’")
        print(f"   æˆåŠŸç”Ÿæˆ: {len(result_videos)}/{video_count} ä¸ªè§†é¢‘")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘ç”ŸæˆæˆåŠŸ
        if not result_videos:
            error_msg = f"è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼šè¯·æ±‚ç”Ÿæˆ{video_count}ä¸ªè§†é¢‘ï¼Œä½†æ²¡æœ‰ä»»ä½•è§†é¢‘æˆåŠŸç”Ÿæˆ"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
        
        return {
            "success": True,
            "message": f"ä¼˜åŒ–ç‰ˆæœ¬è§†é¢‘å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶{total_time:.1f}ç§’ï¼ŒæˆåŠŸç”Ÿæˆ{len(result_videos)}/{video_count}ä¸ªè§†é¢‘",
            "videos": result_videos,
            "performance_stats": {
                "total_time": total_time,
                "preload_time": preload_time,
                "generation_time": generation_time,
                "videos_generated": len(result_videos),
                "videos_requested": video_count
            }
        }
                
    except Exception as e:
        import traceback
        error_msg = f"ä¼˜åŒ–ç‰ˆæœ¬è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}"
        print(f"âŒ {error_msg}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return {"success": False, "error": error_msg}

async def process_clips001(req):
    """
    ã€FFmpegç‰ˆæœ¬ã€‘è§†é¢‘å¤„ç†æ–¹æ³• - æ”¯æŒåŠ¨æ€å­—å¹•é€å¥æ˜¾ç¤º
    """
    import time
    from services.smart_material_cache import smart_cache

    video_count = req.videoCount
    duration_sec = parse_duration(req.duration)
    video_files = req.videos
    audio_files = req.audios
    poster_files = req.posters if hasattr(req, 'posters') else []
    scripts = [s for s in req.scripts if s.selected]
    style = req.style.dict() if hasattr(req.style, "dict") else req.style

    # é¡¹ç›®çš„æ ‡é¢˜å’Œæ ·å¼
    title = req.name
    title_position = style.get("title", {}).get("position", "top")
    subtitle_position = style.get("subtitle", {}).get("position", "bottom")
    
    # æ”¯æŒä¸»å‰¯æ ‡é¢˜ï¼šä¼˜å…ˆä½¿ç”¨ä¸»æ ‡é¢˜çš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é¡¹ç›®åç§°
    title_config = style.get("title", {})
    if title_config.get("mainTitle") and title_config.get("mainTitle", {}).get("text"):
        title = title_config["mainTitle"]["text"]
    
    print(f"ä½¿ç”¨æ ‡é¢˜: {title}")
    print(f"æ ‡é¢˜é…ç½®: {title_config}")

    # ğŸš€ ä½¿ç”¨æ™ºèƒ½ç¼“å­˜å¹¶è¡Œä¸‹è½½æ‰€æœ‰ç´ æ
    print("ğŸ“¥ ä½¿ç”¨æ™ºèƒ½ç¼“å­˜ä¸‹è½½ç´ æ...")
    download_start = time.time()
    
    # æ”¶é›†æ‰€æœ‰ç´ æURL
    all_urls = []
    all_urls.extend([v.url for v in video_files])
    all_urls.extend([a.url for a in audio_files])
    if poster_files:
        all_urls.extend([p.url for p in poster_files])
    
    # å¹¶è¡Œä¸‹è½½æ‰€æœ‰ç´ æ
    url_to_path = await smart_cache.preload_materials(all_urls)
    
    download_time = time.time() - download_start
    print(f"âœ… æ™ºèƒ½ç¼“å­˜ä¸‹è½½å®Œæˆï¼Œè€—æ—¶: {download_time:.1f}ç§’")
    
    # æ˜ å°„åˆ°æœ¬åœ°è·¯å¾„
    local_video_paths = [url_to_path.get(v.url) for v in video_files if url_to_path.get(v.url)]
    local_audio_paths = [url_to_path.get(a.url) for a in audio_files if url_to_path.get(a.url)]

    print(local_video_paths)
    local_video_paths = process_original_video(local_video_paths)
    print(local_video_paths)
    
    local_poster_path = None
    if poster_files and len(poster_files) > 0:
        poster_url = poster_files[0].url
        local_poster_path = url_to_path.get(poster_url)
        if local_poster_path:
            print(f"ğŸ–¼ï¸  æµ·æŠ¥åŠ è½½å®Œæˆ: {local_poster_path}")

    print("=======================================")
    print("åŒ…å«ï¼šTitle + åŠ¨æ€å­—å¹•(æ™ºèƒ½åˆ†å±æ˜¾ç¤º) + TTSè¯­éŸ³ + èƒŒæ™¯éŸ³ä¹ + æµ·æŠ¥èƒŒæ™¯")
    print(f"é¡¹ç›®æ ‡é¢˜: {title}")
    print(f"Titleä½ç½®: {title_position}")
    print(f"åŠ¨æ€å­—å¹•ä½ç½®: {subtitle_position}")
    print("=======================================")

    if not local_video_paths:
        return {"success": False, "error": "æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶"}

    result_videos = []

    try:
        ffmpeg = find_ffmpeg()
        
        # è·å–æ‰€æœ‰æºè§†é¢‘ä¿¡æ¯
        video_infos = []
        for video_path in local_video_paths:
            if os.path.exists(video_path):
                info = get_video_info(video_path)
                video_infos.append(info)

        if not video_infos:
            return {"success": False, "error": "æ— æœ‰æ•ˆè§†é¢‘æ–‡ä»¶"}

        # ğŸš€ å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼šå½“è§†é¢‘æ•°é‡>=2æ—¶å¯ç”¨å¤šçº¿ç¨‹
        generation_start = time.time()
        if video_count >= 2:
            print(f"âš¡ å¯ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† ({video_count}ä¸ªè§†é¢‘)")
            import concurrent.futures
            import threading
            
            # åŠ¨æ€è°ƒæ•´å¹¶å‘çº¿ç¨‹æ•°ï¼Œé¿å…GPUèµ„æºè¿‡åº¦ç«äº‰
            # æ£€æŸ¥å½“å‰GPUè´Ÿè½½ï¼Œå¦‚æœè´Ÿè½½é«˜åˆ™å‡å°‘å¹¶å‘æ•°
            try:
                import psutil
                gpu_memory_percent = 0  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ£€æŸ¥GPUä½¿ç”¨ç‡
                if gpu_memory_percent > 80:
                    max_workers = min(2, video_count)  # é«˜è´Ÿè½½æ—¶å‡å°‘å¹¶å‘
                    print(f"   æ£€æµ‹åˆ°GPUé«˜è´Ÿè½½ï¼Œå‡å°‘å¹¶å‘æ•°è‡³{max_workers}")
                else:
                    max_workers = min(3, video_count)  # æ­£å¸¸è´Ÿè½½
                    print(f"   GPUè´Ÿè½½æ­£å¸¸ï¼Œä½¿ç”¨{max_workers}ä¸ªå¹¶è¡Œçº¿ç¨‹")
            except:
                max_workers = min(2, video_count)  # ä¿å®ˆç­–ç•¥
                print(f"   ä½¿ç”¨ä¿å®ˆå¹¶å‘æ•°{max_workers}ä¸ªçº¿ç¨‹ï¼Œé¿å…èµ„æºç«äº‰")
            
            def process_single_video_001(video_index):
                """å•ä¸ªè§†é¢‘å¤„ç†çº¿ç¨‹å‡½æ•° - process_clips001ç‰ˆæœ¬"""
                return _process_single_video_001(
                    video_index, video_count, local_video_paths, local_audio_paths, 
                    local_poster_path, video_infos, duration_sec, title, scripts, 
                    style, title_position, subtitle_position, req
                )
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_index = {
                    executor.submit(process_single_video_001, i): i 
                    for i in range(video_count)
                }
                
                # æ”¶é›†ç»“æœ
                parallel_results = []
                for future in concurrent.futures.as_completed(future_to_index):
                    video_index = future_to_index[future]
                    try:
                        result = future.result()
                        if result:
                            parallel_results.append(result)
                            print(f"âœ… çº¿ç¨‹{video_index+1}å®Œæˆ")
                        else:
                            print(f"âŒ çº¿ç¨‹{video_index+1}å¤±è´¥")
                    except Exception as e:
                        print(f"âŒ çº¿ç¨‹{video_index+1}å¼‚å¸¸: {e}")
                
                # å°†å¹¶è¡Œç»“æœæ·»åŠ åˆ°result_videos
                result_videos.extend(parallel_results)
        else:
            print("ğŸ”„ å•è§†é¢‘ä½¿ç”¨ä¸²è¡Œå¤„ç†")
            # å•ä¸ªè§†é¢‘æ—¶ä½¿ç”¨åŸæœ‰ä¸²è¡Œé€»è¾‘ï¼Œç›´æ¥è°ƒç”¨å•ä¸ªè§†é¢‘å¤„ç†å‡½æ•°
            for i in range(video_count):
                result = _process_single_video_001(
                    i, video_count, local_video_paths, local_audio_paths, 
                    local_poster_path, video_infos, duration_sec, title, scripts, 
                    style, title_position, subtitle_position, req
                )
                if result:
                    result_videos.append(result)
                    print(f"âœ… ä¸²è¡Œè§†é¢‘{i+1}å®Œæˆ")
                else:
                    print(f"âŒ ä¸²è¡Œè§†é¢‘{i+1}å¤±è´¥")
        
        generation_time = time.time() - generation_start
        print(f"ğŸŠ è§†é¢‘ç”Ÿæˆå®Œæˆï¼æ€»è€—æ—¶: {generation_time:.1f}ç§’")
        print(f"   æˆåŠŸç”Ÿæˆ: {len(result_videos)}/{video_count} ä¸ªè§†é¢‘")
        
        return {
            "success": True,
            "message": f"åŠ¨æ€å­—å¹•è§†é¢‘å¤„ç†å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ{len(result_videos)}/{video_count}ä¸ªè§†é¢‘",
            "videos": result_videos
        }
        
    except Exception as e:
        import traceback
        error_msg = f"åŠ¨æ€å­—å¹•è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}"
        print(f"âŒ {error_msg}")
        traceback.print_exc()
        return {"success": False, "error": error_msg}

def _process_single_video_001(video_index, video_count, local_video_paths, local_audio_paths, 
                              local_poster_path, video_infos, duration_sec, title, scripts, 
                              style, title_position, subtitle_position, req):
    """
    å•ä¸ªè§†é¢‘å¤„ç†å‡½æ•° - process_clips001ç‰ˆæœ¬ï¼Œæ”¯æŒåŠ¨æ€å­—å¹•
    ä¸“é—¨ä¼˜åŒ–GPUä½¿ç”¨ï¼Œå‡å°‘CPUè´Ÿè½½
    """
    import asyncio
    import random
    import time
    from uuid import uuid4
    
    try:
        clip_start = time.time()
        clip_id = str(uuid4())[:8]
        
        print(f"\nğŸï¸  çº¿ç¨‹{video_index+1}: å¤„ç†åŠ¨æ€å­—å¹•è§†é¢‘ (ID: {clip_id})")
        
        # 1. è’™å¤ªå¥‡æ‹¼æ¥ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰
        montage_start = time.time()
        temp_clips = []
        n_videos = len(local_video_paths)
        base_duration = duration_sec // n_videos
        remaining_duration = duration_sec % n_videos
        
        # å…³é”®æ”¹è¿›ï¼šä¸ºæ¯ä¸ªè§†é¢‘éšæœºæ‰“ä¹±ç´ æé¡ºåºï¼Œç¡®ä¿æ¯ä¸ªè§†é¢‘ä½¿ç”¨ä¸åŒçš„æ‹¼æ¥é¡ºåº
        # åˆ›å»ºç´¢å¼•åˆ—è¡¨å¹¶æ‰“ä¹±
        indices = list(range(n_videos))
        random.shuffle(indices)
        
        # ä½¿ç”¨æ‰“ä¹±åçš„ç´¢å¼•æ¥è®¿é—®è§†é¢‘è·¯å¾„å’Œè§†é¢‘ä¿¡æ¯
        for idx in indices:
            video_path = local_video_paths[idx]
            video_info = video_infos[idx]
            
            segment_duration = base_duration
            if len(temp_clips) < remaining_duration:
                segment_duration += 1
            
            if segment_duration <= 0:
                continue
                
            max_segment = min(segment_duration, int(video_info['duration']) - 1)
            if max_segment <= 0:
                continue
            
            max_start = max(0, video_info['duration'] - max_segment - 0.5)
            start_time = random.uniform(0, max_start) if max_start > 0 else 0
            
            temp_clip_path = os.path.join(OUTPUT_DIR, f"temp_segment_{clip_id}_{idx}.mp4")
            
            if extract_random_clip_ffmpeg(video_path, temp_clip_path, start_time, max_segment):
                temp_clips.append(temp_clip_path)
        
        if not temp_clips:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: æ— æœ‰æ•ˆç‰‡æ®µ")
            return None
        
        montage_clip_path = os.path.join(OUTPUT_DIR, f"montage_clip_{clip_id}.mp4")
        
        if len(temp_clips) == 1:
            import shutil
            shutil.copy2(temp_clips[0], montage_clip_path)
        else:
            if not concat_videos_ffmpeg(temp_clips, montage_clip_path):
                print(f"   âŒ çº¿ç¨‹{video_index+1}: æ‹¼æ¥å¤±è´¥")
                return None
        
        montage_time = time.time() - montage_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: è’™å¤ªå¥‡æ‹¼æ¥å®Œæˆï¼Œè€—æ—¶: {montage_time:.1f}ç§’")

        # 2. ç”ŸæˆTitleå›¾ç‰‡
        title_start = time.time()
        title_image_path = os.path.join(SUBTITLE_TEMP_DIR, f"title_{clip_id}.png")
        title_img = create_title_image(title, 1080, 1920, style)
        title_img.save(title_image_path)
        title_time = time.time() - title_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: æ ‡é¢˜å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {title_time:.1f}ç§’")

        # 3. å‡†å¤‡è„šæœ¬æ–‡æœ¬
        script = random.choice(scripts).content if scripts else "è¿™æ˜¯ä¸€æ®µç²¾å½©çš„è§†é¢‘å†…å®¹ï¼Œå±•ç°äº†å¤šä¸ªç²¾å½©ç¬é—´çš„å®Œç¾èåˆã€‚é€šè¿‡è’™å¤ªå¥‡æŠ€æœ¯ï¼Œæˆ‘ä»¬å°†ä¸åŒçš„è§†é¢‘ç‰‡æ®µå·§å¦™åœ°ç»„åˆåœ¨ä¸€èµ·ã€‚"
        
        # 4. ç”ŸæˆTTSéŸ³é¢‘ï¼ˆåœ¨çº¿ç¨‹ä¸­éœ€è¦åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ï¼‰
        tts_start = time.time()
        tts_path = os.path.join(TTS_TEMP_DIR, f"tts_{clip_id}.wav")
        voice = 'zh-CN-YunxiNeural' if hasattr(req, 'voice') and req.voice == 'male' else 'zh-CN-XiaoxiaoNeural'
        
        # åœ¨çº¿ç¨‹ä¸­éœ€è¦åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥è°ƒç”¨å¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(generate_tts_audio(script, tts_path, voice))
        finally:
            loop.close()
        
        tts_time = time.time() - tts_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: TTSè¯­éŸ³ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {tts_time:.1f}ç§’")

        # è¯»å–TTSå®é™…æ—¶é•¿ï¼ŒåŠ¨æ€è°ƒæ•´è§†é¢‘æ—¶é•¿
        target_duration = duration_sec
        try:
            from moviepy.audio.io.AudioFileClip import AudioFileClip
            audio_clip_tmp = AudioFileClip(tts_path)
            tts_len = audio_clip_tmp.duration
            audio_clip_tmp.close()
            if tts_len and tts_len > duration_sec:
                print(f"   ğŸµ çº¿ç¨‹{video_index+1}: TTSæ—¶é•¿{tts_len:.2f}s > ç›®æ ‡æ—¶é•¿{duration_sec}sï¼Œæ‰©å±•åˆ°{tts_len:.2f}s")
                target_duration = tts_len
            else:
                print(f"   ğŸµ çº¿ç¨‹{video_index+1}: TTSæ—¶é•¿{tts_len:.2f}sï¼Œç›®æ ‡æ—¶é•¿ä¿æŒ{duration_sec}s")
        except Exception as e:
            print(f"   âš ï¸  çº¿ç¨‹{video_index+1}: è¯»å–TTSæ—¶é•¿å¤±è´¥: {e}")

        # 5. ä½¿ç”¨æ™ºèƒ½åˆ†å±æ–¹æ³•åˆ†å‰²æ–‡æœ¬
        subtitle_start = time.time()
        sentences = split_text_into_screen_friendly_sentences(script, 1080, style)
        print(f"   ğŸ“ çº¿ç¨‹{video_index+1}: æ™ºèƒ½åˆ†å±åˆ†å‰²æˆ{len(sentences)}ä¸ªç‰‡æ®µ")
        
        # å‡†å¤‡å­—å¹•æ•°æ®ï¼ˆä½¿ç”¨SRTæ ¼å¼ï¼‰
        subtitle_sentences = []
        current_time = 0.0
        time_per_sentence = target_duration / max(len(sentences), 1)
        
        for sentence in sentences:
            text = sentence.strip()
            if text:
                # æ ¹æ®æ–‡å­—é•¿åº¦ä¼°ç®—æ˜¾ç¤ºæ—¶é—´ï¼Œä½†ä¸è¶…è¿‡å¹³å‡æ—¶é—´
                estimated_duration = min(max(2.0, len(text) * 0.15), time_per_sentence * 1.5)
                subtitle_sentences.append({
                    "text": text,
                    "start_time": current_time,
                    "end_time": current_time + estimated_duration
                })
                current_time += estimated_duration
        
        subtitle_time = time.time() - subtitle_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: å­—å¹•æ•°æ®å‡†å¤‡å®Œæˆï¼Œè€—æ—¶: {subtitle_time:.1f}ç§’")

        # 6. GPUåŠ é€Ÿæœ€ç»ˆè§†é¢‘åˆæˆ
        final_start = time.time()
        final_output = os.path.join(OUTPUT_DIR, f"dynamic_subtitle_{clip_id}.mp4")
        
        bgm_audio = random.choice(local_audio_paths) if local_audio_paths else None
        silence_path = None
        if not bgm_audio or not os.path.exists(bgm_audio):
            silence_path = os.path.join(TTS_TEMP_DIR, f"silence_{clip_id}.wav")
            create_silence_audio(target_duration, silence_path)
            bgm_audio = silence_path

        # ğŸš€ ä½¿ç”¨GPUåŠ é€ŸSRTå­—å¹•å¤„ç†
        print(f"   ğŸš€ çº¿ç¨‹{video_index+1}: å¼€å§‹GPUåŠ é€Ÿè§†é¢‘åˆæˆ")
        from services.srt_subtitle_processor import create_gpu_video_with_srt_subtitles
        
        success = create_gpu_video_with_srt_subtitles(
            input_video=montage_clip_path,
            title_image=title_image_path,
            srt_file="",  # å°†åœ¨å‡½æ•°å†…éƒ¨åˆ›å»º
            tts_audio=tts_path,
            bgm_audio=bgm_audio,
            output_path=final_output,
            duration=target_duration,
            title_position=title_position,
            poster_image=local_poster_path,
            use_gpu=True,  # å¼ºåˆ¶ä½¿ç”¨GPU
            subtitle_sentences=subtitle_sentences,
            style=style  # ä¼ é€’æ ·å¼é…ç½®
        )
        
        final_time = time.time() - final_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: è§†é¢‘åˆæˆå®Œæˆï¼Œè€—æ—¶: {final_time:.1f}ç§’")
        
        if not success:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: è§†é¢‘åˆæˆå¤±è´¥")
            return None
        
        # 7. ä¸Šä¼ åˆ°OSS
        upload_start = time.time()
        try:
            clip_name = f"dynamic_subtitle_{clip_id}.mp4"
            with open(final_output, 'rb') as f:
                video_content = f.read()
            
            # åœ¨çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥OSSä¸Šä¼ 
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                oss_url = loop.run_until_complete(oss_client.upload_to_oss(
                    file_buffer=video_content,
                    original_filename=clip_name,
                    folder=OSS_UPLOAD_FINAL_VEDIO
                ))
            finally:
                loop.close()
            
            # åŠ¨æ€è·å–ç«¯å£
            port = os.getenv("BACKEND_PORT", "8000")
            video_url = f"http://39.96.187.7:{port}/api/videos/oss-proxy?url={oss_url}"
            video_size = len(video_content)
            os.remove(final_output)
            
            upload_time = time.time() - upload_start
            print(f"   âœ… çº¿ç¨‹{video_index+1}: OSSä¸Šä¼ å®Œæˆï¼Œè€—æ—¶: {upload_time:.1f}ç§’")
            
        except Exception as e:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: OSSä¸Šä¼ å¤±è´¥: {str(e)}")
            video_url = f"/outputs/clips/dynamic_subtitle_{clip_id}.mp4"
            video_size = os.path.getsize(final_output) if os.path.exists(final_output) else 0

        # 8. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_files = temp_clips + [montage_clip_path, title_image_path, tts_path]
        if silence_path:
            cleanup_files.append(silence_path)
        
        for temp_file in cleanup_files:
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except Exception as e:
                    print(f"   âš ï¸ çº¿ç¨‹{video_index+1}: æ¸…ç†å¤±è´¥: {temp_file} - {e}")
        
        clip_time = time.time() - clip_start
        print(f"   ğŸ‰ çº¿ç¨‹{video_index+1}: å®Œæˆï¼Œæ€»è€—æ—¶: {clip_time:.1f}ç§’")
        
        return {
            "id": clip_id,
            "name": f"dynamic_subtitle_{clip_id}.mp4",
            "url": video_url,
            "size": video_size,
            "duration": target_duration,
            "uploadedAt": None,
            "thread_id": video_index+1,
            "processing_time": clip_time
        }
        
    except Exception as e:
        print(f"   âŒ çº¿ç¨‹{video_index+1}: å¤„ç†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None

async def create_time_synced_dynamic_subtitles(sentences, tts_audio_path, video_width=1080, style=None, temp_dir=None):
    """åˆ›å»ºä¸TTSéŸ³é¢‘æ—¶é—´åŒæ­¥çš„åŠ¨æ€å­—å¹•"""
    if not sentences:
        return []
    
    if temp_dir is None:
        temp_dir = SUBTITLE_TEMP_DIR
    
    try:
        # è·å–TTSéŸ³é¢‘çš„å®é™…æ—¶é•¿
        from moviepy.audio.io.AudioFileClip import AudioFileClip
        audio_clip = AudioFileClip(tts_audio_path)
        actual_audio_duration = audio_clip.duration
        audio_clip.close()
        
        print(f"TTSéŸ³é¢‘å®é™…æ—¶é•¿: {actual_audio_duration:.2f}ç§’")
        
        # ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿åˆ›å»ºå­—å¹•
        return create_dynamic_subtitles(sentences, actual_audio_duration, video_width, style, temp_dir)
        
    except Exception as e:
        print(f"è·å–TTSéŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿")
        # å¦‚æœè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•
        return create_dynamic_subtitles(sentences, 30, video_width, style, temp_dir)

def create_9_16_video_with_dynamic_subtitles_ffmpeg(source_video, title_image, subtitle_clips, tts_audio, bgm_audio, output_path, duration, title_position="top", subtitle_position="bottom", poster_image=None, use_gpu=True, portrait_mode: bool=False):
    """ä½¿ç”¨FFmpegåˆ›å»ºåŒ…å«åŠ¨æ€å­—å¹•çš„9:16è§†é¢‘ï¼Œæ”¯æŒGPUåŠ é€Ÿ"""
    print(f"ğŸš€ è¿›å…¥åŠ¨æ€å­—å¹•å‡½æ•° - portrait_mode: {portrait_mode}, subtitle_position: {subtitle_position}")
    print(f"ğŸ® GPUåŠ é€Ÿå‚æ•°: use_gpu={use_gpu}")
    ffmpeg = find_ffmpeg()
    
    # è·å–åŸå§‹è§†é¢‘ä¿¡æ¯
    video_info = get_video_info(source_video)
    original_width = video_info['width']
    original_height = video_info['height']
    print(f"ğŸ“ åŸå§‹è§†é¢‘å°ºå¯¸: {original_width}x{original_height}")
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å‚æ•°
    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - portrait_mode: {portrait_mode}, subtitle_position: {subtitle_position}")
    
    # æ ¹æ®æ¨¡å¼è®¾ç½®ç›®æ ‡å°ºå¯¸
    # åˆ¤æ–­åŸå§‹è§†é¢‘æ˜¯å¦å·²ç»æ˜¯ç«–å±ï¼ˆé«˜åº¦ > å®½åº¦ï¼‰
    is_already_portrait = original_height > original_width
    
    if portrait_mode or subtitle_position == "template2":
        # ç«–å±æ¨¡å¼å¤„ç†
        if is_already_portrait:
            # åŸå§‹è§†é¢‘å·²ç»æ˜¯ç«–å±ï¼Œä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œä¸å¼ºåˆ¶ç¼©æ”¾
            target_width = original_width
            target_height = original_height
            print(f"âœ… æ£€æµ‹åˆ°åŸå§‹è§†é¢‘å·²æ˜¯ç«–å± ({original_width}x{original_height})ï¼Œä¿æŒåŸå§‹æ¯”ä¾‹")
        else:
            # åŸå§‹è§†é¢‘æ˜¯æ¨ªå±ï¼Œéœ€è¦è½¬æ¢ä¸ºç«–å±9:16æ¯”ä¾‹
            target_width = 1080
            target_height = 1920
            print(f"âœ… æ¨ªå±è§†é¢‘è½¬ç«–å±æ¨¡å¼ï¼Œç›®æ ‡å°ºå¯¸: {target_width}x{target_height}")
    else:
        # æ¨ªå±æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡†9:16å°ºå¯¸
        target_width = 1080
        target_height = 1920
        print(f"âœ… ä½¿ç”¨æ¨ªå±æ¨¡å¼å¤„ç†")
    
    print(f"ğŸ“º æœ€ç»ˆç›®æ ‡å°ºå¯¸: {target_width}x{target_height}")
    
    # è®¡ç®—Titleä½ç½®
    title_margin = 200
    if title_position == "top":
        title_overlay_y = title_margin
    elif title_position == "center":
        title_overlay_y = f"(H-h)/2-100"
    else:
        title_overlay_y = f"H-h-{title_margin}"
    
    # è®¡ç®—Subtitleä½ç½®
    subtitle_margin = 250
    if subtitle_position == "top":
        subtitle_overlay_y = subtitle_margin
        subtitle_overlay_x = "0"
    elif subtitle_position == "center":
        subtitle_overlay_y = f"(H-h)/2+100"
        subtitle_overlay_x = "0"
    elif subtitle_position == "template1":
        # æ¨¡æ¿ä½ç½®1ï¼šè·ä¸Šè¾¹æ¡†1372.4åƒç´  - éœ€è¦è€ƒè™‘å­—å¹•å›¾ç‰‡å†…éƒ¨çš„åç§»
        subtitle_overlay_y = str(1372.4 - 60)  # å‡å»å­—å¹•å›¾ç‰‡é«˜åº¦çš„ä¸€åŠï¼Œè®©æ–‡å­—ä¸­å¿ƒåœ¨1372.4ä½ç½®
        subtitle_overlay_x = "0"  # æ¨¡æ¿ä½ç½®1ï¼šæ°´å¹³å±…ä¸­ï¼ˆX=0è¡¨ç¤ºå±…ä¸­ï¼‰
    else:
        subtitle_overlay_y = f"H-h-{subtitle_margin}"
        subtitle_overlay_x = "0"
    
    # æ„å»ºè¾“å…¥å‚æ•°
    # å°†æºè§†é¢‘å¾ªç¯è¾“å…¥ä»¥è¦†ç›–ç›®æ ‡æ—¶é•¿ï¼›title ä¸ subtitle å›¾ç‰‡ä½œä¸º looped è¾“å…¥
    inputs = [
        '-stream_loop', '-1', '-i', source_video,  # è¾“å…¥0: æºè§†é¢‘ï¼ˆå¾ªç¯ï¼‰
        '-loop', '1', '-i', title_image,   # è¾“å…¥1: Titleå›¾ç‰‡ï¼ˆloopï¼‰
    ]
    
    # æ·»åŠ å­—å¹•è¾“å…¥
    subtitle_input_indices = []
    for i, subtitle_clip in enumerate(subtitle_clips):
        # æ¯ä¸ªå­—å¹•å›¾ç‰‡ä½œä¸º looped è¾“å…¥
        inputs.extend(['-loop', '1', '-i', subtitle_clip['path']])
        subtitle_input_indices.append(2 + i)  # ä»è¾“å…¥2å¼€å§‹
    
    # æ·»åŠ éŸ³é¢‘è¾“å…¥
    tts_input_index = len(subtitle_input_indices) + 2
    bgm_input_index = tts_input_index + 1
    inputs.extend(['-i', tts_audio, '-i', bgm_audio])

    # å¦‚æœæœ‰æµ·æŠ¥èƒŒæ™¯
    poster_input_index = None
    if poster_image and poster_image != "":
        poster_input_index = bgm_input_index + 1
        # poster ä¹Ÿä½œä¸º loop è¾“å…¥
        inputs.extend(['-loop', '1', '-i', poster_image])

    # æ„å»ºæ»¤é•œé“¾ - æ ¹æ®ç«–å±æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
    if portrait_mode or subtitle_position == "template2":
        # ç«–å±æ¨¡å¼å¤„ç†
        if poster_image and poster_image != "":
            # æœ‰æµ·æŠ¥èƒŒæ™¯çš„æƒ…å†µ
            if is_already_portrait:
                # åŸå§‹è§†é¢‘å·²ç»æ˜¯ç«–å±ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸å¼ºåˆ¶ç¼©æ”¾
                filter_parts = [
                    f"[{poster_input_index}:v]scale={target_width}:{target_height}[bg];",
                    f"[0:v][1:v]overlay=0:{title_overlay_y}[video_with_title];",
                    f"[bg][video_with_title]overlay=(W-w)/2:(H-h)/2[with_title];"
                ]
            else:
                # æ¨ªå±è§†é¢‘è½¬ç«–å±ï¼šæµ·æŠ¥ä½œä¸ºèƒŒæ™¯ï¼ŒåŸå§‹è§†é¢‘å åŠ 
                filter_parts = [
                    f"[{poster_input_index}:v]scale={target_width}:{target_height}[bg];",
                    f"[0:v]scale={target_width}:{target_height}[fg];",
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];",
                    f"[bg_with_fg][1:v]overlay=0:{title_overlay_y}[with_title];"
                ]
        else:
            # æ— æµ·æŠ¥èƒŒæ™¯çš„æƒ…å†µ
            if is_already_portrait:
                # åŸå§‹è§†é¢‘å·²ç»æ˜¯ç«–å±ï¼Œä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œç›´æ¥å åŠ æ ‡é¢˜
                filter_parts = [
                    f"[0:v][1:v]overlay=0:{title_overlay_y}[with_title];"
                ]
            else:
                # æ¨ªå±è§†é¢‘è½¬ç«–å±ï¼šç›´æ¥ç¼©æ”¾åˆ°9:16æ¯”ä¾‹
                filter_parts = [
                    f"[0:v]scale={target_width}:{target_height}[base];",
                    f"[base][1:v]overlay=0:{title_overlay_y}[with_title];"
                ]
        
        if is_already_portrait:
            print(f"âœ… ç«–å±æ¨¡å¼ï¼šä¿æŒåŸå§‹è§†é¢‘æ¯”ä¾‹ ({target_width}x{target_height})")
        else:
            print(f"âœ… ç«–å±æ¨¡å¼ï¼šæ¨ªå±è§†é¢‘è½¬æ¢ä¸º9:16æ¯”ä¾‹ ({target_width}x{target_height})")
    else:
        # æ¨ªå±æ¨¡å¼ï¼šä½¿ç”¨åŸæ¥çš„é€»è¾‘
        if poster_image and poster_image != "":
            # æœ‰æµ·æŠ¥èƒŒæ™¯
            filter_parts = [
                f"[{poster_input_index}:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}[bg];",
                f"[0:v]scale={target_width}:-1[fg_scale];",
                f"[fg_scale]scale={target_width}:{target_width*9//16}[fg];",
                f"[bg][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];",
                f"[bg_with_fg][1:v]overlay=0:{title_overlay_y}[with_title];"
            ]
        else:
            # æ— æµ·æŠ¥èƒŒæ™¯ï¼Œä½¿ç”¨æ¨¡ç³ŠèƒŒæ™¯ - ä¿®å¤å åŠ é¡ºåº
            filter_parts = [
                f"[0:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}[bg];",
                f"[bg]boxblur=luma_radius=50:chroma_radius=50:luma_power=3[bg_blur];",
                f"[0:v]scale={target_width}:-1[fg_scale];",
                f"[fg_scale]scale={target_width}:{target_width*9//16}[fg];",
                f"[bg_blur][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];",
                f"[bg_with_fg][1:v]overlay=0:{title_overlay_y}[with_title];"
            ]
        print(f"âœ… æ¨ªå±æ¨¡å¼ï¼šä½¿ç”¨increase+cropï¼Œæœ‰èƒŒæ™¯æ¨¡ç³Š")
    
    # æ·»åŠ åŠ¨æ€å­—å¹•å åŠ 
    current_layer = "with_title"
    for i, (subtitle_clip, input_idx) in enumerate(zip(subtitle_clips, subtitle_input_indices)):
        next_layer = f"with_subtitle_{i}" if i < len(subtitle_clips) - 1 else "final_video"
        
        # æ­£ç¡®çš„å­—å¹•å åŠ è¯­æ³•
        filter_parts.append(
            f"[{current_layer}][{input_idx}:v]overlay={subtitle_overlay_x}:{subtitle_overlay_y}:"
            f"enable='between(t,{subtitle_clip['start_time']},{subtitle_clip['end_time']})'"
            f"[{next_layer}];"
        )
        current_layer = next_layer
        
        print(f"å­—å¹•{i+1}: {subtitle_clip['start_time']:.1f}s-{subtitle_clip['end_time']:.1f}s æ·»åŠ åˆ°æ»¤é•œé“¾")
    # ç¡®ä¿æœ€ç»ˆè¾“å‡ºæ ¼å¼æ­£ç¡®
    filter_parts.append(f"[{current_layer}]format=yuv420p[video_out];")
    
    # éŸ³é¢‘å¤„ç†
    # æ˜ç¡®å°†éŸ³é¢‘ trim åˆ°ç›®æ ‡æ—¶é•¿ï¼Œæ··éŸ³ä½¿ç”¨ shortestï¼Œæœ€ç»ˆå†æˆªæ–­ç¡®ä¿ä¸€è‡´
    filter_parts.extend([
        f"[{tts_input_index}:a]volume=0.8,atrim=0:{duration}[tts];",
        f"[{bgm_input_index}:a]volume=0.15,atrim=0:{duration}[bgm];",
        f"[tts][bgm]amix=inputs=2:duration=shortest:dropout_transition=0,atrim=0:{duration}[audio_out]"
    ])
    
    filter_complex = "".join(filter_parts)
    
    print(f"ä¿®å¤åçš„FFmpegæ»¤é•œé“¾:")
    print(filter_complex)
    print("=" * 50)
    
    # æ„å»ºå®Œæ•´å‘½ä»¤ - GPUåŠ é€Ÿ
    gpu_params = get_gpu_encoding_params(use_gpu, 'balanced')
    print(f"ğŸ® è·å–åˆ°çš„GPUç¼–ç å‚æ•°: {' '.join(gpu_params)}")
    
    cmd = [ffmpeg, '-y'] + inputs + [
        '-filter_complex', filter_complex,
        '-map', '[video_out]',
        '-map', '[audio_out]',
        '-t', str(duration),
        *gpu_params,  # GPUåŠ é€Ÿç¼–ç å‚æ•°
        '-c:a', 'aac',
        '-b:a', '192k',
        '-movflags', '+faststart',
        output_path
    ]
    
    try:
        print("å¼€å§‹FFmpegåŠ¨æ€å­—å¹•å¤„ç†...")
        print(f"æ€»å…±{len(subtitle_clips)}ä¸ªå­—å¹•ç‰‡æ®µ")
        for i, clip in enumerate(subtitle_clips):
            print(f"  å­—å¹•{i+1}: {clip['start_time']:.1f}s-{clip['end_time']:.1f}s '{clip['text'][:30]}...'")
        
        result = subprocess.run(cmd, capture_output=True, text=False)
        if result.returncode != 0:
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                stderr_text = str(result.stderr)
            print(f"FFmpegé”™è¯¯: {stderr_text}")
            # å¦‚æœåŠ¨æ€å­—å¹•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€å¥å­—å¹•ä½œä¸ºé™æ€å­—å¹•
            if subtitle_clips:
                print("å°è¯•ä½¿ç”¨é™æ€å­—å¹•ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...")
                return create_fallback_static_subtitle_video(
                    source_video, title_image, subtitle_clips[0]['path'], 
                    tts_audio, bgm_audio, output_path, duration, 
                    title_position, subtitle_position, poster_image
                )
            return False
        print("FFmpegåŠ¨æ€å­—å¹•å¤„ç†å®Œæˆ")
        return True
    except Exception as e:
        print(f"FFmpegæ‰§è¡Œå¤±è´¥: {e}")
        return False

def create_fallback_static_subtitle_video(source_video, title_image, subtitle_image, tts_audio, bgm_audio, output_path, duration, title_position="top", subtitle_position="bottom", poster_image=None):
    """å¤‡é€‰æ–¹æ¡ˆï¼šåˆ›å»ºé™æ€å­—å¹•è§†é¢‘"""
    print("ä½¿ç”¨é™æ€å­—å¹•å¤‡é€‰æ–¹æ¡ˆ...")
    return create_9_16_video_with_title_ffmpeg(
        source_video, title_image, subtitle_image, 
        tts_audio, bgm_audio, output_path, duration, 
        title_position, subtitle_position, poster_image
    )

def create_optimized_video_with_ass_subtitles(source_video, title_image, ass_subtitle, tts_audio, bgm_audio, output_path, duration, title_position="top", poster_image=None, use_gpu=True, subtitle_position: str = "bottom", portrait_mode: bool=False):
    """
    ä½¿ç”¨ASSå­—å¹•çš„ä¼˜åŒ–è§†é¢‘åˆæˆ - ä¿®å¤FFmpegå…¼å®¹æ€§é—®é¢˜
    æ€§èƒ½ä¼˜åŒ–ï¼šå•æ¬¡FFmpegè°ƒç”¨ï¼ŒASSå­—å¹•çƒ§å½•ï¼ŒGPUç¡¬ä»¶åŠ é€Ÿ
    """
    print(f"ğŸš€ è¿›å…¥ASSå­—å¹•å‡½æ•° - portrait_mode: {portrait_mode}, subtitle_position: {subtitle_position}")
    ffmpeg = find_ffmpeg()
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å‚æ•°
    print(f"ğŸ” ASSå­—å¹•è°ƒè¯•ä¿¡æ¯ - portrait_mode: {portrait_mode}, subtitle_position: {subtitle_position}")
    
    target_width = 1080
    target_height = 1920
    
    # è®¡ç®—Titleä½ç½®
    title_margin = 200
    if title_position == "top":
        title_overlay_y = title_margin
    elif title_position == "center":
        title_overlay_y = f"(H-h)/2-100"
    else:
        title_overlay_y = f"H-h-{title_margin}"
    
    print(f"ğŸ¬ ASSå­—å¹•è§†é¢‘åˆæˆ:")
    print(f"   æºè§†é¢‘: {source_video}")
    print(f"   ASSå­—å¹•: {ass_subtitle}")
    print(f"   Titleä½ç½®: {title_position}")
    print(f"   æµ·æŠ¥èƒŒæ™¯: {'æ˜¯' if poster_image else 'å¦'}")
    
    # ä¿®å¤ASSå­—å¹•è·¯å¾„å¤„ç† - ç¡®ä¿Windowsè·¯å¾„å…¼å®¹æ€§
    ass_path_fixed = ass_subtitle.replace('\\', '/').replace('\\', '/')
    if ':' in ass_path_fixed:  # Windowsç»å¯¹è·¯å¾„
        ass_path_fixed = ass_path_fixed.replace(':', '\\:')
    
    print(f"   ğŸ”§ ä¿®å¤åçš„ASSè·¯å¾„: {ass_path_fixed}")
    
    # ğŸš€ ä¼˜åŒ–åçš„FFmpegæ»¤é•œé“¾ - å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç 
    if portrait_mode or subtitle_position == "template2":
        # ç«–å±æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨åŸå§‹è§†é¢‘ï¼Œä¸åšä»»ä½•ç¼©æ”¾å’ŒèƒŒæ™¯å¤„ç†ï¼Œä¿æŒ9:16æ¯”ä¾‹
        filter_complex = (
            f"[0:v]scale={target_width}:{target_height}[base];"
            f"[base]subtitles='{ass_path_fixed}'[with_subtitles];"
            f"[with_subtitles][1:v]overlay=0:{title_overlay_y}[video_out];"
            f"[2:a]volume=0.8,atrim=0:{duration}[tts];"
            f"[3:a]volume=0.15,atrim=0:{duration}[bgm];"
            f"[tts][bgm]amix=inputs=2:duration=shortest,atrim=0:{duration}[audio_out]"
        )
        
        # å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å‚æ•°
        gpu_decode_params = [
            '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
            '-hwaccel_output_format', 'cuda',      # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
            '-c:v', 'h264_cuvid'                   # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
        ]
        
        print(f"   ğŸš€ ASSå­—å¹•å¤„ç†å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç ")
        
        inputs = [
            ffmpeg, '-y',
            *gpu_decode_params,                        # GPUç¡¬ä»¶è§£ç å‚æ•°
            '-stream_loop', '-1', '-i', source_video,  # è¾“å…¥0: æºè§†é¢‘
            '-loop', '1', '-i', title_image,           # è¾“å…¥1: Titleå›¾ç‰‡
            '-i', tts_audio,                           # è¾“å…¥2: TTSéŸ³é¢‘
            '-i', bgm_audio,                           # è¾“å…¥3: BGMéŸ³é¢‘
        ]
    elif poster_image and poster_image != "" and os.path.exists(poster_image):
        # æœ‰æµ·æŠ¥èƒŒæ™¯çš„ç‰ˆæœ¬ - å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç 
        filter_complex = (
            f"[4:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}[bg];"
            f"[0:v]scale={target_width}:{target_width*9//16}[fg];"
            f"[bg][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];"
            f"[bg_with_fg]subtitles='{ass_path_fixed}'[with_subtitles];"
            f"[with_subtitles][1:v]overlay=0:{title_overlay_y}[video_out];"
            f"[2:a]volume=0.8,atrim=0:{duration}[tts];"
            f"[3:a]volume=0.15,atrim=0:{duration}[bgm];"
            f"[tts][bgm]amix=inputs=2:duration=shortest,atrim=0:{duration}[audio_out]"
        )
        
        # å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å‚æ•°
        gpu_decode_params = [
            '-hwaccel', 'cuda',
            '-hwaccel_output_format', 'cuda',
            '-c:v', 'h264_cuvid'
        ]
        
        inputs = [
            ffmpeg, '-y',
            *gpu_decode_params,                        # GPUç¡¬ä»¶è§£ç å‚æ•°
            '-stream_loop', '-1', '-i', source_video,  # è¾“å…¥0: æºè§†é¢‘
            '-loop', '1', '-i', title_image,           # è¾“å…¥1: Titleå›¾ç‰‡
            '-i', tts_audio,                           # è¾“å…¥2: TTSéŸ³é¢‘
            '-i', bgm_audio,                           # è¾“å…¥3: BGMéŸ³é¢‘
            '-loop', '1', '-i', poster_image,          # è¾“å…¥4: æµ·æŠ¥èƒŒæ™¯
        ]
    else:
        # æ— æµ·æŠ¥èƒŒæ™¯çš„ç‰ˆæœ¬ï¼ˆç®€åŒ–æ¨¡ç³ŠèƒŒæ™¯ï¼‰- å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç 
        filter_complex = (
            f"[0:v]scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height},boxblur=20:20[bg];"
            f"[0:v]scale={target_width}:{target_width*9//16}[fg];"
            f"[bg][fg]overlay=(W-w)/2:(H-h)/2[bg_with_fg];"
            f"[bg_with_fg]subtitles='{ass_path_fixed}'[with_subtitles];"
            f"[with_subtitles][1:v]overlay=0:{title_overlay_y}[video_out];"
            f"[2:a]volume=0.8,atrim=0:{duration}[tts];"
            f"[3:a]volume=0.15,atrim=0:{duration}[bgm];"
            f"[tts][bgm]amix=inputs=2:duration=shortest,atrim=0:{duration}[audio_out]"
        )
        
        # å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å‚æ•°
        gpu_decode_params = [
            '-hwaccel', 'cuda',
            '-hwaccel_output_format', 'cuda',
            '-c:v', 'h264_cuvid'
        ]
        
        inputs = [
            ffmpeg, '-y',
            *gpu_decode_params,                        # GPUç¡¬ä»¶è§£ç å‚æ•°
            '-stream_loop', '-1', '-i', source_video,  # è¾“å…¥0: æºè§†é¢‘
            '-loop', '1', '-i', title_image,           # è¾“å…¥1: Titleå›¾ç‰‡
            '-i', tts_audio,                           # è¾“å…¥2: TTSéŸ³é¢‘
            '-i', bgm_audio,                           # è¾“å…¥3: BGMéŸ³é¢‘
        ]
    
    # è·å–å®‰å…¨çš„ç¼–ç å‚æ•°
    try:
        encoding_params = get_gpu_encoding_params(use_gpu, 'fast')
        print(f"   ğŸ”§ ä½¿ç”¨ç¼–ç å‚æ•°: {encoding_params}")
    except Exception as e:
        print(f"   âš ï¸ GPUç¼–ç å‚æ•°è·å–å¤±è´¥: {e}ï¼Œä½¿ç”¨CPUç¼–ç ")
        encoding_params = ['-c:v', 'libx264', '-preset', 'fast', '-crf', '23']
    
    # æ„å»ºå®Œæ•´å‘½ä»¤ - å¢å¼ºé”™è¯¯å¤„ç†
    cmd = inputs + [
        '-filter_complex', filter_complex,
        '-map', '[video_out]',
        '-map', '[audio_out]',
        '-t', str(duration),
        *encoding_params,
        '-c:a', 'aac',
        '-b:a', '128k',
        '-movflags', '+faststart',
        '-avoid_negative_ts', 'make_zero',
        '-fflags', '+genpts',
        '-max_muxing_queue_size', '1024',  # å¢åŠ ç¼“å†²åŒºå¤§å°
        output_path
    ]
    
    try:
        print("   âš¡ å¼€å§‹ASSå­—å¹•FFmpegå¤„ç†...")
        
        # æ‰“å°å®Œæ•´çš„æ»¤é•œé“¾ç”¨äºè°ƒè¯•
        print(f"   ğŸ”§ æ»¤é•œé“¾: {filter_complex}")
        
        # æ‰“å°å‘½ä»¤ç”¨äºè°ƒè¯•ï¼ˆå»æ‰æ•æ„Ÿè·¯å¾„ä¿¡æ¯ï¼‰
        cmd_debug = [item.replace(os.getcwd(), '.') if isinstance(item, str) else str(item) for item in cmd]
        print(f"   ğŸ”§ FFmpegå‘½ä»¤: {' '.join(cmd_debug[:15])}...")
        
        # æ‰§è¡ŒFFmpegå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=False, timeout=1200)  # 5åˆ†é’Ÿè¶…æ—¶
        
        if result.returncode != 0:
            # å®‰å…¨åœ°è§£ç stderrï¼Œé¿å…ç¼–ç é”™è¯¯
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                try:
                    stderr_text = result.stderr.decode('gbk', errors='replace')
                except:
                    stderr_text = str(result.stderr)
            
            print(f"   âŒ FFmpegé”™è¯¯ (è¿”å›ç : {result.returncode}):")
            print(f"   {stderr_text}")
            
            # æ£€æŸ¥ç‰¹å®šçš„GPUç¼–ç é”™è¯¯ - å¢å¼ºé”™è¯¯æ£€æµ‹
            gpu_error_indicators = [
                '3221225477',  # Windowsè®¿é—®è¿è§„é”™è¯¯
                '0xc0000005',  # å¦ä¸€ç§è®¿é—®è¿è§„è¡¨ç¤º
                'access violation',  # è®¿é—®è¿è§„æ–‡æœ¬
                'out of memory',  # å†…å­˜ä¸è¶³
                'insufficient memory',  # å†…å­˜ä¸è¶³
                'failed locking bitstream buffer',  # NVENC bitstream bufferé”™è¯¯
                'invalid param (8)',  # NVENCå‚æ•°é”™è¯¯
                'error submitting video frame',  # å¸§æäº¤é”™è¯¯
                'error encoding a frame',  # ç¼–ç å¸§é”™è¯¯
                'nvenc',
                'cuda',
                'gpu',
                'device',
                'driver',
                'encoder initialization failed',  # ç¼–ç å™¨åˆå§‹åŒ–å¤±è´¥
                'cannot load encoder',  # æ— æ³•åŠ è½½ç¼–ç å™¨
                'hardware acceleration',  # ç¡¬ä»¶åŠ é€Ÿç›¸å…³
            ]
            
            is_gpu_error = any(indicator.lower() in stderr_text.lower() for indicator in gpu_error_indicators)
            
            # ç‰¹æ®Šå¤„ç†è®¿é—®è¿è§„é”™è¯¯
            is_access_violation = '3221225477' in stderr_text or '0xc0000005' in stderr_text.lower() or 'access violation' in stderr_text.lower()
            
            # å°è¯•ä½¿ç”¨CPUç¼–ç ä½œä¸ºå›é€€
            if use_gpu and (is_gpu_error or 'nvenc' in str(encoding_params)):
                if is_access_violation:
                    print("   ğŸš¨ GPUç¼–ç è®¿é—®è¿è§„é”™è¯¯ - å¯èƒ½æ˜¯GPUå†…å­˜ä¸è¶³æˆ–é©±åŠ¨å…¼å®¹æ€§é—®é¢˜")
                    print("   ğŸ’¡ å»ºè®®: 1) å…³é—­å…¶ä»–GPUåº”ç”¨ 2) é‡å¯ç³»ç»Ÿ 3) æ›´æ–°GPUé©±åŠ¨")
                else:
                    print("   ğŸ”„ æ£€æµ‹åˆ°GPUç¼–ç é”™è¯¯ï¼Œå°è¯•CPUç¼–ç ...")
                    print(f"   ğŸ”§ é”™è¯¯ç±»å‹: {'GPUç›¸å…³é”™è¯¯' if is_gpu_error else 'NVENCç¼–ç å™¨é”™è¯¯'}")
                
                print("   ğŸ”„ GPUç¼–ç å¤±è´¥ï¼Œå°è¯•CPUç¼–ç ...")
                return create_optimized_video_with_ass_subtitles(
                    source_video, title_image, ass_subtitle, tts_audio, bgm_audio,
                    output_path, duration, title_position, poster_image, use_gpu=False
                )
            
            return False
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†…å®¹
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            print(f"   âŒ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {output_path}")
            return False
        
        print("   âœ… ASSå­—å¹•FFmpegå¤„ç†å®Œæˆ")
        return True
        
    except subprocess.TimeoutExpired:
        print(f"   âŒ FFmpegæ‰§è¡Œè¶…æ—¶ (5åˆ†é’Ÿ)")
        return False
    except Exception as e:
        print(f"   âŒ FFmpegæ‰§è¡Œå¤±è´¥: {e}")
        return False

def create_optimized_video_with_ass_subtitles_gpu_enhanced(source_video, title_image, ass_subtitle, 
                                                          tts_audio, bgm_audio, output_path, duration, 
                                                          title_position="top", poster_image=None, 
                                                          subtitle_position="bottom", thread_id=1):
    """
    GPUå¢å¼ºçš„ASSå­—å¹•è§†é¢‘åˆæˆ - ä¸“ä¸ºå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ä¼˜åŒ–
    å‡å°‘CPUè´Ÿè½½ï¼Œå¼ºåˆ¶ä½¿ç”¨GPUåŠ é€Ÿ
    """
    print(f"ğŸš€ çº¿ç¨‹{thread_id}: è¿›å…¥GPUå¢å¼ºASSå­—å¹•åˆæˆ")
    ffmpeg = find_ffmpeg()
    
    target_width = 1080
    target_height = 1920
    
    # è®¡ç®—Titleä½ç½®
    title_margin = 200
    if title_position == "top":
        title_overlay_y = title_margin
    elif title_position == "center":
        title_overlay_y = f"(H-h)/2-100"
    else:
        title_overlay_y = f"H-h-{title_margin}"
    
    print(f"   çº¿ç¨‹{thread_id}: æºè§†é¢‘: {os.path.basename(source_video)}")
    print(f"   çº¿ç¨‹{thread_id}: å­—å¹•ä½ç½®: {subtitle_position}")
    
    # ä¿®å¤ASSå­—å¹•è·¯å¾„
    ass_path_fixed = ass_subtitle.replace('\\', '/').replace('\\', '/')
    if ':' in ass_path_fixed:
        ass_path_fixed = ass_path_fixed.replace(':', '\\:')
    
    # ğŸš€ å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç 
    gpu_decode_params = [
        '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
        '-hwaccel_output_format', 'cuda',      # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
        '-c:v', 'h264_cuvid'                   # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
    ]
    
    gpu_encode_params = [
        '-c:v', 'h264_nvenc',                  # å¼ºåˆ¶ä½¿ç”¨h264_nvencç¼–ç 
        '-preset', 'fast',
        '-crf', '23',
        '-profile:v', 'main',
        '-pix_fmt', 'yuv420p'
    ]
    
    print(f"   ğŸš€ çº¿ç¨‹{thread_id}: å¼ºåˆ¶ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç ")
    
    # ğŸš€ ä¼˜åŒ–çš„æ»¤é•œé“¾ - å‡å°‘CPUæ“ä½œï¼Œä¸“ä¸ºtemplate2ä¼˜åŒ–
    portrait_mode = subtitle_position == "template2"
    
    if portrait_mode:
        # ç«–å±æ¨¡å¼ï¼šç›´æ¥ç¼©æ”¾ï¼Œå‡å°‘å¤æ‚æ“ä½œ
        filter_complex = (
            f"[0:v]scale={target_width}:{target_height}:flags=fast_bilinear[base];"
            f"[base]subtitles='{ass_path_fixed}':fontsdir=fonts[with_subtitles];"
            f"[with_subtitles][1:v]overlay=0:{title_overlay_y}:format=auto[video_out];"
            f"[2:a]volume=0.8,aresample=44100[tts];"
            f"[3:a]volume=0.15,aresample=44100[bgm];"
            f"[tts][bgm]amix=inputs=2:duration=first[audio_out]"
        )
    else:
        # å…¶ä»–æ¨¡å¼çš„ç®€åŒ–å¤„ç†
        filter_complex = (
            f"[0:v]scale={target_width}:{target_height}:flags=fast_bilinear[base];"
            f"[base]subtitles='{ass_path_fixed}':fontsdir=fonts[with_subtitles];"
            f"[with_subtitles][1:v]overlay=0:{title_overlay_y}:format=auto[video_out];"
            f"[2:a]volume=0.8,aresample=44100[tts];"
            f"[3:a]volume=0.15,aresample=44100[bgm];"
            f"[tts][bgm]amix=inputs=2:duration=first[audio_out]"
        )
    
    # æ„å»ºä¼˜åŒ–çš„FFmpegå‘½ä»¤
    cmd = [
        ffmpeg, '-y',
        *gpu_decode_params,                        # GPUç¡¬ä»¶è§£ç 
        '-i', source_video,                        # è¾“å…¥0: æºè§†é¢‘
        '-loop', '1', '-i', title_image,           # è¾“å…¥1: Titleå›¾ç‰‡
        '-i', tts_audio,                           # è¾“å…¥2: TTSéŸ³é¢‘
        '-i', bgm_audio,                           # è¾“å…¥3: BGMéŸ³é¢‘
        '-filter_complex', filter_complex,
        '-map', '[video_out]',
        '-map', '[audio_out]',
        '-t', str(duration),
        *gpu_encode_params,                        # GPUç¼–ç å‚æ•°
        '-c:a', 'aac',
        '-b:a', '128k',
        '-movflags', '+faststart',
        '-threads', '2',                           # é™åˆ¶çº¿ç¨‹æ•°ï¼Œé¿å…èµ„æºç«äº‰
        output_path
    ]
    
    try:
        print(f"   âš¡ çº¿ç¨‹{thread_id}: å¼€å§‹GPUåŠ é€ŸFFmpegå¤„ç†...")
        
        # æ‰§è¡ŒFFmpegå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=False, timeout=600)
        
        if result.returncode != 0:
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                stderr_text = str(result.stderr)
            
            print(f"   âŒ çº¿ç¨‹{thread_id}: FFmpegé”™è¯¯: {stderr_text[:200]}...")
            
            # å¦‚æœGPUå¤±è´¥ï¼Œå°è¯•CPUå›é€€
            if 'nvenc' in stderr_text.lower() or 'cuda' in stderr_text.lower():
                print(f"   ğŸ”„ çº¿ç¨‹{thread_id}: GPUç¼–ç å¤±è´¥ï¼Œå›é€€åˆ°CPU")
                return create_optimized_video_with_ass_subtitles(
                    source_video, title_image, ass_subtitle, tts_audio, bgm_audio,
                    output_path, duration, title_position, poster_image, use_gpu=False,
                    subtitle_position=subtitle_position, portrait_mode=portrait_mode
                )
            
            return False
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            print(f"   âŒ çº¿ç¨‹{thread_id}: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            return False
        
        print(f"   âœ… çº¿ç¨‹{thread_id}: GPUå¢å¼ºFFmpegå¤„ç†å®Œæˆ")
        return True
        
    except subprocess.TimeoutExpired:
        print(f"   âŒ çº¿ç¨‹{thread_id}: FFmpegæ‰§è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"   âŒ çº¿ç¨‹{thread_id}: FFmpegæ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def find_ffmpeg():
    """æŸ¥æ‰¾FFmpegå¯æ‰§è¡Œæ–‡ä»¶"""
    possible_paths = [
        'ffmpeg',  # ç³»ç»ŸPATHä¸­
        'ffmpeg.exe',
        r'C:\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
        '/usr/bin/ffmpeg',
        '/usr/local/bin/ffmpeg'
    ]
    
    for path in possible_paths:
        try:
            subprocess.run([path, '-version'], capture_output=True, check=True, text=False)
            return path
        except (subprocess.CalledProcessError, FileNotFoundError):
            continue
    
    raise Exception("æœªæ‰¾åˆ°FFmpegï¼Œè¯·å®‰è£…FFmpegå¹¶æ·»åŠ åˆ°ç³»ç»ŸPATH")

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=False, timeout=10)
        if result.returncode == 0:
            try:
                output = result.stdout.decode('utf-8', errors='replace').strip()
                used, total = map(int, output.split(', '))
                usage_percent = (used / total) * 100
                
                print(f"ğŸ” GPUå†…å­˜ä½¿ç”¨: {used}MB / {total}MB ({usage_percent:.1f}%)")
                
                # å¦‚æœGPUå†…å­˜ä½¿ç”¨è¶…è¿‡80%ï¼Œå¯èƒ½å¯¼è‡´ç¼–ç å¤±è´¥
                if usage_percent > 80:
                    print("âš ï¸ GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯èƒ½å¯¼è‡´ç¼–ç å¤±è´¥")
                    return False
                return True
            except:
                return True  # è§£æå¤±è´¥æ—¶å‡è®¾å†…å­˜å……è¶³
        return True
    except Exception:
        return True  # æ£€æŸ¥å¤±è´¥æ—¶å‡è®¾å†…å­˜å……è¶³

def test_nvenc_encoder():
    """æµ‹è¯•NVENCç¼–ç å™¨æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ - å¢å¼ºå†…å­˜æ£€æŸ¥"""
    try:
        # å…ˆæ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        if not check_gpu_memory():
            print("âŒ GPUå†…å­˜ä¸è¶³ï¼Œè·³è¿‡NVENCæµ‹è¯•")
            return False
        
        ffmpeg = find_ffmpeg()
        
        # ä½¿ç”¨æç®€å‚æ•°è¿›è¡Œæµ‹è¯•ï¼Œé¿å…è®¿é—®è¿è§„
        test_cmd = [
            ffmpeg, '-y',
            '-f', 'lavfi',
            '-i', 'testsrc=duration=1:size=320x240:rate=1',
            '-c:v', 'h264_nvenc',
            '-preset', 'fast',  # æœ€å…¼å®¹çš„é¢„è®¾
            '-cq', '30',        # ä½¿ç”¨æ’å®šè´¨é‡ï¼Œé¿å…æ¯”ç‰¹ç‡æ§åˆ¶
            '-t', '1',
            '-f', 'null',
            '-'
        ]
        
        print(f"ğŸ§ª æµ‹è¯•NVENCç¼–ç å™¨: {' '.join(test_cmd[3:8])}...")
        result = subprocess.run(test_cmd, capture_output=True, text=False, timeout=15)
        
        if result.returncode == 0:
            print("âœ… NVENCç¼–ç å™¨æµ‹è¯•æˆåŠŸ")
            return True
        else:
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                stderr_text = str(result.stderr)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è®¿é—®è¿è§„é”™è¯¯
            if '3221225477' in stderr_text:
                print(f"âŒ NVENCè®¿é—®è¿è§„é”™è¯¯ (3221225477) - GPUå†…å­˜ä¸è¶³æˆ–é©±åŠ¨é—®é¢˜")
                print(f"ğŸ’¡ å»ºè®®: 1) å…³é—­å…¶ä»–GPUåº”ç”¨ 2) é‡å¯ç³»ç»Ÿ 3) é™ä½è§†é¢‘åˆ†è¾¨ç‡")
            else:
                print(f"âŒ NVENCç¼–ç å™¨æµ‹è¯•å¤±è´¥: {stderr_text[:200]}...")
            return False
            
    except Exception as e:
        print(f"âŒ NVENCç¼–ç å™¨æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def check_gpu_support():
    """æ£€æŸ¥GPUç¡¬ä»¶ç¼–ç æ”¯æŒ"""
    try:
        ffmpeg = find_ffmpeg()
        result = subprocess.run([ffmpeg, '-encoders'], capture_output=True, text=False)
        try:
            output = result.stdout.decode('utf-8', errors='replace').lower()
        except:
            output = str(result.stdout).lower()
        
        # æ£€æŸ¥NVIDIA NVENCæ”¯æŒ
        has_nvenc = 'h264_nvenc' in output or 'hevc_nvenc' in output
        
        # æ£€æŸ¥AMD AMFæ”¯æŒ
        has_amf = 'h264_amf' in output or 'hevc_amf' in output
        
        # æ£€æŸ¥Intel QSVæ”¯æŒ
        has_qsv = 'h264_qsv' in output or 'hevc_qsv' in output
        
        # æ£€æŸ¥NVENC APIç‰ˆæœ¬å…¼å®¹æ€§
        nvenc_version = check_nvenc_version()
        
        # å¦‚æœæ£€æµ‹åˆ°NVENCï¼Œè¿›è¡Œå®é™…æµ‹è¯•
        nvenc_working = False
        if has_nvenc:
            nvenc_working = test_nvenc_encoder()
        
        return {
            'nvenc': has_nvenc and nvenc_working,  # åªæœ‰é€šè¿‡æµ‹è¯•æ‰è®¤ä¸ºå¯ç”¨
            'amf': has_amf,
            'qsv': has_qsv,
            'any_gpu': (has_nvenc and nvenc_working) or has_amf or has_qsv,
            'nvenc_version': nvenc_version,
            'nvenc_compatible': nvenc_version >= 12.0 if nvenc_version else False,
            'nvenc_tested': nvenc_working
        }
    except Exception as e:
        print(f"æ£€æŸ¥GPUæ”¯æŒå¤±è´¥: {e}")
        return {'nvenc': False, 'amf': False, 'qsv': False, 'any_gpu': False, 'nvenc_version': None, 'nvenc_compatible': False}

def check_nvenc_version():
    """æ£€æŸ¥NVENC APIç‰ˆæœ¬"""
    try:
        # æ£€æŸ¥NVIDIAé©±åŠ¨ç‰ˆæœ¬
        result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'], 
                              capture_output=True, text=False)
        if result.returncode == 0:
            try:
                driver_version = result.stdout.decode('utf-8', errors='replace').strip()
            except:
                driver_version = str(result.stdout).strip()
            # å°†é©±åŠ¨ç‰ˆæœ¬è½¬æ¢ä¸ºNVENC APIç‰ˆæœ¬
            driver_num = float(driver_version.split('.')[0])
            
            if driver_num >= 570:
                return 13.0
            elif driver_num >= 560:
                return 12.2
            elif driver_num >= 550:
                return 12.1
            elif driver_num >= 540:
                return 12.0
            else:
                return 11.0
        return None
    except Exception:
        return None

def get_gpu_encoding_params(use_gpu=True, quality='balanced'):
    """
    ç»Ÿä¸€çš„GPUç¼–ç å‚æ•°è·å–å‡½æ•° - å¼ºåˆ¶ä½¿ç”¨h264_nvenc
    
    Args:
        use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        quality: ç¼–ç è´¨é‡ ('fast', 'balanced', 'quality')
    
    Returns:
        list: FFmpegç¼–ç å‚æ•°åˆ—è¡¨
    """
    # å¼ºåˆ¶ä½¿ç”¨GPUï¼Œé™¤éæ˜ç¡®æŒ‡å®šä¸ä½¿ç”¨
    if not use_gpu:
        print("ğŸ”§ ç”¨æˆ·æ˜ç¡®æŒ‡å®šä½¿ç”¨CPUç¼–ç ")
        return [
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '23'
        ]
    
    # å¼ºåˆ¶ä½¿ç”¨h264_nvencç¼–ç 
    print("ğŸš€ ä½¿ç”¨GPUç¡¬ä»¶ç¼–ç  (h264_nvenc)")
    
    base_params = [
        '-c:v', 'h264_nvenc',
        '-preset', 'fast',
        '-profile:v', 'main',
        '-pix_fmt', 'yuv420p'
    ]
    
    # æ ¹æ®è´¨é‡çº§åˆ«è°ƒæ•´å‚æ•°
    if quality == 'fast':
        return base_params + [
            '-crf', '28',
            '-b:v', '5M',
            '-maxrate', '8M',
            '-bufsize', '10M'
        ]
    elif quality == 'quality':
        return base_params + [
            '-crf', '20',
            '-b:v', '10M',
            '-maxrate', '15M',
            '-bufsize', '20M'
        ]
    else:  # balanced
        return base_params + [
            '-crf', '23',
            '-b:v', '8M',
            '-maxrate', '12M',
            '-bufsize', '16M'
        ]

def _get_safe_nvenc_params(quality):
    """
    è·å–ä¿®å¤NVENCç¼–ç é”™è¯¯çš„å®‰å…¨å‚æ•°
    è§£å†³"Failed locking bitstream buffer: invalid param (8)"é”™è¯¯
    åŸºäºå®é™…æµ‹è¯•ç»“æœçš„æœ€ä½³å‚æ•°ç»„åˆ
    """
    print("ğŸ”§ ä½¿ç”¨ä¿®å¤åçš„NVENCå‚æ•° (è§£å†³bitstream bufferé”™è¯¯)")

    # åŸºäºæµ‹è¯•ç»“æœçš„æœ€ä½³å‚æ•° - å…¼å®¹æ€§ä¼˜å…ˆ
    # è¿™äº›å‚æ•°åœ¨æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œç¼–ç æ—¶é—´æœ€çŸ­ä¸”ç¨³å®š
    base_params = [
        '-c:v', 'h264_nvenc',
        '-preset', 'fast',         # ä½¿ç”¨fasté¢„è®¾ï¼Œé¿å…å¤æ‚å‚æ•°
        '-profile:v', 'main',      # å¼ºåˆ¶ä½¿ç”¨main profile
        '-level', '4.1',           # è®¾ç½®å…¼å®¹çš„level
        '-pix_fmt', 'yuv420p',     # å¼ºåˆ¶åƒç´ æ ¼å¼ï¼Œé¿å…æ ¼å¼å†²çª
        '-gpu', '0',               # æŒ‡å®šGPUè®¾å¤‡
    ]

    # æ ¹æ®è´¨é‡çº§åˆ«è°ƒæ•´å‚æ•° - ä½¿ç”¨ç®€åŒ–å‚æ•°é¿å…bitstream bufferé”™è¯¯
    if quality == 'fast':
        return base_params + [
            '-cq', '30',           # è¾ƒä½è´¨é‡ï¼Œæ›´å¿«ç¼–ç 
            '-b:v', '5M',          # ä¿å®ˆçš„æ¯”ç‰¹ç‡è®¾ç½®
            '-maxrate', '8M',      # ä¿å®ˆçš„æœ€å¤§æ¯”ç‰¹ç‡
            '-bufsize', '10M',     # è¾ƒå°çš„ç¼“å†²åŒºé¿å…å†…å­˜é—®é¢˜
        ]
    elif quality == 'quality':
        return base_params + [
            '-cq', '22',           # é«˜è´¨é‡ä½†ä¸è¿‡åº¦
            '-b:v', '8M',          # é€‚ä¸­çš„æ¯”ç‰¹ç‡
            '-maxrate', '12M',     # é€‚ä¸­çš„æœ€å¤§æ¯”ç‰¹ç‡
            '-bufsize', '16M',     # é€‚ä¸­çš„ç¼“å†²åŒº
        ]
    else:  # balanced
        return base_params + [
            '-cq', '25',           # å¹³è¡¡è´¨é‡
            '-b:v', '6M',          # å¹³è¡¡æ¯”ç‰¹ç‡
            '-maxrate', '10M',     # å¹³è¡¡æœ€å¤§æ¯”ç‰¹ç‡
            '-bufsize', '12M',     # å¹³è¡¡ç¼“å†²åŒº
        ]

def _handle_nvenc_encoding_error(stderr_text: str, quality: str = 'balanced'):
    """
    å¤„ç†NVENCç¼–ç é”™è¯¯å¹¶æä¾›æ¢å¤æ–¹æ¡ˆ
    ä¸“é—¨å¤„ç†"Failed locking bitstream buffer: invalid param (8)"ç­‰é”™è¯¯
    """
    print("ğŸš¨ æ£€æµ‹åˆ°NVENCç¼–ç é”™è¯¯ï¼Œå¯åŠ¨é”™è¯¯æ¢å¤æœºåˆ¶")

    # åˆ†æé”™è¯¯ç±»å‹
    error_type = "unknown"
    if "failed locking bitstream buffer" in stderr_text.lower():
        error_type = "bitstream_buffer_lock"
        print("   ğŸ” é”™è¯¯ç±»å‹: Bitstream Bufferé”å®šå¤±è´¥")
    elif "error submitting video frame" in stderr_text.lower():
        error_type = "frame_submission"
        print("   ğŸ” é”™è¯¯ç±»å‹: è§†é¢‘å¸§æäº¤å¤±è´¥")
    elif "error encoding a frame" in stderr_text.lower():
        error_type = "frame_encoding"
        print("   ğŸ” é”™è¯¯ç±»å‹: å¸§ç¼–ç å¤±è´¥")
    elif "invalid param" in stderr_text.lower():
        error_type = "invalid_param"
        print("   ğŸ” é”™è¯¯ç±»å‹: æ— æ•ˆå‚æ•°")

    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ¢å¤å‚æ•°
    recovery_params = _get_nvenc_recovery_params(error_type, quality)

    print(f"   ğŸ”§ åº”ç”¨æ¢å¤å‚æ•°: {' '.join(recovery_params[:6])}...")
    return recovery_params

def _get_nvenc_recovery_params(error_type: str, quality: str = 'balanced'):
    """
    è·å–NVENCé”™è¯¯æ¢å¤å‚æ•°
    åŸºäºé”™è¯¯ç±»å‹æä¾›æœ€ä¿å®ˆçš„ç¼–ç å‚æ•°
    """
    # æœ€åŸºç¡€çš„æ¢å¤å‚æ•° - æç®€é…ç½®
    base_recovery_params = [
        '-c:v', 'h264_nvenc',
        '-preset', 'fast',         # å›ºå®šä½¿ç”¨fasté¢„è®¾
        '-profile:v', 'baseline',  # ä½¿ç”¨æœ€å…¼å®¹çš„baseline profile
        '-level', '3.1',           # é™ä½levelé¿å…å¤æ‚ç‰¹æ€§
        '-pix_fmt', 'yuv420p',     # å¼ºåˆ¶åƒç´ æ ¼å¼
    ]

    if error_type == "bitstream_buffer_lock":
        # Bitstream bufferé”å®šå¤±è´¥ - å‡å°‘å†…å­˜ä½¿ç”¨
        return base_recovery_params + [
            '-cq', '28',           # ä½¿ç”¨æ’å®šè´¨é‡é¿å…æ¯”ç‰¹ç‡æ§åˆ¶å¤æ‚æ€§
            '-bufsize', '4M',      # æå°çš„ç¼“å†²åŒº
            '-rc', 'cqp',          # ä½¿ç”¨æ’å®šé‡åŒ–å‚æ•°æ¨¡å¼
        ]
    elif error_type == "frame_submission":
        # å¸§æäº¤å¤±è´¥ - ç®€åŒ–å¸§å¤„ç†
        return base_recovery_params + [
            '-cq', '30',           # è¾ƒä½è´¨é‡
            '-g', '30',            # å›ºå®šGOPå¤§å°
            '-bf', '0',            # ç¦ç”¨Bå¸§
        ]
    elif error_type == "invalid_param":
        # å‚æ•°æ— æ•ˆ - ä½¿ç”¨æœ€ç®€å‚æ•°
        return [
            '-c:v', 'h264_nvenc',
            '-preset', 'fast',
            '-cq', '28',
        ]
    else:
        # é€šç”¨æ¢å¤å‚æ•°
        return base_recovery_params + [
            '-cq', '28',
            '-b:v', '3M',
            '-maxrate', '5M',
            '-bufsize', '6M',
        ]

def detect_video_codec(video_path):
    """
    æ£€æµ‹è§†é¢‘æ–‡ä»¶çš„ç¼–è§£ç å™¨

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        str: ç¼–è§£ç å™¨åç§° ('h264', 'hevc', 'av1', 'unknown')
    """
    try:
        ffmpeg = find_ffmpeg()
        cmd = [
            ffmpeg, '-i', video_path,
            '-t', '0.1',  # åªæ£€æŸ¥0.1ç§’
            '-f', 'null', '-'
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        stderr_output = result.stderr.lower()

        # æ£€æµ‹ç¼–è§£ç å™¨
        if 'hevc' in stderr_output or 'h.265' in stderr_output or 'hev1' in stderr_output:
            return 'hevc'
        elif 'h264' in stderr_output or 'h.264' in stderr_output or 'avc1' in stderr_output:
            return 'h264'
        elif 'av1' in stderr_output or 'av01' in stderr_output:
            return 'av1'
        else:
            print(f"âš ï¸ æœªè¯†åˆ«çš„ç¼–è§£ç å™¨ï¼ŒFFmpegè¾“å‡º: {stderr_output[:200]}")
            return 'unknown'

    except Exception as e:
        print(f"âš ï¸ ç¼–è§£ç å™¨æ£€æµ‹å¤±è´¥: {e}")
        return 'unknown'

def get_gpu_decoding_params(codec='h264'):
    """
    è·å–GPUç¡¬ä»¶è§£ç å‚æ•° - æ”¯æŒå¤šç§ç¼–è§£ç å™¨

    Args:
        codec: è§†é¢‘ç¼–è§£ç å™¨ ('h264', 'hevc', 'av1')

    Returns:
        list: GPUè§£ç å‚æ•°åˆ—è¡¨
    """
    try:
        gpu_support = check_gpu_support()

        if gpu_support.get('nvenc', False):
            # æ ¹æ®ç¼–è§£ç å™¨é€‰æ‹©å¯¹åº”çš„CUVIDè§£ç å™¨
            decoder_map = {
                'h264': 'h264_cuvid',
                'hevc': 'hevc_cuvid',
                'av1': 'av1_cuvid'
            }

            decoder = decoder_map.get(codec, 'h264_cuvid')
            print(f"ğŸš€ å¯ç”¨NVIDIAç¡¬ä»¶è§£ç åŠ é€Ÿ ({codec} -> {decoder})")

            return [
                '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
                '-hwaccel_output_format', 'cuda',      # è¾“å‡ºæ ¼å¼ä¿æŒåœ¨GPU
                '-extra_hw_frames', '8',               # é¢å¤–ç¡¬ä»¶å¸§ç¼“å†²
                '-c:v', decoder,                       # ä½¿ç”¨å¯¹åº”çš„CUVIDç¡¬ä»¶è§£ç å™¨
            ]
        elif gpu_support.get('amf', False):
            print("ğŸš€ å¯ç”¨AMDç¡¬ä»¶è§£ç åŠ é€Ÿ")
            return [
                '-hwaccel', 'd3d11va',                 # AMDç¡¬ä»¶åŠ é€Ÿ
                '-hwaccel_output_format', 'd3d11',     # D3D11è¾“å‡ºæ ¼å¼
            ]
        elif gpu_support.get('qsv', False):
            print("ğŸš€ å¯ç”¨Intelç¡¬ä»¶è§£ç åŠ é€Ÿ")
            return [
                '-hwaccel', 'qsv',                     # Intel QSVç¡¬ä»¶åŠ é€Ÿ
                '-hwaccel_output_format', 'qsv',       # QSVè¾“å‡ºæ ¼å¼
            ]
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°GPUè§£ç æ”¯æŒï¼Œä½¿ç”¨CPUè§£ç ")
            return []

    except Exception as e:
        print(f"âš ï¸ GPUè§£ç å‚æ•°è·å–å¤±è´¥: {e}")
        return []

def get_gpu_filter_params():
    """è·å–GPUåŠ é€Ÿæ»¤é•œå‚æ•° - åœ¨GPUä¸Šæ‰§è¡Œæ»¤é•œæ“ä½œ"""
    try:
        gpu_support = check_gpu_support()

        if gpu_support.get('nvenc', False):
            return {
                'scale': 'scale_cuda',           # GPUç¼©æ”¾æ»¤é•œ
                'overlay': 'overlay_cuda',       # GPUå åŠ æ»¤é•œ
                'format': 'hwupload_cuda',       # ä¸Šä¼ åˆ°GPUå†…å­˜
                'download': 'hwdownload',        # ä»GPUä¸‹è½½
            }
        else:
            return {
                'scale': 'scale',
                'overlay': 'overlay',
                'format': '',
                'download': '',
            }
    except Exception:
        return {
            'scale': 'scale',
            'overlay': 'overlay',
            'format': '',
            'download': '',
        }

def gpu_accelerated_video_composition(video_paths, output_path, composition_type='concat', **kwargs):
    """
    GPUåŠ é€Ÿè§†é¢‘åˆæˆå‡½æ•° - å……åˆ†åˆ©ç”¨RTX 3090æ€§èƒ½

    Args:
        video_paths: è¾“å…¥è§†é¢‘è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        composition_type: åˆæˆç±»å‹ ('concat', 'overlay', 'grid', 'pip')
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        bool: åˆæˆæ˜¯å¦æˆåŠŸ
    """
    print(f"ğŸš€ GPUåŠ é€Ÿè§†é¢‘åˆæˆ: {composition_type}")
    print(f"   è¾“å…¥è§†é¢‘æ•°é‡: {len(video_paths)}")
    print(f"   è¾“å‡ºè·¯å¾„: {os.path.basename(output_path)}")

    try:
        # æ£€æµ‹è§†é¢‘ç¼–è§£ç å™¨
        codecs = []
        for video_path in video_paths:
            codec = detect_video_codec(video_path)
            codecs.append(codec)
            print(f"   æ£€æµ‹åˆ°ç¼–è§£ç å™¨: {os.path.basename(video_path)} -> {codec}")

        # é€‰æ‹©ä¸»è¦ç¼–è§£ç å™¨
        from collections import Counter
        codec_counts = Counter(codec for codec in codecs if codec != 'unknown')
        primary_codec = codec_counts.most_common(1)[0][0] if codec_counts else 'h264'
        print(f"   ä½¿ç”¨ä¸»è¦ç¼–è§£ç å™¨: {primary_codec}")

        # è·å–å¯¹åº”çš„GPUå‚æ•°
        gpu_decode_params = get_gpu_decoding_params(primary_codec)
        gpu_encode_params = get_gpu_encoding_params(use_gpu=True, quality='balanced')
        gpu_filters = get_gpu_filter_params()

        # æ„å»ºåŸºç¡€å‘½ä»¤
        ffmpeg = find_ffmpeg()
        cmd = [ffmpeg, '-y']

        # æ·»åŠ GPUè§£ç å‚æ•°åˆ°æ¯ä¸ªè¾“å…¥
        inputs = []
        for video_path in video_paths:
            if gpu_decode_params:
                inputs.extend(gpu_decode_params)
            inputs.extend(['-i', video_path])

        cmd.extend(inputs)

        # æ ¹æ®åˆæˆç±»å‹æ„å»ºæ»¤é•œé“¾
        if composition_type == 'concat':
            # GPUåŠ é€Ÿæ‹¼æ¥
            filter_complex = _build_gpu_concat_filter(len(video_paths), gpu_filters)
        elif composition_type == 'grid':
            # GPUåŠ é€Ÿç½‘æ ¼å¸ƒå±€
            grid_size = kwargs.get('grid_size', (2, 2))
            output_size = kwargs.get('output_size', (1920, 1080))
            filter_complex = _build_gpu_grid_filter(len(video_paths), grid_size, output_size, gpu_filters)
        elif composition_type == 'overlay':
            # GPUåŠ é€Ÿå åŠ 
            positions = kwargs.get('positions', [(0, 0)])
            filter_complex = _build_gpu_overlay_filter(len(video_paths), positions, gpu_filters)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆæˆç±»å‹: {composition_type}")

        # æ·»åŠ æ»¤é•œé“¾
        cmd.extend(['-filter_complex', filter_complex])
        cmd.extend(['-map', '[out]'])

        # æ·»åŠ GPUç¼–ç å‚æ•°
        cmd.extend(gpu_encode_params)

        # éŸ³é¢‘å’Œè¾“å‡ºè®¾ç½®
        cmd.extend([
            '-c:a', 'aac',
            '-b:a', '192k',
            '-movflags', '+faststart',
            '-avoid_negative_ts', 'make_zero',
            output_path
        ])

        print(f"ğŸ”§ æ‰§è¡ŒGPUåŠ é€Ÿåˆæˆå‘½ä»¤...")
        result = subprocess.run(cmd, capture_output=True, text=False, timeout=600)

        if result.returncode == 0:
            print(f"âœ… GPUåŠ é€ŸåˆæˆæˆåŠŸ: {os.path.basename(output_path)}")
            return True
        else:
            stderr_text = result.stderr.decode('utf-8', errors='replace')
            print(f"âŒ GPUåˆæˆå¤±è´¥: {stderr_text}")
            return False

    except Exception as e:
        print(f"âŒ GPUåŠ é€Ÿåˆæˆå¼‚å¸¸: {e}")
        return False

def _build_gpu_concat_filter(num_videos, gpu_filters):
    """æ„å»ºGPUåŠ é€Ÿæ‹¼æ¥æ»¤é•œ"""
    if gpu_filters['scale'] == 'scale_cuda':
        # ä½¿ç”¨GPUæ»¤é•œ
        filter_parts = []
        for i in range(num_videos):
            filter_parts.append(f'[{i}:v]hwupload_cuda,scale_cuda=1920:1080[v{i}];')

        concat_inputs = "".join([f"[v{i}]" for i in range(num_videos)])
        filter_parts.append(f'{concat_inputs}concat=n={num_videos}:v=1:a=0,hwdownload,format=nv12[out]')

        return "".join(filter_parts)
    else:
        # å›é€€åˆ°CPUæ»¤é•œ
        filter_parts = []
        for i in range(num_videos):
            filter_parts.append(f'[{i}:v]scale=1920:1080[v{i}];')

        concat_inputs = "".join([f"[v{i}]" for i in range(num_videos)])
        filter_parts.append(f'{concat_inputs}concat=n={num_videos}:v=1:a=0[out]')

        return "".join(filter_parts)

def _build_gpu_grid_filter(num_videos, grid_size, output_size, gpu_filters):
    """æ„å»ºGPUåŠ é€Ÿç½‘æ ¼æ»¤é•œ"""
    rows, cols = grid_size
    output_width, output_height = output_size
    cell_width = output_width // cols
    cell_height = output_height // rows

    if gpu_filters['scale'] == 'scale_cuda':
        # GPUç½‘æ ¼æ»¤é•œ
        filter_parts = []

        # ä¸Šä¼ åˆ°GPUå¹¶ç¼©æ”¾
        for i in range(num_videos):
            filter_parts.append(f'[{i}:v]hwupload_cuda,scale_cuda={cell_width}:{cell_height}[v{i}];')

        # æ„å»ºç½‘æ ¼å¸ƒå±€
        if num_videos == 4:  # 2x2ç½‘æ ¼
            filter_parts.append('[v0][v1]hstack_cuda=inputs=2[top];')
            filter_parts.append('[v2][v3]hstack_cuda=inputs=2[bottom];')
            filter_parts.append('[top][bottom]vstack_cuda=inputs=2,hwdownload,format=nv12[out]')
        else:  # ç®€å•æ°´å¹³æ‹¼æ¥
            inputs = "".join([f"[v{i}]" for i in range(num_videos)])
            filter_parts.append(f'{inputs}hstack_cuda=inputs={num_videos},hwdownload,format=nv12[out]')

        return "".join(filter_parts)
    else:
        # CPUç½‘æ ¼æ»¤é•œ
        filter_parts = []
        for i in range(num_videos):
            filter_parts.append(f'[{i}:v]scale={cell_width}:{cell_height}[v{i}];')

        if num_videos == 4:
            filter_parts.append('[v0][v1]hstack=inputs=2[top];')
            filter_parts.append('[v2][v3]hstack=inputs=2[bottom];')
            filter_parts.append('[top][bottom]vstack=inputs=2[out]')
        else:
            inputs = "".join([f"[v{i}]" for i in range(num_videos)])
            filter_parts.append(f'{inputs}hstack=inputs={num_videos}[out]')

        return "".join(filter_parts)

def _get_safe_amf_params(quality):
    """è·å–å®‰å…¨çš„AMD AMFå‚æ•°"""
    print("ğŸ”§ ä½¿ç”¨å®‰å…¨çš„AMFå‚æ•°")
    
    base_params = ['-c:v', 'h264_amf']
    
    if quality == 'fast':
        return base_params + ['-b:v', '6M', '-maxrate', '8M']
    elif quality == 'quality':
        return base_params + ['-b:v', '10M', '-maxrate', '15M']
    else:  # balanced
        return base_params + ['-b:v', '8M', '-maxrate', '12M']

def _get_safe_qsv_params(quality):
    """è·å–å®‰å…¨çš„Intel QSVå‚æ•°"""
    print("ğŸ”§ ä½¿ç”¨å®‰å…¨çš„QSVå‚æ•°")
    
    base_params = ['-c:v', 'h264_qsv']
    
    if quality == 'fast':
        return base_params + ['-preset', 'fast', '-b:v', '6M']
    elif quality == 'quality':
        return base_params + ['-preset', 'slow', '-b:v', '10M']
    else:  # balanced
        return base_params + ['-preset', 'medium', '-b:v', '8M']

def _get_default_nvenc_params(quality):
    """è·å–é»˜è®¤NVIDIA NVENCå‚æ•° - å…¼å®¹ä¸åŒAPIç‰ˆæœ¬"""
    gpu_support = check_gpu_support()
    nvenc_version = gpu_support.get('nvenc_version', 12.0)
    
    print(f"ğŸ”§ æ£€æµ‹åˆ°NVENC APIç‰ˆæœ¬: {nvenc_version}")
    
    # åŸºç¡€å‚æ•°
    base_params = ['-c:v', 'h264_nvenc', '-gpu', '0']
    
    # æ ¹æ®APIç‰ˆæœ¬é€‰æ‹©å…¼å®¹çš„å‚æ•°
    if nvenc_version >= 13.0:
        # æ–°ç‰ˆæœ¬API (é©±åŠ¨570+)
        print("âœ… ä½¿ç”¨æ–°ç‰ˆNVENCå‚æ•°")
        base_params.extend(['-rc', 'vbr'])
        
        if quality == 'fast':
            return base_params + ['-preset', 'p1', '-cq', '28', '-b:v', '8M', '-maxrate', '12M', '-bufsize', '16M']
        elif quality == 'quality':
            return base_params + ['-preset', 'p7', '-cq', '19', '-b:v', '12M', '-maxrate', '18M', '-bufsize', '24M']
        else:  # balanced
            return base_params + ['-preset', 'p4', '-cq', '23', '-b:v', '10M', '-maxrate', '15M', '-bufsize', '20M']
    
    else:
        # æ—§ç‰ˆæœ¬APIå…¼å®¹æ¨¡å¼ (é©±åŠ¨560-569)
        print("âš ï¸ ä½¿ç”¨å…¼å®¹ç‰ˆNVENCå‚æ•°")
        base_params.extend(['-rc', 'cbr'])  # ä½¿ç”¨CBRæ¨¡å¼æ›´å…¼å®¹
        
        if quality == 'fast':
            return base_params + ['-preset', 'fast', '-b:v', '8M', '-maxrate', '12M', '-bufsize', '16M']
        elif quality == 'quality':
            return base_params + ['-preset', 'slow', '-b:v', '12M', '-maxrate', '18M', '-bufsize', '24M']
        else:  # balanced
            return base_params + ['-preset', 'medium', '-b:v', '10M', '-maxrate', '15M', '-bufsize', '20M']

def _get_default_amf_params(quality):
    """è·å–é»˜è®¤AMD AMFå‚æ•°"""
    return [
        '-c:v', 'h264_amf', '-quality', 'balanced', '-rc', 'vbr_peak',
        '-qp_i', '22', '-qp_p', '24', '-b:v', '10M', '-maxrate', '15M'
    ]

def _get_default_qsv_params(quality):
    """è·å–é»˜è®¤Intel QSVå‚æ•°"""
    return [
        '-c:v', 'h264_qsv', '-preset', 'medium', '-global_quality', '23',
        '-b:v', '10M', '-maxrate', '15M'
    ]

def concat_videos_ffmpeg(video_paths, output_path):
    """
    ä½¿ç”¨FFmpegæ‹¼æ¥å¤šä¸ªè§†é¢‘ç‰‡æ®µ - æ”¯æŒæ··åˆç¼–è§£ç å™¨

    Args:
        video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    if not video_paths:
        return False

    ffmpeg = find_ffmpeg()

    try:
        print(f"ğŸ¬ å¼€å§‹æ‹¼æ¥{len(video_paths)}ä¸ªè§†é¢‘ç‰‡æ®µ")

        # æ£€æµ‹æ‰€æœ‰è§†é¢‘çš„ç¼–è§£ç å™¨
        codecs = []
        for i, video_path in enumerate(video_paths):
            if os.path.exists(video_path):
                codec = detect_video_codec(video_path)
                codecs.append(codec)
                print(f"   è§†é¢‘{i+1}: {os.path.basename(video_path)} -> {codec}")
            else:
                print(f"   âš ï¸ è§†é¢‘{i+1}ä¸å­˜åœ¨: {video_path}")
                codecs.append('unknown')

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        concat_file = os.path.join(OUTPUT_DIR, f"concat_list_{str(uuid4())[:8]}.txt")

        with open(concat_file, 'w', encoding='utf-8') as f:
            for video_path in video_paths:
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
                abs_path = os.path.abspath(video_path)
                f.write(f"file '{abs_path}'\n")

        # åˆ¤æ–­æ˜¯å¦å¯ä»¥ä½¿ç”¨æµå¤åˆ¶æ¨¡å¼
        unique_codecs = set(codec for codec in codecs if codec != 'unknown')
        # å¼ºåˆ¶ä½¿ç”¨GPUåŠ é€Ÿæ‹¼æ¥ï¼Œä¸ä½¿ç”¨æµå¤åˆ¶æ¨¡å¼
        print("ğŸš€ å¼ºåˆ¶ä½¿ç”¨GPUåŠ é€Ÿæ‹¼æ¥æ¨¡å¼")

        # é€‰æ‹©ä¸»è¦ç¼–è§£ç å™¨ï¼ˆå‡ºç°æœ€å¤šçš„ï¼‰
        if codecs:
            from collections import Counter
            codec_counts = Counter(codec for codec in codecs if codec != 'unknown')
            primary_codec = codec_counts.most_common(1)[0][0] if codec_counts else 'h264'
        else:
            primary_codec = 'h264'

        print(f"   æ£€æµ‹åˆ°ç¼–è§£ç å™¨: {list(unique_codecs)}")
        print(f"   ä¸»è¦ç¼–è§£ç å™¨: {primary_codec}")

        # ä¿®å¤æ‹¼æ¥ï¼šä½¿ç”¨GPUè§£ç ä½†å…è®¸CPUæ ¼å¼è½¬æ¢ï¼Œé¿å…concatæ»¤é•œæ ¼å¼å†²çª
        cmd = [
            ffmpeg, '-y',
            '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿè§£ç 
            '-c:v', 'h264_cuvid',                  # å¼ºåˆ¶ä½¿ç”¨h264_cuvidè§£ç 
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c:v', 'h264_nvenc',                  # å¼ºåˆ¶ä½¿ç”¨h264_nvencç¼–ç 
            '-preset', 'fast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-movflags', '+faststart',
            output_path
        ]
        
        print("ğŸš€ ä½¿ç”¨GPUç¡¬ä»¶è§£ç å’Œç¼–ç æ‹¼æ¥è§†é¢‘ï¼ˆä¿®å¤concatæ ¼å¼å…¼å®¹æ€§ï¼‰")
        
        result = subprocess.run(cmd, capture_output=True, text=False)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(concat_file):
            os.remove(concat_file)
            
        if result.returncode != 0:
            try:
                stderr_text = result.stderr.decode('utf-8', errors='replace')
            except:
                stderr_text = str(result.stderr)
            print(f"FFmpegæ‹¼æ¥é”™è¯¯: {stderr_text}")
            return False

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(output_path):
            print(f"âŒ æ‹¼æ¥å¤±è´¥ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ {output_path}")
            return False

        # è·å–è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
        output_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        print(f"âœ… æˆåŠŸæ‹¼æ¥{len(video_paths)}ä¸ªç‰‡æ®µ")
        print(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size:.1f}MB")

        # æ‰“å°è§†é¢‘é“¾æ¥
        print(f"ğŸ”— æ‹¼æ¥åè§†é¢‘è·¯å¾„: {output_path}")
        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶å: {os.path.basename(output_path)}")


        return True
        
    except Exception as e:
        print(f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {e}")
        return False


def get_video_info(video_path):
    """è·å–è§†é¢‘ä¿¡æ¯ - ä½¿ç”¨GPUç¡¬ä»¶è§£ç """
    ffmpeg = find_ffmpeg()
    
    # å…ˆå°è¯•ä½¿ç”¨GPUç¡¬ä»¶è§£ç 
    cmd_gpu = [
        ffmpeg,
        '-hwaccel', 'cuda',                    # å¯ç”¨CUDAç¡¬ä»¶åŠ é€Ÿ
        '-c:v', 'h264_cuvid',                  # ä½¿ç”¨h264_cuvidè§£ç 
        '-i', video_path,
        '-t', '0.1',                           # åªå¤„ç†0.1ç§’ï¼Œå¿«é€Ÿè·å–ä¿¡æ¯
        '-f', 'null', '-'
    ]
    
    try:
        result = subprocess.run(cmd_gpu, capture_output=True, text=True, timeout=10)
        
        # å¦‚æœGPUè§£ç å¤±è´¥ï¼Œå›é€€åˆ°CPU
        if result.returncode != 0:
            print(f"GPUè§£ç è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥ï¼Œå›é€€åˆ°CPU: {os.path.basename(video_path)}")
            cmd_cpu = [
                ffmpeg, '-i', video_path,
                '-t', '0.1',
                '-f', 'null', '-'
            ]
            result = subprocess.run(cmd_cpu, capture_output=True, text=True, timeout=10)
        else:
            print(f"ğŸš€ ä½¿ç”¨GPUè§£ç è·å–è§†é¢‘ä¿¡æ¯: {os.path.basename(video_path)}")
        
        # ä»stderrä¸­è§£æè§†é¢‘ä¿¡æ¯
        output = result.stderr
        
        # æå–åˆ†è¾¨ç‡
        import re
        resolution_match = re.search(r'(\d+)x(\d+)', output)
        if resolution_match:
            width, height = map(int, resolution_match.groups())
        else:
            width, height = 1920, 1080  # é»˜è®¤å€¼
        
        # æå–æ—¶é•¿
        duration_match = re.search(r'Duration: (\d+):(\d+):(\d+\.\d+)', output)
        if duration_match:
            h, m, s = duration_match.groups()
            duration = int(h) * 3600 + int(m) * 60 + float(s)
        else:
            duration = 30.0  # é»˜è®¤å€¼
        
        return {
            'width': width,
            'height': height,
            'duration': duration
        }
    except Exception as e:
        print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return {'width': 1920, 'height': 1080, 'duration': 30.0}

def _process_single_video_optimized(video_index, video_count, local_video_paths, local_audio_paths, 
                                    local_poster_path, video_infos, duration_sec, title, scripts, 
                                    style, title_position, subtitle_position, req):
    """
    å•ä¸ªè§†é¢‘å¤„ç†å‡½æ•° - ç”¨äºå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
    ä¼˜åŒ–GPUä½¿ç”¨ï¼Œå‡å°‘CPUè´Ÿè½½
    """
    import asyncio
    import random
    import time
    from uuid import uuid4
    
    try:
        clip_start = time.time()
        clip_id = str(uuid4())[:8]
        
        print(f"\nğŸï¸  çº¿ç¨‹{video_index+1}: å¤„ç†è§†é¢‘ (ID: {clip_id})")
        
        # 3.1 è’™å¤ªå¥‡æ‹¼æ¥ï¼ˆä½¿ç”¨FFmpegï¼Œæ›´å¿«ï¼‰
        montage_start = time.time()
        temp_clips = []
        n_videos = len(local_video_paths)
        base_duration = duration_sec // n_videos
        remaining_duration = duration_sec % n_videos
        
        # å…³é”®æ”¹è¿›ï¼šä¸ºæ¯ä¸ªè§†é¢‘éšæœºæ‰“ä¹±ç´ æé¡ºåºï¼Œç¡®ä¿æ¯ä¸ªè§†é¢‘ä½¿ç”¨ä¸åŒçš„æ‹¼æ¥é¡ºåº
        # åˆ›å»ºç´¢å¼•åˆ—è¡¨å¹¶æ‰“ä¹±
        indices = list(range(n_videos))
        random.shuffle(indices)
        
        # ä½¿ç”¨æ‰“ä¹±åçš„ç´¢å¼•æ¥è®¿é—®è§†é¢‘è·¯å¾„å’Œè§†é¢‘ä¿¡æ¯
        for idx in indices:
            video_path = local_video_paths[idx]
            video_info = video_infos[idx]
            
            segment_duration = base_duration
            if len(temp_clips) < remaining_duration:
                segment_duration += 1
            
            if segment_duration <= 0:
                continue
                
            max_segment = min(segment_duration, int(video_info['duration']) - 1)
            if max_segment <= 0:
                continue
            
            max_start = max(0, video_info['duration'] - max_segment - 0.5)
            start_time = random.uniform(0, max_start) if max_start > 0 else 0
            
            temp_clip_path = os.path.join(OUTPUT_DIR, f"temp_segment_{clip_id}_{idx}.mp4")
            
            # ğŸš€ å¼ºåˆ¶ä½¿ç”¨GPUåŠ é€Ÿæå–ç‰‡æ®µ
            if extract_random_clip_ffmpeg(video_path, temp_clip_path, start_time, max_segment):
                temp_clips.append(temp_clip_path)
        
        if not temp_clips:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: æ— æœ‰æ•ˆç‰‡æ®µ")
            return None
        
        montage_clip_path = os.path.join(OUTPUT_DIR, f"montage_clip_{clip_id}.mp4")
        
        if len(temp_clips) == 1:
            import shutil
            shutil.copy2(temp_clips[0], montage_clip_path)
        else:
            if not concat_videos_ffmpeg(temp_clips, montage_clip_path):
                print(f"   âŒ çº¿ç¨‹{video_index+1}: æ‹¼æ¥å¤±è´¥")
                return None
        
        montage_time = time.time() - montage_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: è’™å¤ªå¥‡æ‹¼æ¥å®Œæˆï¼Œè€—æ—¶: {montage_time:.1f}ç§’")

        # 3.2 ç”ŸæˆTitleå›¾ç‰‡
        title_start = time.time()
        title_image_path = os.path.join(SUBTITLE_TEMP_DIR, f"title_{clip_id}.png")
        title_img = create_title_image(title, 1080, 1920, style)
        title_img.save(title_image_path)
        title_time = time.time() - title_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: æ ‡é¢˜å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {title_time:.1f}ç§’")

        # 3.3 å‡†å¤‡è„šæœ¬æ–‡æœ¬
        script = random.choice(scripts).content if scripts else "è¿™æ˜¯ä¸€æ®µç²¾å½©çš„è§†é¢‘å†…å®¹ï¼Œå±•ç°äº†å¤šä¸ªç²¾å½©ç¬é—´çš„å®Œç¾èåˆã€‚"
        
        # 3.4 ç”ŸæˆTTSéŸ³é¢‘ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰
        tts_start = time.time()
        tts_path = os.path.join(TTS_TEMP_DIR, f"tts_{clip_id}.wav")
        voice = 'zh-CN-YunxiNeural' if hasattr(req, 'voice') and req.voice == 'male' else 'zh-CN-XiaoxiaoNeural'
        
        # åœ¨çº¿ç¨‹ä¸­éœ€è¦åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥è°ƒç”¨å¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(generate_tts_audio(script, tts_path, voice))
        finally:
            loop.close()
        
        tts_time = time.time() - tts_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: TTSè¯­éŸ³ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {tts_time:.1f}ç§’")

        # 3.5 ç”ŸæˆASSå­—å¹•
        ass_start = time.time()
        
        # æ™ºèƒ½åˆ†å‰²æ–‡æœ¬
        sentences = split_text_into_screen_friendly_sentences(script, 1080, style)
        print(f"   ğŸ“ çº¿ç¨‹{video_index+1}: æ™ºèƒ½åˆ†å±åˆ†å‰²æˆ{len(sentences)}ä¸ªç‰‡æ®µ")
        
        # è¯»å–TTSå®é™…æ—¶é•¿
        try:
            from moviepy.audio.io.AudioFileClip import AudioFileClip
            audio_clip_tmp = AudioFileClip(tts_path)
            actual_tts_duration = audio_clip_tmp.duration
            audio_clip_tmp.close()
            
            target_duration = max(duration_sec, actual_tts_duration)
            print(f"   ğŸµ çº¿ç¨‹{video_index+1}: TTSæ—¶é•¿: {actual_tts_duration:.1f}sï¼Œç›®æ ‡æ—¶é•¿: {target_duration:.1f}s")
        except Exception as e:
            print(f"   âš ï¸  çº¿ç¨‹{video_index+1}: è¯»å–TTSæ—¶é•¿å¤±è´¥: {e}")
            target_duration = duration_sec
        
        # ç”ŸæˆASSå­—å¹•æ–‡ä»¶
        ass_subtitle_path = os.path.join(SUBTITLE_TEMP_DIR, f"subtitle_{clip_id}.ass")
        ass_generator.create_ass_file(
            sentences=sentences,
            total_duration=target_duration,
            style_config=style,
            output_path=ass_subtitle_path
        )
        
        ass_time = time.time() - ass_start
        print(f"   âœ… çº¿ç¨‹{video_index+1}: ASSå­—å¹•ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {ass_time:.1f}ç§’")

        # 3.6 æœ€ç»ˆè§†é¢‘åˆæˆï¼ˆå¼ºåˆ¶GPUåŠ é€Ÿï¼‰
        final_start = time.time()
        final_output = os.path.join(OUTPUT_DIR, f"optimized_{clip_id}.mp4")
        
        # å¤„ç†èƒŒæ™¯éŸ³ä¹
        bgm_audio = random.choice(local_audio_paths) if local_audio_paths else None
        silence_path = None
        if not bgm_audio or not os.path.exists(bgm_audio):
            silence_path = os.path.join(TTS_TEMP_DIR, f"silence_{clip_id}.wav")
            create_silence_audio(target_duration, silence_path)
            bgm_audio = silence_path

        # ğŸš€ ä½¿ç”¨ä¼˜åŒ–çš„GPUåŠ é€ŸFFmpegåˆæˆ
        try:
            success = create_optimized_video_with_ass_subtitles_gpu_enhanced(
                source_video=montage_clip_path,
                title_image=title_image_path,
                ass_subtitle=ass_subtitle_path,
                tts_audio=tts_path,
                bgm_audio=bgm_audio,
                output_path=final_output,
                duration=target_duration,
                title_position=title_position,
                poster_image=local_poster_path,
                subtitle_position=subtitle_position,
                thread_id=video_index+1  # ä¼ é€’çº¿ç¨‹IDç”¨äºæ—¥å¿—
            )
            
            final_time = time.time() - final_start
            print(f"   âœ… çº¿ç¨‹{video_index+1}: è§†é¢‘åˆæˆå®Œæˆï¼Œè€—æ—¶: {final_time:.1f}ç§’")
            
            if not success:
                print(f"   âŒ çº¿ç¨‹{video_index+1}: FFmpegå¤„ç†å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: è§†é¢‘åˆæˆå¼‚å¸¸: {e}")
            return None
        
        # ä¸Šä¼ åˆ°OSSï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
        upload_start = time.time()
        try:
            clip_name = f"optimized_{clip_id}.mp4"
            with open(final_output, 'rb') as f:
                video_content = f.read()
            
            # åœ¨çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥OSSä¸Šä¼ 
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                oss_url = loop.run_until_complete(oss_client.upload_to_oss(
                    file_buffer=video_content,
                    original_filename=clip_name,
                    folder=OSS_UPLOAD_FINAL_VEDIO
                ))
            finally:
                loop.close()
            
            # åŠ¨æ€è·å–ç«¯å£
            port = os.getenv("BACKEND_PORT", "8000")
            video_url = f"http://39.96.187.7:{port}/api/videos/oss-proxy?url={oss_url}"
            video_size = len(video_content)
            os.remove(final_output)
            
            upload_time = time.time() - upload_start
            print(f"   âœ… çº¿ç¨‹{video_index+1}: OSSä¸Šä¼ å®Œæˆï¼Œè€—æ—¶: {upload_time:.1f}ç§’")
            
        except Exception as e:
            print(f"   âŒ çº¿ç¨‹{video_index+1}: OSSä¸Šä¼ å¤±è´¥: {str(e)}")
            video_url = f"/outputs/clips/optimized_{clip_id}.mp4"
            video_size = os.path.getsize(final_output) if os.path.exists(final_output) else 0

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_files = temp_clips + [montage_clip_path, title_image_path, tts_path, ass_subtitle_path]
        if silence_path:
            cleanup_files.append(silence_path)
        
        for temp_file in cleanup_files:
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except Exception as e:
                    print(f"   âš ï¸ çº¿ç¨‹{video_index+1}: æ¸…ç†å¤±è´¥: {temp_file} - {e}")
        
        clip_time = time.time() - clip_start
        print(f"   ğŸ‰ çº¿ç¨‹{video_index+1}: å®Œæˆï¼Œæ€»è€—æ—¶: {clip_time:.1f}ç§’")
        
        return {
            "id": clip_id,
            "name": f"optimized_{clip_id}.mp4",
            "url": video_url,
            "size": video_size,
            "duration": target_duration,
            "uploadedAt": None,
            "thread_id": video_index+1,
            "processing_time": clip_time
        }
        
    except Exception as e:
        print(f"   âŒ çº¿ç¨‹{video_index+1}: å¤„ç†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None

def split_text_into_sentences(text, max_words_per_sentence=8):
    """å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆ"""
    if not text:
        return []
    
    import re
    
    # ä¸­æ–‡å¥å­åˆ†å‰²ç¬¦
    chinese_punctuation = 'ã€‚ï¼ï¼Ÿï¼›'
    # è‹±æ–‡å¥å­åˆ†å‰²ç¬¦
    english_punctuation = '.!?;'
    
    sentences = []
    current_sentence = ""
    
    # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
    for char in text:
        current_sentence += char
        if char in chinese_punctuation or char in english_punctuation:
            if current_sentence.strip():
                sentences.append(current_sentence.strip())
            current_sentence = ""
    
    # å¤„ç†æœ€åä¸€éƒ¨åˆ†
    if current_sentence.strip():
        sentences.append(current_sentence.strip())
    
    # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼ŒæŒ‰é•¿åº¦åˆ†å‰²
    if not sentences:
        words = text.split() if ' ' in text else list(text)
        for i in range(0, len(words), max_words_per_sentence):
            sentence = ''.join(words[i:i+max_words_per_sentence]) if ' ' not in text else ' '.join(words[i:i+max_words_per_sentence])
            if sentence:
                sentences.append(sentence)
    
    # ç¡®ä¿è‡³å°‘æœ‰ä¸€å¥
    if not sentences:
        sentences = [text]
    
    return sentences




def check_and_convert_video_if_needed(video_path, output_path=None):
    """æ£€æŸ¥å¹¶è½¬æ¢è§†é¢‘æ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§"""
    if not ENCODING_OPTIMIZATION_AVAILABLE:
        return video_path
    
    try:
        needs_conversion = check_video_needs_conversion(video_path)
        
        if not needs_conversion:
            print(f"âœ… è§†é¢‘æ ¼å¼å…¼å®¹: {os.path.basename(video_path)}")
            return video_path
        
        print(f"âš ï¸ æ£€æµ‹åˆ°å…¼å®¹æ€§é—®é¢˜: {os.path.basename(video_path)}")
        
        if output_path is None:
            base, ext = os.path.splitext(video_path)
            output_path = f"{base}_compatible{ext}"
        
        # ä½¿ç”¨ä¼˜åŒ–å‚æ•°è½¬æ¢è§†é¢‘
        from video_encoding_compatibility_optimizer import VideoEncodingCompatibilityOptimizer
        optimizer = VideoEncodingCompatibilityOptimizer()
        
        success = optimizer.convert_to_compatible_format(
            video_path, output_path, 'h264', 'balanced', True
        )
        
        if success:
            print(f"âœ… è§†é¢‘è½¬æ¢æˆåŠŸ: {os.path.basename(output_path)}")
            return output_path
        else:
            print(f"âŒ è§†é¢‘è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
            return video_path
            
    except Exception as e:
        print(f"âš ï¸ è§†é¢‘å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return video_path

