#!/usr/bin/env python3
"""
Tesla T4 GPUä¼˜åŒ–æ¨¡å—
ä¸“é—¨é’ˆå¯¹NVIDIA Tesla T4æ•°æ®ä¸­å¿ƒGPUçš„è§†é¢‘å¤„ç†ä¼˜åŒ–
"""

import os
import subprocess
import json
from typing import Dict, List, Optional, Tuple

class TeslaT4Optimizer:
    """Tesla T4 GPUä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.gpu_info = self._detect_tesla_t4()
        self.driver_version = self._get_driver_version()
        self.nvenc_support = self._check_nvenc_support()
        
    def _detect_tesla_t4(self) -> Dict:
        """æ£€æµ‹Tesla T4 GPU"""
        try:
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=name,memory.total,driver_version,compute_cap',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 4:
                        gpu_name = parts[0]
                        if 'Tesla T4' in gpu_name or 'T4' in gpu_name:
                            return {
                                'available': True,
                                'name': gpu_name,
                                'memory_mb': int(parts[1]),
                                'driver_version': parts[2],
                                'compute_capability': parts[3],
                                'is_tesla_t4': True
                            }
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°Tesla T4ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–NVIDIA GPU
                if lines and lines[0]:
                    parts = [p.strip() for p in lines[0].split(',')]
                    return {
                        'available': True,
                        'name': parts[0],
                        'memory_mb': int(parts[1]),
                        'driver_version': parts[2],
                        'compute_capability': parts[3] if len(parts) >= 4 else 'unknown',
                        'is_tesla_t4': False
                    }
            
            return {'available': False, 'reason': 'No NVIDIA GPU detected'}
            
        except Exception as e:
            return {'available': False, 'reason': f'Detection failed: {str(e)}'}
    
    def _get_driver_version(self) -> Optional[float]:
        """è·å–é©±åŠ¨ç‰ˆæœ¬å·"""
        if self.gpu_info.get('available') and 'driver_version' in self.gpu_info:
            try:
                version_str = self.gpu_info['driver_version']
                return float(version_str.split('.')[0])
            except:
                return None
        return None
    
    def _check_nvenc_support(self) -> bool:
        """æ£€æŸ¥NVENCç¼–ç å™¨æ”¯æŒ"""
        try:
            # æŸ¥æ‰¾FFmpeg
            ffmpeg_paths = ['ffmpeg', 'ffmpeg.exe']
            for ffmpeg_path in ffmpeg_paths:
                try:
                    result = subprocess.run([ffmpeg_path, '-encoders'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        return 'h264_nvenc' in result.stdout.lower()
                except:
                    continue
            return False
        except:
            return False
    
    def is_ready(self) -> Tuple[bool, str]:
        """æ£€æŸ¥Tesla T4æ˜¯å¦å‡†å¤‡å°±ç»ª"""
        if not self.gpu_info.get('available'):
            return False, self.gpu_info.get('reason', 'GPUä¸å¯ç”¨')
        
        if not self.nvenc_support:
            return False, 'FFmpegä¸æ”¯æŒNVENCç¼–ç å™¨'
        
        if not self.driver_version:
            return False, 'æ— æ³•è·å–é©±åŠ¨ç‰ˆæœ¬'
        
        if self.driver_version < 450:
            return False, f'é©±åŠ¨ç‰ˆæœ¬è¿‡æ—§ ({self.driver_version})ï¼Œå»ºè®®å‡çº§åˆ°450+ç‰ˆæœ¬'
        
        return True, 'Tesla T4 GPUå‡†å¤‡å°±ç»ª'
    
    def get_optimal_encoding_params(self, quality: str = 'balanced') -> List[str]:
        """
        è·å–Tesla T4ä¼˜åŒ–çš„ç¼–ç å‚æ•° - å…¼å®¹æ€§ä¼˜å…ˆç‰ˆæœ¬
        
        Tesla T4ç‰¹ç‚¹ï¼š
        - æ•°æ®ä¸­å¿ƒGPUï¼Œä¸“ä¸ºæ¨ç†å’Œç¼–ç ä¼˜åŒ–
        - æ”¯æŒæœ€æ–°çš„NVENCç¼–ç å™¨
        - 16GB GDDR6å†…å­˜ï¼Œé€‚åˆå¤§å‹è§†é¢‘å¤„ç†
        """
        ready, message = self.is_ready()
        if not ready:
            print(f"âš ï¸ Tesla T4ä¸å¯ç”¨: {message}")
            return self._get_cpu_fallback_params()
        
        print(f"ğŸš€ ä½¿ç”¨Tesla T4 GPUåŠ é€Ÿç¼–ç  (é©±åŠ¨ç‰ˆæœ¬: {self.driver_version}) - å…¼å®¹æ¨¡å¼")
        
        # Tesla T4å…¼å®¹æ€§ä¼˜å…ˆå‚æ•° - ç®€åŒ–ç‰ˆ
        base_params = [
            '-c:v', 'h264_nvenc',
            '-pix_fmt', 'yuv420p',         # æ ‡å‡†åƒç´ æ ¼å¼
        ]
        
        # ä½¿ç”¨æ›´å…¼å®¹çš„å‚æ•°ï¼Œé¿å…æ–°APIå¯èƒ½çš„é—®é¢˜
        if quality == 'fast':
            quality_params = [
                '-preset', 'fast',         # ä½¿ç”¨ä¼ ç»Ÿé¢„è®¾å
                '-rc', 'cbr',              # æ’å®šæ¯”ç‰¹ç‡
                '-b:v', '8M',
                '-maxrate', '12M',
                '-bufsize', '16M',
                '-profile:v', 'main',      # å…¼å®¹æ€§profile
                '-level', '4.1',           # å…¼å®¹level
            ]
        elif quality == 'quality':
            quality_params = [
                '-preset', 'slow',         # é«˜è´¨é‡ä¼ ç»Ÿé¢„è®¾
                '-rc', 'vbr_hq',           # é«˜è´¨é‡VBR
                '-cq', '19',
                '-b:v', '15M',
                '-maxrate', '20M',
                '-bufsize', '30M',
                '-profile:v', 'high',      # é«˜è´¨é‡profile
                '-level', '4.1',
            ]
        else:  # balanced
            quality_params = [
                '-preset', 'medium',       # å¹³è¡¡ä¼ ç»Ÿé¢„è®¾
                '-rc', 'vbr',              # æ ‡å‡†VBR
                '-cq', '23',
                '-b:v', '10M',
                '-maxrate', '15M',
                '-bufsize', '20M',
                '-profile:v', 'main',      # å¹³è¡¡profile
                '-level', '4.1',
            ]
        
        return base_params + quality_params
    
    def _get_new_api_params(self, quality: str) -> List[str]:
        """æ–°ç‰ˆé©±åŠ¨APIå‚æ•° (470+) - ä¿®å¤æ ¼å¼å…¼å®¹æ€§é—®é¢˜"""
        if quality == 'fast':
            return [
                '-preset', 'p1',           # æœ€å¿«é¢„è®¾
                '-tune', 'ull',            # è¶…ä½å»¶è¿Ÿ
                '-rc', 'cbr',              # æ’å®šæ¯”ç‰¹ç‡
                '-b:v', '8M',
                '-maxrate', '12M',
                '-bufsize', '16M',
                '-bf', '0',                # æ— Bå¸§ï¼Œé™ä½å»¶è¿Ÿ
                '-profile:v', 'main',      # å¼ºåˆ¶ä½¿ç”¨main profile
                '-level', '4.1',           # è®¾ç½®å…¼å®¹level
            ]
        elif quality == 'quality':
            return [
                '-preset', 'p7',           # æœ€é«˜è´¨é‡é¢„è®¾
                '-tune', 'hq',             # é«˜è´¨é‡è°ƒä¼˜
                '-rc', 'vbr',              # å¯å˜æ¯”ç‰¹ç‡
                '-cq', '19',               # é«˜è´¨é‡CQå€¼
                '-b:v', '15M',
                '-maxrate', '20M',
                '-bufsize', '30M',
                '-bf', '3',                # ä½¿ç”¨Bå¸§æé«˜å‹ç¼©ç‡
                '-profile:v', 'high',      # é«˜è´¨é‡profile
                '-level', '4.1',           # è®¾ç½®å…¼å®¹level
            ]
        else:  # balanced
            return [
                '-preset', 'p4',           # å¹³è¡¡é¢„è®¾
                '-tune', 'hq',             # é«˜è´¨é‡è°ƒä¼˜
                '-rc', 'vbr',              # å¯å˜æ¯”ç‰¹ç‡
                '-cq', '23',               # å¹³è¡¡çš„CQå€¼
                '-b:v', '10M',
                '-maxrate', '15M',
                '-bufsize', '20M',
                '-bf', '2',                # é€‚åº¦ä½¿ç”¨Bå¸§
                '-profile:v', 'main',      # å¹³è¡¡profile
                '-level', '4.1',           # è®¾ç½®å…¼å®¹level
            ]
    
    def _get_legacy_api_params(self, quality: str) -> List[str]:
        """æ—§ç‰ˆé©±åŠ¨å…¼å®¹å‚æ•° (450-469)"""
        if quality == 'fast':
            return [
                '-preset', 'fast',         # å¿«é€Ÿé¢„è®¾
                '-rc', 'cbr',              # æ’å®šæ¯”ç‰¹ç‡
                '-b:v', '8M',
                '-maxrate', '12M',
                '-bufsize', '16M',
                '-2pass', '0',             # å•æ¬¡ç¼–ç 
            ]
        elif quality == 'quality':
            return [
                '-preset', 'slow',         # é«˜è´¨é‡é¢„è®¾
                '-rc', 'vbr_hq',           # é«˜è´¨é‡VBR
                '-cq', '19',
                '-b:v', '15M',
                '-maxrate', '20M',
                '-bufsize', '30M',
                '-2pass', '1',             # åŒæ¬¡ç¼–ç 
            ]
        else:  # balanced
            return [
                '-preset', 'medium',       # å¹³è¡¡é¢„è®¾
                '-rc', 'vbr',              # å¯å˜æ¯”ç‰¹ç‡
                '-cq', '23',
                '-b:v', '10M',
                '-maxrate', '15M',
                '-bufsize', '20M',
            ]
    
    def _get_cpu_fallback_params(self) -> List[str]:
        """CPUå›é€€å‚æ•°"""
        return [
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '23',
            '-threads', str(os.cpu_count())
        ]
    
    def get_hardware_decode_params(self) -> List[str]:
        """è·å–ç¡¬ä»¶è§£ç å‚æ•° - ä¿®å¤æ ¼å¼å…¼å®¹æ€§"""
        ready, _ = self.is_ready()
        if not ready:
            return []
        
        # ä¸ä½¿ç”¨ cuda è¾“å‡ºæ ¼å¼ï¼Œé¿å…æ ¼å¼è½¬æ¢é—®é¢˜
        return [
            '-hwaccel', 'cuda'
        ]
    
    def get_gpu_filter_params(self) -> Dict[str, str]:
        """è·å–GPUæ»¤é•œå‚æ•°"""
        ready, _ = self.is_ready()
        if not ready:
            return {
                'scale': 'scale',
                'overlay': 'overlay',
                'format': '',
                'download': '',
            }
        
        return {
            'scale': 'scale_cuda',           # GPUç¼©æ”¾
            'overlay': 'overlay_cuda',       # GPUå åŠ 
            'format': 'hwupload_cuda',       # ä¸Šä¼ åˆ°GPU
            'download': 'hwdownload',        # ä»GPUä¸‹è½½
        }
    
    def optimize_ffmpeg_command(self, base_cmd: List[str], enable_gpu_filters: bool = True) -> List[str]:
        """ä¼˜åŒ–FFmpegå‘½ä»¤ä»¥ä½¿ç”¨Tesla T4"""
        ready, message = self.is_ready()
        if not ready:
            print(f"âš ï¸ Tesla T4ä¼˜åŒ–è·³è¿‡: {message}")
            return base_cmd
        
        optimized_cmd = base_cmd.copy()
        
        # æ·»åŠ ç¡¬ä»¶è§£ç 
        if '-i ' in ' '.join(optimized_cmd):
            # åœ¨ç¬¬ä¸€ä¸ªè¾“å…¥å‰æ·»åŠ ç¡¬ä»¶è§£ç å‚æ•°
            for i, arg in enumerate(optimized_cmd):
                if arg == '-i':
                    decode_params = self.get_hardware_decode_params()
                    optimized_cmd = optimized_cmd[:i] + decode_params + optimized_cmd[i:]
                    break
        
        # æ›¿æ¢CPUç¼–ç å™¨ä¸ºGPUç¼–ç å™¨
        for i, arg in enumerate(optimized_cmd):
            if arg == 'libx264':
                optimized_cmd[i] = 'h264_nvenc'
                # æ·»åŠ GPUç¼–ç å‚æ•°
                gpu_params = self.get_optimal_encoding_params('balanced')
                # ç§»é™¤é‡å¤çš„ç¼–ç å™¨å‚æ•°
                gpu_params = [p for p in gpu_params if p not in ['-c:v', 'h264_nvenc']]
                optimized_cmd = optimized_cmd[:i+1] + gpu_params + optimized_cmd[i+1:]
                break
        
        return optimized_cmd
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'gpu_available': self.gpu_info.get('available', False),
            'gpu_name': self.gpu_info.get('name', 'Unknown'),
            'is_tesla_t4': self.gpu_info.get('is_tesla_t4', False),
            'memory_mb': self.gpu_info.get('memory_mb', 0),
            'driver_version': self.driver_version,
            'nvenc_support': self.nvenc_support,
            'compute_capability': self.gpu_info.get('compute_capability', 'unknown')
        }
    
    def print_status(self):
        """æ‰“å°Tesla T4çŠ¶æ€"""
        print("ğŸ® Tesla T4 GPUçŠ¶æ€:")
        print("=" * 50)
        
        if self.gpu_info.get('available'):
            print(f"âœ… GPU: {self.gpu_info['name']}")
            print(f"ğŸ“Š å†…å­˜: {self.gpu_info['memory_mb']}MB")
            print(f"ğŸ”§ é©±åŠ¨ç‰ˆæœ¬: {self.driver_version}")
            print(f"âš¡ NVENCæ”¯æŒ: {'âœ…' if self.nvenc_support else 'âŒ'}")
            print(f"ğŸ¯ Tesla T4: {'âœ…' if self.gpu_info.get('is_tesla_t4') else 'âŒ'}")
            
            ready, message = self.is_ready()
            print(f"ğŸš€ çŠ¶æ€: {'å°±ç»ª' if ready else message}")
            
            if ready:
                print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                print("â€¢ è§†é¢‘ç¼–ç å°†ä½¿ç”¨GPUç¡¬ä»¶åŠ é€Ÿ")
                print("â€¢ é¢„æœŸæ€§èƒ½æå‡: 3-8å€ç¼–ç é€Ÿåº¦")
                print("â€¢ GPUå†…å­˜ä½¿ç”¨: 2-4GB (è§†é¢‘å¤æ‚åº¦å†³å®š)")
                print("â€¢ CPUä½¿ç”¨ç‡: å¤§å¹…é™ä½")
        else:
            print(f"âŒ GPUä¸å¯ç”¨: {self.gpu_info.get('reason', 'æœªçŸ¥é”™è¯¯')}")

# å…¨å±€Tesla T4ä¼˜åŒ–å™¨å®ä¾‹
tesla_t4_optimizer = TeslaT4Optimizer()

def check_tesla_t4_support() -> Dict:
    """æ£€æŸ¥Tesla T4æ”¯æŒçŠ¶æ€"""
    return tesla_t4_optimizer.gpu_info

def get_tesla_t4_encoding_params(quality: str = 'balanced') -> List[str]:
    """è·å–Tesla T4ç¼–ç å‚æ•°"""
    return tesla_t4_optimizer.get_optimal_encoding_params(quality)

def optimize_command_for_tesla_t4(cmd: List[str]) -> List[str]:
    """ä¸ºTesla T4ä¼˜åŒ–FFmpegå‘½ä»¤"""
    return tesla_t4_optimizer.optimize_ffmpeg_command(cmd)

if __name__ == "__main__":
    # æµ‹è¯•Tesla T4ä¼˜åŒ–å™¨
    optimizer = TeslaT4Optimizer()
    optimizer.print_status()
    
    # æµ‹è¯•ç¼–ç å‚æ•°
    print("\nğŸ”§ ç¼–ç å‚æ•°æµ‹è¯•:")
    for quality in ['fast', 'balanced', 'quality']:
        params = optimizer.get_optimal_encoding_params(quality)
        print(f"  {quality}: {' '.join(params)}")
