"""
æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿ
å®æ—¶ç›‘æ§GPU/CPUä½¿ç”¨ç‡ï¼Œè‡ªåŠ¨è°ƒæ•´å‚æ•°ä»¥æœ€å¤§åŒ–æ€§èƒ½
"""

import asyncio
import time
import json
import os
import subprocess
import psutil
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: float
    gpu_utilization: int
    gpu_memory_used: int
    gpu_memory_total: int
    gpu_temperature: int
    cpu_utilization: float
    cpu_memory_percent: float
    active_gpu_tasks: int
    active_cpu_tasks: int
    video_processing_fps: float = 0.0
    encoding_speed: float = 0.0

@dataclass
class OptimizationRecommendation:
    """ä¼˜åŒ–å»ºè®®æ•°æ®ç±»"""
    category: str  # gpu, cpu, memory, encoding
    priority: str  # low, medium, high, critical
    title: str
    description: str
    action: str
    expected_improvement: str

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨ - è‡ªåŠ¨ç›‘æ§å’Œè°ƒä¼˜"""
    
    def __init__(self):
        self.running = False
        self.metrics_history: List[PerformanceMetrics] = []
        self.optimization_history: List[OptimizationRecommendation] = []
        
        # æ€§èƒ½é˜ˆå€¼é…ç½®
        self.thresholds = {
            'gpu_utilization_low': 30,      # GPUåˆ©ç”¨ç‡è¿‡ä½é˜ˆå€¼
            'gpu_utilization_high': 95,     # GPUåˆ©ç”¨ç‡è¿‡é«˜é˜ˆå€¼
            'gpu_memory_high': 90,          # GPUå†…å­˜ä½¿ç”¨è¿‡é«˜é˜ˆå€¼
            'cpu_utilization_high': 85,     # CPUåˆ©ç”¨ç‡è¿‡é«˜é˜ˆå€¼
            'cpu_memory_high': 90,          # CPUå†…å­˜ä½¿ç”¨è¿‡é«˜é˜ˆå€¼
            'gpu_temperature_high': 83,     # GPUæ¸©åº¦è¿‡é«˜é˜ˆå€¼
            'encoding_fps_low': 50,         # ç¼–ç FPSè¿‡ä½é˜ˆå€¼
        }
        
        # å½“å‰ä¼˜åŒ–é…ç½®
        self.current_config = {
            'gpu_encoding_quality': 'balanced',
            'max_concurrent_gpu_tasks': 3,
            'max_concurrent_cpu_tasks': 8,
            'ffmpeg_threads': psutil.cpu_count() // 2,
            'gpu_memory_buffer': 2048,  # MB
        }
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'monitoring_duration': 0.0,
            'total_optimizations': 0,
            'performance_improvements': [],
            'avg_gpu_utilization': 0.0,
            'avg_cpu_utilization': 0.0,
            'peak_encoding_fps': 0.0,
        }
    
    async def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if self.running:
            return
        
        self.running = True
        self.start_time = time.time()
        
        logger.info("ğŸ” æ€§èƒ½ç›‘æ§ç³»ç»Ÿå¯åŠ¨")
        logger.info("   ç›‘æ§GPU/CPUä½¿ç”¨ç‡")
        logger.info("   è‡ªåŠ¨ä¼˜åŒ–ç¼–ç å‚æ•°")
        logger.info("   å®æ—¶è°ƒæ•´å¹¶å‘æ•°")
        
        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        asyncio.create_task(self._monitoring_loop())
        asyncio.create_task(self._optimization_loop())
    
    async def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.running = False
        self.stats['monitoring_duration'] = time.time() - self.start_time
        
        logger.info("ğŸ›‘ æ€§èƒ½ç›‘æ§ç³»ç»Ÿåœæ­¢")
        await self._generate_performance_report()
    
    async def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯ - æ¯ç§’æ”¶é›†æ€§èƒ½æ•°æ®"""
        while self.running:
            try:
                metrics = await self._collect_performance_metrics()
                self.metrics_history.append(metrics)
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(self.metrics_history) > 300:  # ä¿ç•™5åˆ†é’Ÿæ•°æ®
                    self.metrics_history = self.metrics_history[-200:]
                
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")
                await asyncio.sleep(5)
    
    async def _optimization_loop(self):
        """ä¼˜åŒ–å¾ªç¯ - æ¯10ç§’åˆ†æå¹¶ä¼˜åŒ–"""
        while self.running:
            try:
                if len(self.metrics_history) >= 10:
                    await self._analyze_and_optimize()
                
                await asyncio.sleep(10)
                
            except Exception as e:
                logger.error(f"æ€§èƒ½ä¼˜åŒ–é”™è¯¯: {e}")
                await asyncio.sleep(10)
    
    async def _collect_performance_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        # GPUæŒ‡æ ‡
        gpu_metrics = await self._get_gpu_metrics()
        
        # CPUæŒ‡æ ‡
        cpu_metrics = await self._get_cpu_metrics()
        
        # ä»»åŠ¡æ•°é‡ï¼ˆéœ€è¦ä»è°ƒåº¦å™¨è·å–ï¼‰
        task_counts = await self._get_task_counts()
        
        return PerformanceMetrics(
            timestamp=time.time(),
            gpu_utilization=gpu_metrics['utilization'],
            gpu_memory_used=gpu_metrics['memory_used'],
            gpu_memory_total=gpu_metrics['memory_total'],
            gpu_temperature=gpu_metrics['temperature'],
            cpu_utilization=cpu_metrics['utilization'],
            cpu_memory_percent=cpu_metrics['memory_percent'],
            active_gpu_tasks=task_counts['gpu_tasks'],
            active_cpu_tasks=task_counts['cpu_tasks']
        )
    
    async def _get_gpu_metrics(self) -> Dict:
        """è·å–GPUæŒ‡æ ‡"""
        try:
            result = await asyncio.create_subprocess_exec(
                'nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
                '--format=csv,noheader,nounits',
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await result.communicate()
            
            if result.returncode == 0:
                values = stdout.decode().strip().split(', ')
                return {
                    'utilization': int(values[0]),
                    'memory_used': int(values[1]),
                    'memory_total': int(values[2]),
                    'temperature': int(values[3])
                }
        except:
            pass
        
        return {
            'utilization': 0,
            'memory_used': 0,
            'memory_total': 24576,
            'temperature': 0
        }
    
    async def _get_cpu_metrics(self) -> Dict:
        """è·å–CPUæŒ‡æ ‡"""
        return {
            'utilization': psutil.cpu_percent(interval=0.1),
            'memory_percent': psutil.virtual_memory().percent,
            'core_count': psutil.cpu_count()
        }
    
    async def _get_task_counts(self) -> Dict:
        """è·å–ä»»åŠ¡æ•°é‡ï¼ˆéœ€è¦ä¸è°ƒåº¦å™¨é›†æˆï¼‰"""
        # è¿™é‡Œåº”è¯¥ä»GPUè°ƒåº¦å™¨è·å–å®é™…æ•°æ®
        return {
            'gpu_tasks': 0,
            'cpu_tasks': 0
        }
    
    async def _analyze_and_optimize(self):
        """åˆ†ææ€§èƒ½æ•°æ®å¹¶æ‰§è¡Œä¼˜åŒ–"""
        recent_metrics = self.metrics_history[-10:]  # æœ€è¿‘10ç§’æ•°æ®
        
        # è®¡ç®—å¹³å‡å€¼
        avg_gpu_util = sum(m.gpu_utilization for m in recent_metrics) / len(recent_metrics)
        avg_cpu_util = sum(m.cpu_utilization for m in recent_metrics) / len(recent_metrics)
        avg_gpu_memory = sum(m.gpu_memory_used for m in recent_metrics) / len(recent_metrics)
        avg_gpu_temp = sum(m.gpu_temperature for m in recent_metrics) / len(recent_metrics)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['avg_gpu_utilization'] = avg_gpu_util
        self.stats['avg_cpu_utilization'] = avg_cpu_util
        
        recommendations = []
        
        # GPUåˆ©ç”¨ç‡åˆ†æ
        if avg_gpu_util < self.thresholds['gpu_utilization_low']:
            recommendations.append(OptimizationRecommendation(
                category='gpu',
                priority='high',
                title='GPUåˆ©ç”¨ç‡è¿‡ä½',
                description=f'GPUå¹³å‡åˆ©ç”¨ç‡ä»…{avg_gpu_util:.1f}%ï¼Œè¿œä½äºé¢„æœŸ',
                action='increase_gpu_tasks',
                expected_improvement='æå‡GPUåˆ©ç”¨ç‡è‡³60-80%'
            ))
        
        elif avg_gpu_util > self.thresholds['gpu_utilization_high']:
            recommendations.append(OptimizationRecommendation(
                category='gpu',
                priority='medium',
                title='GPUåˆ©ç”¨ç‡è¿‡é«˜',
                description=f'GPUå¹³å‡åˆ©ç”¨ç‡{avg_gpu_util:.1f}%ï¼Œå¯èƒ½å½±å“ç¨³å®šæ€§',
                action='decrease_gpu_tasks',
                expected_improvement='é™ä½GPUåˆ©ç”¨ç‡è‡³80-90%'
            ))
        
        # GPUå†…å­˜åˆ†æ
        gpu_memory_percent = (avg_gpu_memory / recent_metrics[0].gpu_memory_total) * 100
        if gpu_memory_percent > self.thresholds['gpu_memory_high']:
            recommendations.append(OptimizationRecommendation(
                category='memory',
                priority='high',
                title='GPUå†…å­˜ä½¿ç”¨è¿‡é«˜',
                description=f'GPUå†…å­˜ä½¿ç”¨{gpu_memory_percent:.1f}%ï¼Œå¯èƒ½å¯¼è‡´ç¼–ç å¤±è´¥',
                action='reduce_gpu_memory_usage',
                expected_improvement='é™ä½GPUå†…å­˜ä½¿ç”¨è‡³80%ä»¥ä¸‹'
            ))
        
        # CPUåˆ©ç”¨ç‡åˆ†æ
        if avg_cpu_util > self.thresholds['cpu_utilization_high']:
            recommendations.append(OptimizationRecommendation(
                category='cpu',
                priority='medium',
                title='CPUåˆ©ç”¨ç‡è¿‡é«˜',
                description=f'CPUå¹³å‡åˆ©ç”¨ç‡{avg_cpu_util:.1f}%ï¼Œå¯èƒ½å½±å“ç³»ç»Ÿå“åº”',
                action='reduce_cpu_tasks',
                expected_improvement='é™ä½CPUåˆ©ç”¨ç‡è‡³70%ä»¥ä¸‹'
            ))
        
        # GPUæ¸©åº¦åˆ†æ
        if avg_gpu_temp > self.thresholds['gpu_temperature_high']:
            recommendations.append(OptimizationRecommendation(
                category='gpu',
                priority='critical',
                title='GPUæ¸©åº¦è¿‡é«˜',
                description=f'GPUå¹³å‡æ¸©åº¦{avg_gpu_temp:.1f}Â°Cï¼Œå­˜åœ¨è¿‡çƒ­é£é™©',
                action='reduce_gpu_load',
                expected_improvement='é™ä½GPUæ¸©åº¦è‡³80Â°Cä»¥ä¸‹'
            ))
        
        # æ‰§è¡Œä¼˜åŒ–å»ºè®®
        for rec in recommendations:
            await self._execute_optimization(rec)
            self.optimization_history.append(rec)
    
    async def _execute_optimization(self, recommendation: OptimizationRecommendation):
        """æ‰§è¡Œä¼˜åŒ–å»ºè®®"""
        logger.info(f"ğŸ”§ æ‰§è¡Œä¼˜åŒ–: {recommendation.title}")
        
        if recommendation.action == 'increase_gpu_tasks':
            # å¢åŠ GPUå¹¶å‘ä»»åŠ¡æ•°
            self.current_config['max_concurrent_gpu_tasks'] = min(
                5, self.current_config['max_concurrent_gpu_tasks'] + 1
            )
            logger.info(f"   å¢åŠ GPUå¹¶å‘æ•°è‡³: {self.current_config['max_concurrent_gpu_tasks']}")
        
        elif recommendation.action == 'decrease_gpu_tasks':
            # å‡å°‘GPUå¹¶å‘ä»»åŠ¡æ•°
            self.current_config['max_concurrent_gpu_tasks'] = max(
                1, self.current_config['max_concurrent_gpu_tasks'] - 1
            )
            logger.info(f"   å‡å°‘GPUå¹¶å‘æ•°è‡³: {self.current_config['max_concurrent_gpu_tasks']}")
        
        elif recommendation.action == 'reduce_gpu_memory_usage':
            # é™ä½GPUç¼–ç è´¨é‡ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
            if self.current_config['gpu_encoding_quality'] == 'quality':
                self.current_config['gpu_encoding_quality'] = 'balanced'
            elif self.current_config['gpu_encoding_quality'] == 'balanced':
                self.current_config['gpu_encoding_quality'] = 'fast'
            logger.info(f"   è°ƒæ•´ç¼–ç è´¨é‡è‡³: {self.current_config['gpu_encoding_quality']}")
        
        elif recommendation.action == 'reduce_cpu_tasks':
            # å‡å°‘CPUå¹¶å‘ä»»åŠ¡æ•°
            self.current_config['max_concurrent_cpu_tasks'] = max(
                2, self.current_config['max_concurrent_cpu_tasks'] - 1
            )
            logger.info(f"   å‡å°‘CPUå¹¶å‘æ•°è‡³: {self.current_config['max_concurrent_cpu_tasks']}")
        
        elif recommendation.action == 'reduce_gpu_load':
            # é™ä½GPUè´Ÿè½½
            self.current_config['max_concurrent_gpu_tasks'] = max(
                1, self.current_config['max_concurrent_gpu_tasks'] - 1
            )
            self.current_config['gpu_encoding_quality'] = 'fast'
            logger.info("   é™ä½GPUè´Ÿè½½: å‡å°‘å¹¶å‘æ•°å¹¶ä½¿ç”¨å¿«é€Ÿç¼–ç ")
        
        self.stats['total_optimizations'] += 1
    
    async def _generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics_history:
            return
        
        report = {
            'summary': {
                'monitoring_duration': self.stats['monitoring_duration'],
                'total_optimizations': self.stats['total_optimizations'],
                'avg_gpu_utilization': self.stats['avg_gpu_utilization'],
                'avg_cpu_utilization': self.stats['avg_cpu_utilization'],
            },
            'final_config': self.current_config,
            'optimization_history': [asdict(opt) for opt in self.optimization_history],
            'performance_trends': self._calculate_performance_trends(),
            'recommendations': self._generate_final_recommendations()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = f"logs/performance_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs('logs', exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ‰“å°æ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ‘˜è¦")
        print("="*60)
        print(f"ç›‘æ§æ—¶é•¿: {self.stats['monitoring_duration']:.1f}ç§’")
        print(f"æ‰§è¡Œä¼˜åŒ–: {self.stats['total_optimizations']}æ¬¡")
        print(f"å¹³å‡GPUåˆ©ç”¨ç‡: {self.stats['avg_gpu_utilization']:.1f}%")
        print(f"å¹³å‡CPUåˆ©ç”¨ç‡: {self.stats['avg_cpu_utilization']:.1f}%")
        print(f"æœ€ç»ˆGPUå¹¶å‘æ•°: {self.current_config['max_concurrent_gpu_tasks']}")
        print(f"æœ€ç»ˆç¼–ç è´¨é‡: {self.current_config['gpu_encoding_quality']}")
        print("="*60)
    
    def _calculate_performance_trends(self) -> Dict:
        """è®¡ç®—æ€§èƒ½è¶‹åŠ¿"""
        if len(self.metrics_history) < 20:
            return {}
        
        # è®¡ç®—å‰åå¯¹æ¯”
        early_metrics = self.metrics_history[:10]
        late_metrics = self.metrics_history[-10:]
        
        early_gpu_util = sum(m.gpu_utilization for m in early_metrics) / len(early_metrics)
        late_gpu_util = sum(m.gpu_utilization for m in late_metrics) / len(late_metrics)
        
        early_cpu_util = sum(m.cpu_utilization for m in early_metrics) / len(early_metrics)
        late_cpu_util = sum(m.cpu_utilization for m in late_metrics) / len(late_metrics)
        
        return {
            'gpu_utilization_change': late_gpu_util - early_gpu_util,
            'cpu_utilization_change': late_cpu_util - early_cpu_util,
            'optimization_effectiveness': 'improved' if late_gpu_util > early_gpu_util else 'stable'
        }
    
    def _generate_final_recommendations(self) -> List[str]:
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        recommendations = []
        
        if self.stats['avg_gpu_utilization'] < 50:
            recommendations.append("è€ƒè™‘å¢åŠ è§†é¢‘å¤„ç†ä»»åŠ¡çš„å¹¶å‘æ•°ä»¥æé«˜GPUåˆ©ç”¨ç‡")
        
        if self.stats['avg_cpu_utilization'] > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å°†æ›´å¤šä»»åŠ¡è½¬ç§»åˆ°GPUå¤„ç†")
        
        if self.stats['total_optimizations'] > 10:
            recommendations.append("ç³»ç»Ÿè¿›è¡Œäº†å¤šæ¬¡è‡ªåŠ¨ä¼˜åŒ–ï¼Œå»ºè®®æ£€æŸ¥ç¡¬ä»¶é…ç½®")
        
        return recommendations
    
    def get_current_status(self) -> Dict:
        """è·å–å½“å‰çŠ¶æ€"""
        return {
            'running': self.running,
            'current_config': self.current_config,
            'stats': self.stats,
            'recent_metrics': self.metrics_history[-5:] if self.metrics_history else [],
            'recent_optimizations': self.optimization_history[-3:] if self.optimization_history else []
        }

# å…¨å±€æ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹
performance_optimizer = PerformanceOptimizer()
